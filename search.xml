<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>üçΩ ü•® MensaarLecker -- A beloved tool to find out Mensa Ladies&#39; favourite menu using Seleniumü•® üçΩ</title>
      <link href="/mensaar/"/>
      <url>/mensaar/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Repository: <a href="https://github.com/greenmeeple/MensaarLecker">MensaarLecker</a></p></blockquote><p>As an <a href="https://www.uni-saarland.de/start.html">UdS</a> Student,<br>Are you tired of seeing french friesüçü 3 times a week, or wondering when I can have the best pizza üçï in the Mensacafe?<br>MensaarLecker aims to collect all the data from Menu 1, 2, and Mensacafe to trace your favourite, or Mensa Ladies‚Äô, favourite menu!</p><hr><h2 id="ü•ó-Description"><a href="#ü•ó-Description" class="headerlink" title="ü•ó Description"></a>ü•ó Description</h2><p>A fully automated scraper and static website for the Saarbr√ºcken Mensa, powered by Python, Selenium, Google Sheets, and GitHub Actions.</p><blockquote><p>Get a clean and daily-updated overview of meals from <a href="https://mensaar.de/">mensaar.de</a>, with searchable history, meal components, and frequency stats.</p></blockquote><hr><h2 id="üåê-Live-Demo"><a href="#üåê-Live-Demo" class="headerlink" title="üåê Live Demo"></a>üåê Live Demo</h2><p>üëâ <a href="https://your-username.github.io/MensaarLecker">View Website</a><br>üëâ <a href="https://docs.google.com/spreadsheets/d/your-sheet-id-here">View Data in Google Sheets</a></p><hr><h2 id="üìÖ-Features"><a href="#üìÖ-Features" class="headerlink" title="üìÖ Features"></a>üìÖ Features</h2><ul><li>‚úÖ Scrapes the Saarbr√ºcken Mensa daily menu</li><li>‚úÖ Publishes structured data to a connected Google Sheet</li><li>‚úÖ Generates static HTML pages:<ul><li><strong><code>index.html</code></strong> ‚Äì Today‚Äôs menu with meal frequency counts</li><li><strong><code>menu.html</code></strong> ‚Äì Full searchable menu with DataTables</li></ul></li><li>‚úÖ Automatically updates via GitHub Actions at <strong>10:00 AM UTC on weekdays</strong></li><li>‚úÖ Beautiful card-style layout &amp; component display</li><li>‚úÖ No server required ‚Äî 100% static</li></ul><hr><h2 id="üß†-Meal-Frequency-Display-Example"><a href="#üß†-Meal-Frequency-Display-Example" class="headerlink" title="üß† Meal Frequency Display Example"></a>üß† Meal Frequency Display Example</h2><p>The homepage shows how often each meal has been served based on historical data since 2025.03.20:</p><p><strong>üçΩÔ∏è Pasta mit Tomatenso√üe</strong><br><em>üìä Seen since 2025.03.20</em><br>‚úÖ Geriebener K√§se<br>‚úÖ Rucola</p><hr><h2 id="üìÅ-Project-Structure"><a href="#üìÅ-Project-Structure" class="headerlink" title="üìÅ Project Structure"></a>üìÅ Project Structure</h2><pre><code class="bash">.‚îú‚îÄ‚îÄ Mensaar_scraper.py         # Scrapes from mensaar.de and writes to Google Sheet‚îú‚îÄ‚îÄ generate_menu.py           # Reads the sheet and generates index.html and menu.html‚îú‚îÄ‚îÄ credentials.json           # Google service account key (excluded from repo)‚îú‚îÄ‚îÄ index.html                 # Main website page with today&#39;s menu‚îú‚îÄ‚îÄ menu.html                  # Full searchable table of meals‚îú‚îÄ‚îÄ .github/workflows/‚îÇ   ‚îî‚îÄ‚îÄ update_menu.yml        # GitHub Actions automation‚îú‚îÄ‚îÄ src/‚îÇ   ‚îî‚îÄ‚îÄ uds_spirit.jpg         # Soul of this project‚îî‚îÄ‚îÄ README.md</code></pre>]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Scraper </tag>
            
            <tag> Selenium </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MensaarLecker Development Walkthrough</title>
      <link href="/mensaar-walkthrough/"/>
      <url>/mensaar-walkthrough/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Repository: <a href="https://github.com/greenmeeple/MensaarLecker">MensaarLecker</a></p></blockquote><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Me and my friends <del>hate</del><strong>love</strong> the UdS Mensa so much! The infinite frozen food and french fries menus give us so much energy and motivation for the 5-hour afternoon coding marathon. However, no one actually knows how many potatoes they have exterminated throughout the week. We have a genius webpage created by some <a href="https://gibtesheuteschnitzel.de/">Schnitzel lover</a>. Personally, I like its minimalistic layout and determination on Schnitzel searching. </p><blockquote><p>However, we want more.</p></blockquote><p>It‚Äôs not just Schnitzel; we want to know everything about their menu. We want to know what‚Äôs inside the mensa ladies‚Äô brains when they design next week‚Äôs menu.</p><blockquote><p>The desire never ends. We need more data, more details, more, More, <strong>MORE!</strong></p></blockquote><h2 id="Developing-Process"><a href="#Developing-Process" class="headerlink" title="Developing Process"></a>Developing Process</h2><h3 id="Beautiful-Soup"><a href="#Beautiful-Soup" class="headerlink" title="Beautiful Soup"></a><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">Beautiful Soup</a></h3><p>I started my journey with Beautiful Soup, one of the most popular Python web scraper packages. However, as a Uni that is well-known for its computer science program, all the menus are rendered using JavaScript. And beautiful can only scrape HTML and XML tags. So the scraper can only see an empty skeleton page:</p><p><img src="/images/projects/mensaar_empty.png"></p><h3 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a><a href="https://selenium-python.readthedocs.io/">Selenium</a></h3><p>Basically, Selenium is a <a href="https://www.selenium.dev/documentation/webdriver/">Webdriver</a> that opens a browser naturally, like a human user. Then from there we can scrape the rendered information. Things get simpler once we can see the website as we see it on the browser. We just need to find the tag that contains the information we need and save it for storage.</p><h3 id="Scraping"><a href="#Scraping" class="headerlink" title="Scraping"></a>Scraping</h3><table><thead><tr><th align="left">data we need</th><th align="left">tag</th></tr></thead><tbody><tr><td align="left">menus</td><td align="left"><code>&lt;div class=&quot;counter&quot;&gt;</code></td></tr><tr><td align="left">date</td><td align="left"><code>&lt;div class=&quot;cursor-pointer active list-group-item&quot;&gt;</code></td></tr><tr><td align="left">main dish</td><td align="left"><code>&lt;span class=&quot;meal-title&quot;&gt;</code></td></tr><tr><td align="left">side dish</td><td align="left"><code>&lt;div class=&quot;component&quot;&gt;</code></td></tr></tbody></table><p>The first part of the task is to get the daily menu. We also get the date on the website to make the following work easier.</p><p>By the <code>find_element</code> and <code>find_elements</code> functions in Selenium, we can create a simple scraper like this:</p><pre><code class="python">from selenium import webdriverfrom selenium.webdriver.common.keys import Keysfrom selenium.webdriver.common.by import Bydriver = webdriver.Firefox()driver.get(&quot;https://mensaar.de/#/menu/sb&quot;)counters = driver.find_elements(By.CLASS_NAME, &quot;counter&quot;)for counter in counters:    meal_title = meal.find_element(By.CLASS_NAME, &quot;meal-title&quot;).text.strip()</code></pre><p>However, on the webpage there is also a counter called <code>Wahlessen.</code> Which refers to a more pricy and unpredictable menu, and we want to exclude its data:</p><pre><code class="python">counter_title = counter.find_element(By.CLASS_NAME, &quot;counter-title&quot;).text.strip()# Filter for specified counter titlesif counter_title in [&quot;Men√º 1&quot;, &quot;Men√º 2&quot;, &quot;Mensacaf√©&quot;]:    meal_title = meal.find_element(By.CLASS_NAME, &quot;meal-title&quot;).text.strip()</code></pre><!-- ### StorageIt is kinda pointless to make a full database for these small piece of data *(I may take my word back in the future)*, so we just store the collected data in Json files.Therefore, everyday we will have a separate Json file. We create a separate Json file for statistics, it is calculated simply by adding current date's data into the file, so it will accumlate each data entry.```pythonwith open(output_file, "w", encoding="utf-8") as f:    json.dump(result, f, ensure_ascii=False, indent=2)print(f"Results saved to {output_file}")# Save the updated occurrence counts to the JSON filecount_result = {    "meal_counts": dict(meal_count),    "component_counts": dict(component_count)}with open(count_file, "w", encoding="utf-8") as f:    json.dump(count_result, f, ensure_ascii=False, indent=2)print(f"Counts saved to {count_file}")```### Automation with [GitHub Workflow](https://docs.github.com/en/actions/writing-workflows) -->]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Scraper </tag>
            
            <tag> Selenium </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 12.3 -- Complementation of Parity Tree Automata</title>
      <link href="/AGV/agv12-3/"/>
      <url>/AGV/agv12-3/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv12-2/">Emptiness Game</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>We now prove that parity tree automata are closed under complementation. As discussed at the beginning of the section, our proof makes heavy use of the determinacy of parity games (with infinite game arenas) established in <a href="../agv11-4">Theorem 11.3</a>.</p><blockquote><p>$\textbf{Theorem 12.3. } \textit{For every parity tree automaton }\mathcal{A}\textit{ over }\Sigma\textit{ there is a parity tree automaton }\mathcal{A}‚Äô\newline\textit{ with }\mathcal{L(A‚Äô)}&#x3D;\mathcal{T}_\Sigma\setminus\mathcal{L(A)}.$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>Let $\mathcal{A}&#x3D;(\Sigma,Q,q_0,T,\small\text{PARITY} \normalsize(C))$. By Theorem 12.1, a tree $(\mathcal{T},t)$ is accepted by $\mathcal{A}$ iff Player 0 has a winning strategy from position $(\varepsilon,q_0)$ of the acceptance game $\mathcal{G}_{\mathcal{A},t}$. </p><p>Since $\mathcal{A}$ is a parity tree automaton, $\mathcal{G}<em>{\mathcal{A},t}$ is a parity game and therefore, by Theorem 11.3, memoryless determined. Hence, $\mathcal{A}$ does not accept some tree $t$ iff Player 1 has a winning memoryless strategy $\sigma$ in $\mathcal{G}</em>{\mathcal{A},t}$ from $(\varepsilon,q_0)$. </p><p>The strategy $\sigma:\lbrace 0,1\rbrace^\ast\times T\rightarrow\lbrace 0,1\rbrace^\ast\times Q$ can be represented as a function $\sigma‚Äô:\lbrace 0,1\rbrace^\ast\times T\rightarrow\lbrace 0,1\rbrace$</p><p>where $\sigma(w,(q,\sigma,q^0,q^1))&#x3D;(wi,q^i)$ iff $\sigma‚Äô(w,(q,\sigma,q^0,q^1))&#x3D;i$. Yet another representation of the same strategy is $\sigma‚Äô:\lbrace 0,1\rbrace^\ast\rightarrow\lbrace T\rightarrow\lbrace 0,1\rbrace\rbrace$,</p><p>which can be understood as a labeling of $\mathcal{T}$ with finite ‚Äúlocal strategies‚Äù. Hence, A does not accept $(\mathcal{T},t)$ iff</p><ol><li>there is a $(T\rightarrow\lbrace 0,1\rbrace)$-labeled tree $(\mathcal{T},v)$ such that</li><li>for all i0i1i2 . . . ‚àà {0, 1}</li></ol><hr><p>Next chapter: <a href="../agv/"></a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 12.2 -- Emptiness Game</title>
      <link href="/AGV/agv12-2/"/>
      <url>/AGV/agv12-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv12-1/">Tree Automata and Acceptance Game</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Emptiness-Game"><a href="#Emptiness-Game" class="headerlink" title="Emptiness Game"></a>Emptiness Game</h2><p>The acceptance game can also be used to test if the language of a given tree automaton is non-empty. For this purpose, we first translate the given automaton into an automaton with singleton alphabet.</p><blockquote><p>$\textbf{Construction 12.1. } \text{For a given tree automaton }\mathcal{A}\text{ over }\Sigma\text{-labeled trees, we consider the}\newline\text{following tree automaton }\mathcal{A}‚Äô\text{ over }\lbrace1\rbrace\text{-labeled trees, such that }\mathcal{L(A)}&#x3D;\varnothing\text{ iff }\mathcal{L(A‚Äô)}&#x3D;\varnothing:\newline<br>\begin{array}{l}<br>\hspace{1cm} \cdot \ Q‚Äô&#x3D;Q \newline<br>\hspace{1cm} \cdot \ q_0‚Äô&#x3D;q_0\newline<br>\hspace{1cm} \cdot \ T‚Äô&#x3D;\lbrace(q,1,q‚Äô,q‚Äô‚Äô)\mid(q,\sigma,q‚Äô,q‚Äô‚Äô)\in T,\sigma\in\Sigma\rbrace\newline<br>\hspace{1cm} \cdot \ Acc‚Äô &#x3D; Acc<br>\end{array}$</p></blockquote><p>Because the subtrees of a $\lbrace 1\rbrace$-labeled binary tree are the same from all nodes, we can simplify its acceptance game such that only finitely many positions are needed. We call this game the <strong>emptiness game</strong>.</p><blockquote><p>$\textbf{Definition 12.5. } \text{Let }\mathcal{A}&#x3D;(\Sigma,Q,q_0,T,Acc)\text{ be a tree automaton. The }\textit{emptiness game}\text{ of }\mathcal{A}\newline \text{ is the game }\mathcal{G}_{\mathcal{A}}&#x3D;(\mathcal{A}‚Äô,\text{Win}‚Äô)\text{ with the finite game arena }\mathcal{A}‚Äô&#x3D;(Q\cup T, Q,T,E)\text{, where}\newline E&#x3D;\lbrace(q,\tau)\mid\tau&#x3D;(q,\sigma,q^0,q^1),\tau\in T\rbrace\cup\lbrace(\tau,q‚Äô)\mid\tau&#x3D;(\rule{0.5em}{0.4pt},\sigma,q^0,q^1)\text{ and }(q‚Äô&#x3D;q^0\text{ or }q‚Äô&#x3D;q^1)\rbrace\newline\text{and Win‚Äô}&#x3D;\lbrace q(0)\tau(0)q(1)\tau(1)\dots\mid q(0)q(1)\dots\in Acc,\tau(0)\tau(1)\dots\in T^\omega\rbrace$</p></blockquote><blockquote><p>$\textbf{Theorem 12.2. } \textit{The language of a tree automaton }\mathcal{A}\textit{ is non-empty iff Player 0 wins the}\newline\textit{emptiness game }\mathcal{G}_{\mathcal{A}}\textit{ from position }q_0.$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>The emptiness game corresponds to the acceptance game of the automaton from Construction 12.1 on the $\lbrace 1\rbrace$-labeled binary tree.</p><hr><p>Next chapter: <a href="../agv11-3/">Complementation of Parity Tree Automata</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 12.1 -- Tree Automata and Acceptance Game</title>
      <link href="/AGV/agv12-1/"/>
      <url>/AGV/agv12-1/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv11-6/">A Remark on Undetermined Games</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Infinite games allow us to reason elegantly about infinite trees. A famous example of an argument that became significantly simpler with the introduction of game-theoretic ideas is the proof of <strong>Rabin‚Äôs theorem</strong>. </p><p>Rabin‚Äôs theorem states that the satisfiability of <strong>monadic second-order logic with two successors (S2S)</strong> is decidable. Like in <a href="../agv6-5/">Section 6</a>, where we showed that S1S formulas can be translated to automata, we will show that S2S formulas can be translated to automata, this time, in order to accommodate more than one successor function, to automata over infinite trees. </p><p>The most difficult part of the proof of Rabin‚Äôs theorem is to show that tree automata are <em>closed under complement</em>. The original proof was purely combinatorial (and very difficult to understand), but the game-theoretic argument is simply based on <strong>the determinacy of the acceptance game of the tree automaton</strong>:</p><ul><li><p>the acceptance of a tree by a tree automaton &#x3D; the existence of a winning strategy for Player 0,</p></li><li><p>the non-acceptance &#x3D; the absence of such a strategy &#x3D; the existence of a winning strategy for Player 1.</p></li></ul><p>We can therefore complement the language of a given tree automaton by constructing a new automaton that verifies the existence of a winning strategy for Player 1. We begin this section with a discussion of tree automata. The logic S2S and the translation to tree automata will be introduced later in the section.</p><h2 id="Tree-Automata"><a href="#Tree-Automata" class="headerlink" title="Tree Automata"></a>Tree Automata</h2><p>We consider tree automata over infinite binary trees. We use the notation for trees introduced in <a href="../agv7-1/">Section 7.1</a>. The (full) binary tree is the language $\mathcal{T} &#x3D;\lbrace 0, 1\rbrace^\ast$. For an alphabet $\Sigma, \mathcal{T}_\Sigma &#x3D; \lbrace(\mathcal{T}, t)\mid t:\mathcal{T}\rightarrow\Sigma\rbrace$ is the set of all binary $\Sigma$-labeled trees.</p><blockquote><p>$\textbf{Definition 12.1. } \text{An }\textit{automaton over infinite binary trees }\mathcal{A}\text{ is a tuple }(\Sigma,Q,q_0,T,Acc)\text{, where}\newline<br>\begin{array}{l}<br>\hspace{1cm} \cdot \ \Sigma \text{ is a finite alphabet,} \newline<br>\hspace{1cm} \cdot \ Q \text{ is a finite set of states,} \newline<br>\hspace{1cm} \cdot \ q_0 \in Q \text{ is an initial states,} \newline<br>\hspace{1cm} \cdot \ T \subseteq Q \times \Sigma \times Q \times Q, \newline<br>\hspace{1cm} \cdot \ Acc \subseteq Q^\omega \text{ is the accepting condition}<br>\end{array}$</p></blockquote><p>In the following, we will refer to automata over infinite binary trees simply as tree automata. Note that a transition of a tree automaton has two successor states, rather than a successor state as for word automata. The two states correspond to the two directions 0 and 1 of the input tree, the automaton may transition into different states for the different directions.</p><blockquote><p>$\textbf{Definition 12.2. } \text{A }\textit{run }\text{of a tree automata }\mathcal{A}\text{ on an infinite }\Sigma\text{-labeled binary tree }(\mathcal{T},t)\newline\text{ is a }Q\text{-labeled binary tree }(\mathcal{T},r)\text{ such that the following hold:}\newline<br>\begin{array}{l}<br>\hspace{0.5cm} \cdot \ r(\varepsilon)&#x3D;q_0 \hspace{2.5cm} \cdot \ (r(n),t(n),r(n0),r(n1))\in T\text{ for all }n\in\lbrace 0,1\rbrace^\ast<br>\end{array}$</p></blockquote><p>Note that $n0$ and $n1$ are the children of node $n$ in direction 0 and 1, respectively. The <strong>accepting runs</strong> are defined as for alternating automata in <a href="../agv7-1/">Section 7.1</a>: we apply the acceptance condition to the branches of the run tree. (Note that a run of an alternating automaton may have finite and infinite branches. The acceptance condition is only checked on infinite branches. Here, all branches are infinite.)</p><blockquote><p>$\textbf{Definition 12.3. } \text{A }\textit{run }(\mathcal{T},r)\text{ is }\textit{accepting}\text{ iff, for every infinite branch }n_0n_1n_2\dots,$<br>$$r(n_0)r(n_1)r(n_2)\dots\in Acc$$</p></blockquote><p>The language of the tree automaton $\mathcal{A}$ consists of the set of accepted $\Sigma$-labeled trees.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>The following B√ºchi tree automaton $\mathcal{A}&#x3D;(\Sigma,Q,q_0,T,\small\text{B√úCHI}\normalsize(F))$ accepts all $\lbrace a,b\rbrace$-labeled trees with infinitely many $b$‚Äôs on each branch.</p><ul><li>$\Sigma &#x3D; \lbrace a,b\rbrace$</li><li>$Q&#x3D;\lbrace q_a,q_b\rbrace; q_0&#x3D;q_a$</li><li>$T&#x3D;\lbrace(q_a,a,q_a,q_a),(q_b,a,q_a,q_a),(q_a,b,q_b,q_b),(q_b,b,q_b,q_b)\rbrace$</li><li>$F &#x3D; \lbrace q_b\rbrace$</li></ul><p>Consider the $\Sigma$-labeled input tree $(\mathcal{T},t)$:</p><p><img src="/images/notes/uds/agv/12_1_inputtree.png"></p><p>The following $Q$-labeled tree is a run $(\mathcal{T},r)$ of $\mathcal{A}$ on $(\mathcal{T},t)$:</p><p><img src="/images/notes/uds/agv/12_1_runtree.png"></p><h2 id="Acceptance-Game"><a href="#Acceptance-Game" class="headerlink" title="Acceptance Game"></a>Acceptance Game</h2><p>The acceptance mechanism of a tree automaton is also characterized via its <strong>acceptance game</strong>. Player 0 can choose the alphabet $t(w)$ and Player 1 can choose the next state $q‚Äô$:</p><blockquote><p>$\textbf{Definition 12.4. } \text{Let }\mathcal{A}&#x3D;(\Sigma,Q,q_0,T,Acc)\text{ be a tree automata and let }(\mathcal{T},t)\text{ be a }\Sigma\text{-labeled}\newline\text{binary tree. Then the }\textit{acceptance game}\text{ of }\mathcal{A}\text{ on }(\mathcal{T},t)\text{ is the game }\mathcal{G}_{\mathcal{A},t}&#x3D;(\mathcal{A}‚Äô,\text{Win}‚Äô)\text{ with the}\newline\text{infinite game arena }\mathcal{A}‚Äô&#x3D;(V‚Äô,V_0‚Äô,V_1‚Äô,E‚Äô)\text{ and the winning condition Win‚Äô defined as follows:}\newline<br>\begin{array}{lll}<br>\hspace{1cm} \cdot \ V_0‚Äô&amp;&#x3D;&amp;\lbrace(w,q)\mid w\in\lbrace0,1\rbrace^\ast,q\in Q\rbrace\newline<br>\hspace{1cm} \cdot \ V_1‚Äô&amp;&#x3D;&amp;\lbrace(w,\tau)\mid w\in\lbrace0,1\rbrace^\ast,\tau\in T\rbrace\newline<br>\hspace{1cm} \cdot \ E‚Äô&amp;&#x3D;&amp;\lbrace((w,q),(w,\tau))\mid\tau&#x3D;(q,t(w),q^0,q^1),\tau\in T\rbrace\ \cup \newline<br>&amp;&amp;\lbrace((w,\tau),(w,q‚Äô))\mid\tau&#x3D;(q,\sigma,q^0,q^1)\text{ and}\newline<br>&amp;&amp;\hspace{3.65cm}w‚Äô&#x3D;w0\text{ and }q‚Äô&#x3D;q^0\text{ or }w‚Äô&#x3D;w1\text{ and }q‚Äô&#x3D;q^1\rbrace\newline<br>\hspace{1cm} \cdot \ \text{Win}‚Äô &amp;&#x3D;&amp; \lbrace(w[0,0],q(0))(w[0,0],\tau(0))(w[0,1],q(1))(w[0,1],\tau(1))\dots\mid\newline<br>&amp;&amp; \hspace{1cm} q(0)q(1)\dots\in Acc, w(0)w(1)\dots\in\lbrace 0,1\rbrace^\omega,\tau(0)\tau(1)\dots\in T^\omega\rbrace<br>\end{array}$</p></blockquote><h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h3><p>The following is a part of the acceptance game of automaton $\mathcal{A}$ from the example above:</p><p><img src="/images/notes/uds/agv/12_1_accgame.png"></p><blockquote><p>$\textbf{Theorem 12.1. } \textit{A tree automaton }\mathcal{A}&#x3D;(\Sigma,Q,q_0,T,Acc)\textit{ accepts an input tree }(\mathcal{T},r)\newline\textit{ if and only if Player 0 wins the acceptance game }\mathcal{G}_{\mathcal{A},t}&#x3D;(\mathcal{A}‚Äô,\text{Win}‚Äô)\textit{ from position }(\varepsilon,q_0).$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p><strong>If the input tree is accepted, there is a winning strategy for Player 0</strong></p><p>Given an accepting run $(\mathcal{T},r)$ of $\mathcal{A}$, we construct a memoryless winning strategy $\sigma:V_0‚Äô\rightarrow V‚Äô$ for Player 0:</p><p>$$\sigma(w,q)&#x3D;(w,(r(w),t(w),r(w0),r(w1)))$$</p><p><strong>If there is a winning strategy for Player 0, the input tree is accepted</strong></p><p>Given a winning strategy $\sigma:V‚Äô^\ast V_0‚Äô\rightarrow V‚Äô$, we construct an accepting run $(\mathcal{T},r)$ where $r(\varepsilon)&#x3D;q_0$ and for all $w\in\lbrace 0,1 \rbrace^\ast$</p><p>$$r(w0)&#x3D;q\text{ for }\sigma(\Delta(w))&#x3D;(w,(\rule{0.5em}{0.4pt},\rule{0.5em}{0.4pt},q,\rule{0.5em}{0.4pt}))\ \text{ and }\ r(w1)&#x3D;q\text{ for }\sigma(\Delta(w))&#x3D;(w,(\rule{0.5em}{0.4pt},\rule{0.5em}{0.4pt},\rule{0.5em}{0.4pt}q))$$</p><p>where $\Delta(\varepsilon)&#x3D;(\varepsilon,q_0)\ \text{ and }\ \Delta(wd)&#x3D;\Delta(w)\cdot\sigma(\Delta(w))\cdot(wd,r(wd))\text{ for }d\in\lbrace0,1\rbrace.$</p><hr><p>Next chapter: <a href="../agv12-2/">Emptiness Game</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 11.6 -- A Remark on Undetermined Games</title>
      <link href="/AGV/agv11-6/"/>
      <url>/AGV/agv11-6/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv11-5/">Muller Games</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><p>Since we have shown that <a href="../agv11-2/">reachability</a>, <a href="../agv11-3/">B√ºchi</a>, <a href="../agv11-4/">parity</a>, and <a href="../agv11-5/">Muller</a> games are all <strong>determined</strong>, it might seem as if all games were determined. The purpose of this last subsection is to remark that this is not the case. By definition, every play is either won by Player 0 or by Player 1; however, it is entirely possible that neither Player 0 nor Player 1 has a winning strategy.</p><p>We will construct a game with a winning condition that allows the players to <em>steal</em> strategies in the sense that if Player i has a winning strategy œÉ, then Player 1‚àí$i$ has a strategy $\tau$ that mimicks $\sigma$ so that the play resulting from strategies œÉ and œÑ is won by Player 1-$i$: hence, strategy $\sigma$ is not winning after all! </p><p>We fix the alphabet $\mathbb{B}&#x3D;\lbrace 0,1\rbrace$. To define the winning condition, we introduce an <em>infinite</em> $\text{XOR}$ <em>function</em> $f$. An infinite $\text{XOR}$ function is a function $f:\mathbb{B}^\omega\rightarrow\mathbb{B}$ such that $f(\alpha)\neq f(\beta)$ for all Œ±, Œ≤ ‚àà B œâ that have the exact same letter in every position except for exactly one position where they have different letters. </p><p>To see that such a function exists, define an equivalence relation $\sim$ such that $\alpha\sim\beta$ iff there exists a position $n\in\mathbb{N}$ such that $\alpha(i)&#x3D;\beta(i)$ for all $i\geq n$. Let $S\subseteq\mathbb{B}^\omega$ be a set that contains exactly one element from each $\sim$-equivalence class, and let $r(\alpha)$ be the unique $\beta\in S$ such that $\alpha\sim\beta$. For every $\alpha\in\mathbb{B}^\omega$, the two sequences $\alpha$ and $r(\alpha)$ differ only in a finite number of positions. We define $f(\alpha)&#x3D;0$ if this number is even and $f(\alpha)&#x3D;1$ if it is odd. Hence, $f$ is indeed an infinite $\text{XOR}$ function: if two sequences $\alpha,\beta\in\mathbb{B}^\omega$ differ in exactly one position, then $f(\alpha)\neq f(\beta)$. </p><p>We now use the infinite $\text{XOR}$ function $f$ to define the game. We‚Äôll describe the game somewhat informally in terms of rounds executed by the players; it is straightforward to translate this into an explicit arena and winning condition. Our game is played in rounds $n &#x3D; 0, 1, 2,\dots,$ where in round $n$, first Player 0 picks a finite word $w_{2n}\in\mathbb{B}^+$, then Player 1 picks $w_{2n+1}\in\mathbb{B}^+$. The resulting play $\alpha&#x3D;w_0,w_1,w_2,\dots$ is winning for Player $f(\alpha)$.</p><p>We now use the ‚Äústrategy stealing‚Äù argument to show that no player has a winnig strategy in this game. A strategy for Player $i$ is a mapping $\sigma:\cup_{n\in\mathbb{N}}(\mathbb{B}^+)^{2n+i}$, where we denote $(\mathbb{B}^+)^0&#x3D;\varepsilon$.</p><p>As usual, $\sigma$ is a winning strategy for Player $i$ if Player $i$ wins every play that is consistent with $\sigma_i$ . Now fix an arbitrary strategy $\tau$ for Player 1. From $\tau$, we construct two different strategies $\sigma$ and $\sigma‚Äô$ for Player 0. </p><p>For the first round:</p><ul><li><p>$\sigma(\varepsilon)&#x3D;0$</p></li><li><p>$\sigma‚Äô(\varepsilon)&#x3D;1w_1$ where $w_1&#x3D;\tau(0)$</p></li></ul><p>and for all subsequent rounds:</p><ul><li><p>$\sigma(0,w_1,w_2,\dots,w_{2n+1})&#x3D;\tau(1w_1,w_2,\dots,w_{2n+1})$</p></li><li><p>$\sigma‚Äô(1w_1,w_2,\dots,w_{2n+1})&#x3D;\tau(0,w_1,w_2,\dots,w_{2n+1})$</p></li></ul><p>i.e., $\sigma$ continues to mimick $\tau$. Consider now the plays $\alpha$, resulting from playing strategies $\sigma$ and $\tau$, and $\alpha‚Äô$ resulting from playing strategies $\sigma‚Äô$ and $\tau$. By construction, $\alpha&#x3D; 0w_1w_2w_3\dots$ and $\alpha‚Äô&#x3D; 1w_1w_2\dots$ are the same except for the first position, where $\alpha$ has a 0 and $\alpha‚Äô$ has a 1. Hence, we have that $f(\alpha)\neq f(\alpha‚Äô)$: one of the two plays is won by Player 0, the other by Player 1. Hence, $\tau$ cannot be a winning strategy for Player 1! </p><p>The construction of the stealing strategies $\tau$, $\tau‚Äô$ for Player 1 from a given strategy œÉ of Player 0 is analogous. </p><p>For the first round:</p><ul><li><p>$\tau(w_0)&#x3D;0$ for $W_0&#x3D;\sigma(\varepsilon)$</p></li><li><p>$\tau‚Äô(w_0)&#x3D;1w_1$ for $w_1&#x3D;\sigma(0,w_0)$</p></li></ul><p>and for all subsequent rounds:</p><ul><li><p>$\tau(w_0,0,w_2,\dots,w_{2n+1})&#x3D;\sigma(w_0,1w_1,w_2,\dots,w_{2n+1})$</p></li><li><p>$\tau‚Äô(w_0,1w_1,w_2,\dots,w_{2n+1})&#x3D;\sigma(w_0,0,w_1,w_2,\dots,w_{2n+1})$</p></li></ul><p>Again, the resulting plays only differ in exactly one position and are, hence, won by different players. Thus, strategy $\sigma$ cannot be winning for Player 0 either.</p><hr><p>Next chapter: <a href="../agv12-1/">Tree Automata and Acceptance Game</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 11.5 -- Muller Games</title>
      <link href="/AGV/agv11-5/"/>
      <url>/AGV/agv11-5/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv11-4/">Parity Games</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><p>Muller games differ from the games we have studied so far in that they are not memoryless determined. Consider, for example, a game arena consisting of three positions $v_0,v_1,v_2$, such that there are edges from $v_0$ and $v_2$ to $v_1$ and from $v_1$ to $v_0$ and $v_2$. Hence, the only choice in the game is in $v_1$, where Player 0 gets to choose between moving to $v_0$ or $v_2$:</p><p><img src="/images/notes/uds/agv/11_5_muller.png"></p><p>The Muller condition $\mathcal{F}&#x3D;\lbrace\lbrace v_0,v_1,v_2\rbrace\rbrace$ is only satisfied if all three positions are visited infinitely often. Player 0 can therefore not win the game with a memoryless strategy, because such a strategy would either visit $v_0$ and $v_1$ infinitely often, or $v_1$ and $v_2$, but not all three positions.  </p><p>There is, however, a memoryful winning strategy: simply alternate between moving from $v_1$ to $v_0$ and to $v_2$.</p><p>In the following, we solve Muller games via a reduction to parity games, i.e., we define a parity game such that we can translate the winning strategy in the parity game into a winning strategy in the Muller game.</p><p>The fact that parity games are memoryless determined and Muller games are not, is not a contradiction: our reduction introduces additional state into the parity game, such that, on the extended state space, there exists a memoryless winning strategy. This augmentation of the state space is known as the <strong>latest appearence record</strong>:</p><h2 id="Latest-Appearence-Record"><a href="#Latest-Appearence-Record" class="headerlink" title="Latest Appearence Record"></a>Latest Appearence Record</h2><blockquote><p>$\textbf{Definition 11.11. } \text{Let }V\text{ be the set of positions of the game arena and let }{$}\text{ be some fresh}\newline\text{symbol. A }\textit{latest appearence record}\text{ over }V\text{ is a finite word over the alphabet }V\cup\lbrace{$}\rbrace\text{ where every}\newline\text{letter from }V\cup\lbrace{$}\rbrace\text{ appears exactly once and whose first letter is from }V\text{ . The }\textit{hit set}\text{ of a latest}\newline\text{appearence record }\ell&#x3D;v_0v_1\dots v_m{$}v_m+1\dots v_n\text{ is defined as }hit(\ell)&#x3D;\lbrace v_0,\dots v_m\rbrace.$</p></blockquote><p>We denote the set of all <strong>latest appearence records</strong> by $\text{LAR}$. Each latest appearence record represents a permutation of $V$ plus a position indicated by ${$}$.</p><p>We will construct the parity game in such a way that whenever the play visits $v_i$, $v_i$ is moved to the beginning of the word, and the ${$}$-symbol is moved to $v_i$‚Äôs previous position. </p><p>In this way, every play will reach a position such that, from then on, the <strong>hit set</strong> (i.e., the set of game positions to the left of ${$}$) is always a subset of the infinity set, and infinitely often equal to the infinity set. The winning condition in the parity game thus only needs to ensure that the infinity set is actually one that satisfies the Muller condition. </p><p>For this purpose, we assign even colors to hit sets (multiply the size of hit sets by 2) that appear in the table of the Muller condition, and odd colors to hit sets (multiply the size of hit sets by 2 then -1) that do not appear in the table. Since the hit set corresponds to subsets of the infinity set, we need to make sure that odd colors that result from strict subsets of entries in the table are ignored.</p><p>We do this by increasing the colors depending on the position of the ${$}$-symbol. In this way, the color of the appearence records corresponding to the full infinity set is more important than the colors of the subsets that appear in-between occurrences of the full infinity set.</p><blockquote><p>$\textbf{Definition 11.4. } \text{Let a Muller game }\mathcal{G}&#x3D;(\mathcal{A},\small\text{MULLER} \normalsize(\mathcal{F}))\text{ with arena }\mathcal{A} &#x3D; (V,V_0,V_1,E)\newline\text{be given. We compute a parity game }\mathcal{G}‚Äô&#x3D;(\mathcal{A}‚Äô,\small\text{PARITY}\normalsize(\mathcal{c}) )\text{ with arena }\mathcal{A}‚Äô &#x3D; (V‚Äô,V_0‚Äô,V_1‚Äô,E‚Äô)\newline\text{ as follows.}$<br>$\begin{array}{l}<br>  \hspace{0.5cm} \cdot \ V‚Äô&#x3D;V\times\text{LAR},V_0‚Äô&#x3D;V_0\times\text{LAR},V_1‚Äô&#x3D;V_1\times\text{LAR} \newline<br>  \hspace{0.5cm} \cdot \ E‚Äô&#x3D;\lbrace((v,v_0v_1\dots v_m{$}v_{m+1}\dots v_n),(v‚Äô,v_0‚Äôv_1‚Äô\dots v_{j-1}{$}v_{j+1}\dots v_{m+1}\dots v_n))\mid(v,v‚Äô)\in E,v‚Äô&#x3D;v_j\rbrace\newline<br>  \hspace{0.5cm} \cdot \ c(v,\ell)&#x3D; \left\lbrace\begin{array}{ll}<br>    2\cdot |hit(\ell)| &amp; \text{if }hit(\ell)\in\mathcal{F}\newline<br>    2\cdot |hit(\ell)|-1 &amp; \text{if }hit(\ell)\notin\mathcal{F}\newline<br>  \end{array}\right. \newline<br>\end{array}$</p></blockquote><p>In order to solve a given Muller game, we solve the constructed parity game. To determine if a player has a winning strategy from some position $v$ of the Muller game, we then simply check if the same player wins from the corresponding position of the parity game.</p><p>In principle, we could use any position of the parity game where $v$ appears in the first component of the position of the parity game. In the following theorem, we arbitrarily fix the position $(v,v_0v_1\dots v_n{$})$.</p><blockquote><p>$\textbf{Theorem 11.4. } \textit{For every Muller game }\mathcal{G}&#x3D;(\mathcal{A},\small\text{MULLER} \normalsize(\mathcal{F}))\textit{ with arena }\mathcal{A} &#x3D; (V,V_0,V_1,E),\newline\textit{there is a parity game }\mathcal{G}‚Äô&#x3D;(\mathcal{A}‚Äô,\small\text{PARITY}\normalsize(\mathcal{c}) )\text{ with arena }\mathcal{A}‚Äô &#x3D; (V‚Äô,V_0‚Äô,V_1‚Äô,E‚Äô)\textit{ where}\newline V‚Äô&#x3D;V\times\text{LAR}\textit{ such that each player has a winning strategy from a position }v\in V\textit{ of the Muller}\newline\textit{game iff the same player has a winning strategy from position }(v,v_0v_1\dots v_n{$})\textit{ of the parity game.}$</p></blockquote><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Consider the following game with winning condition $\small\text{MULLER} \normalsize(\lbrace\lbrace v_0,v_1\rbrace\rbrace)$:</p><p><img src="/images/notes/uds/agv/11_5_example.png"></p><p>We construct the following parity game:</p><p><img src="/images/notes/uds/agv/11_5_parity.png"></p><p>(Shown is only the reachable part of the arena from positions $(v_0, v_0v_1{$})$ and $(v_1, v_0v_1{$})$.) Since Player 0 wins from every position of the parity game, we conclude that the same is true for every position of the Muller game.</p><hr><p>Next chapter: <a href="../agv11-6/">A Remark on Undetermined Games</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 11.4 -- Parity Games</title>
      <link href="/AGV/agv11-4/"/>
      <url>/AGV/agv11-4/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv11-3/">B√ºchi Games</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Perhaps the most intriguing type of infinite games are <strong>parity games</strong>. <strong>Parity games</strong> play a key role in verification (in particular for $\mu$-calculus model checking) and synthesis, and finding fast algorithms for parity games is an active research topic. </p><p>The algorithm discussed in the following takes exponential time. There are also several quasi-polynomial-time algorithms for solving parity games (starting with a breakthrough result by Calude, Jain, Khoussainov, Li, and Stephan in 2017). In practice, however, these algorithms do not perform well (yet).</p><h2 id="Parity-Condition"><a href="#Parity-Condition" class="headerlink" title="Parity Condition"></a>Parity Condition</h2><blockquote><p>$\textbf{Definition 11.10. }\text{The }\textit{parity condition }\small\text{PARITY} \normalsize(C)\text{ for a coloring function }c:V\rightarrow\mathbb{N}\text{ is the set}$<br>$$\small\text{PARITY} \normalsize(C)&#x3D;\lbrace\alpha\in V^\omega\mid\text{max}\lbrace c(q)\mid q\in\text{Inf}(\alpha)\rbrace\text{is even}\rbrace.$$</p></blockquote><p>The parity condition is satisfied if the biggest number $q$ of the coloring function is even, among all positions that are visited infinitely often.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p><img src="/images/notes/uds/agv/11_4_parity.png"></p><ul><li><p>The winning region for Player 0: $W_0(\mathcal{G})&#x3D;\lbrace v_3,v_6,v_7\rbrace$</p><ul><li>Strategy: $\sigma(v_3) &#x3D; v_6, \sigma(v_7) &#x3D; v_4, \sigma(v_7) &#x3D; v_6$ ($v_8$ have no choices and $v_1$ is arbitrary)</li></ul></li><li><p>The winning region for Player 1: $W_1(\mathcal{G})&#x3D;\lbrace v_0,v_1,v_2,v_4,v_5,v_8\rbrace$</p><ul><li>Strategy: $\tau(v_0) &#x3D; v_1, \tau(v_2) &#x3D; v_5, \tau(v_4) &#x3D; v_0, \tau(v_5) &#x3D; v_1$</li></ul></li></ul><p>We first prove that parity games are memoryless determined, then derive an algorithm for solving parity games. In the following theorem, we emphasize that determinacy holds also for (countably) infinite game arenas. </p><p>This will be helpful when we use the determinacy to complement tree automata, because the acceptance game of a tree automaton refers to the infinite input tree and is therefore infinite.</p><blockquote><p>$\textbf{Theorem 11.3. } \textit{Parity games are memoryless determined with uniform winning strategies}\newline\textit{for game arenas with a countable set of positions and a finite number of colors.}$</p></blockquote><p>Here, we try to construct a uniform winning strategy for an arbitrary parity game.</p><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>Let $k&#x3D;\text{max}\lbrace c(v)\mid v\in V\rbrace$ be the highest color in the given parity game. We prove that parity games are memoryless determined by induction on $k$.</p><p><strong>Case</strong> $k&#x3D;0$: If the highest color is 0, then all plays are winning. $W_0(\mathcal{G})&#x3D;V, W_1(\mathcal{G})&#x3D;\varnothing$. For the memoryless winning strategy $\sigma$, we fix an arbitrary total order on $V$ and choose $\sigma(v)&#x3D;\text{min}\lbrace v‚Äô\in V\mid(v,v‚Äô)\in E\rbrace$.</p><p><strong>Case</strong> $k&gt;0$: If $k$ is even, consider Player $i$, otherwise Player (1-$i$). Let $W_{i-1}$ be the set of positions where Player (1-$i$) has a memoryless winning strategy. We show that Player $i$ has a memoryless winning strategy $\sigma$ from $V\setminus W_{1‚àíi}$ . Consider the subgame $\mathcal{G‚Äô}$:</p><ul><li>$V_0‚Äô &#x3D; V_0\setminus W_{1-i},V_i‚Äô&#x3D;V_1\setminus W_{1-i}, V‚Äô&#x3D;V_0‚Äô\cup V_1‚Äô$</li><li>$E‚Äô&#x3D;E\cap(V‚Äô\times V‚Äô)$</li><li>$c‚Äô(v)&#x3D;c(v)\text{ for all }v\in V‚Äô$</li></ul><p>Note that $\mathcal{G‚Äô}$ is still a game:</p><ul><li>for $v\in V_i‚Äô$, there is a $v\in V\setminus W_{1-i}$ with $(v,v‚Äô)\in E‚Äô$, otherwise $v$ would be in $W_{1-i}$</li><li>for $v\in V_{1-i}‚Äô$, for all $v‚Äô\in V$ with $(v,v‚Äô)\in E‚Äô$, $v‚Äô\in V\setminus W_{1-i}$, hence there is a $v‚Äô\in V‚Äô$ with $(v,v‚Äô)\in E$.</li></ul><p>Let $c‚Äô^{‚àí1}(k)&#x3D;\lbrace v\in V‚Äô\mid c‚Äô(v)&#x3D;k\rbrace$ (set of highest color positions in $V‚Äô$), and<br>Let $Y&#x3D;Attr_i‚Äô(c‚Äô^{-1}(k))$. (attractor here means the set of positions that at least visit $c‚Äô^{-1}(k)$ once)<br>Let $\sigma_A$ be the corresponding attractor strategy on $\mathcal{G‚Äô}$ into $c‚Äô^{-1}(k)$, as defined in the proof of <a href="../agv11-2/">Theorem 11.1</a>.</p><p>Now consider the subgame $\mathcal{G‚Äô‚Äô}$:</p><ul><li>$V_0‚Äô‚Äô &#x3D; V_0‚Äô\setminus Y,V_i‚Äô‚Äô&#x3D;V_1‚Äô\setminus Y, V‚Äô‚Äô&#x3D;V_0‚Äô‚Äô\cup V_1‚Äô‚Äô$</li><li>$E‚Äô‚Äô&#x3D;E‚Äô\cap(V‚Äô‚Äô\times V‚Äô‚Äô)$</li><li>$c‚Äô‚Äô:V‚Äô‚Äô\rightarrow\lbrace 0,\dots,k-1\rbrace;c‚Äô‚Äô(v)&#x3D;c‚Äô(v)\text{ for all }v\in V‚Äô‚Äô$</li></ul><p>Note that $\mathcal{G‚Äô‚Äô}$ is still a game, and that the maximal color in $\mathcal{G‚Äô‚Äô}$ is at most $k‚àí1$ (we removed position that color as $k$ and positions that can visit it by Player $i$). By induction hypothesis, that $\mathcal{G‚Äô‚Äô}$ is memoryless determined. </p><p>It is also clear that $W_{1-i}‚Äô‚Äô$, the set of positions in game $\mathcal{G‚Äô‚Äô}$ where Player (1‚àí$i$) has a memoryless winning strategy, is empty, because $W_{1-i}‚Äô‚Äô$ is a subset of $W_{1-i}$: </p><p>assume Player (1‚àí$i$) had a memoryless winning strategy from some position in $V‚Äô‚Äô$. Then this strategy would win in $\mathcal{G}$, too, since Player $i$ has no opportunity to leave $\mathcal{G‚Äô‚Äô}$ other than to $W_{1-i}$. </p><p>Hence, there is a uniform winning memoryless winning strategy $\sigma_{IH}$ for player $i$ from all positions in $V‚Äô‚Äô$. We define the following uniform strategy $\sigma$ for Player $i$ in game $\mathcal{G}$:</p><p>$$\sigma(v)&#x3D;\left\lbrace\begin{array}{ll}<br>\sigma_{IH}(v)&amp;\text{if }\ v\in V‚Äô‚Äô\newline<br>\sigma_{A}(v)&amp;\text{if }\ v\in V\setminus c‚Äô^{-1}(k)\newline<br>\text{min. successor in }V\setminus W_{1-i}&amp;\text{if }\ v\in V\cap c‚Äô^{-1}(k)\newline<br>\text{min. successor in }V&amp;\text{otherwise.}\newline<br>\end{array}\right.<br>$$</p><p>The strategy $\sigma$ is winning for Player 0 on $V\setminus W_{1‚àí\sigma}$. Consider a play that is consistent with $\sigma$, it can be either:</p><ol><li><p>$Y$ (Set of positions that Player 0 can visit the highest color $k$) is visited infinitely often. Thus, Player $i$ wins.</p></li><li><p>Eventually only positions in $V‚Äô‚Äô$ are visited. Hence, since Player $i$ follows $\sigma_{IH}$, Player $i$ wins.</p></li></ol><h2 id="Construct-W-1‚àíi-with-McNaughton‚Äôs-algorithm"><a href="#Construct-W-1‚àíi-with-McNaughton‚Äôs-algorithm" class="headerlink" title="Construct $W_{1‚àíi}$ with McNaughton‚Äôs algorithm"></a>Construct $W_{1‚àíi}$ with McNaughton‚Äôs algorithm</h2><p>The proof above is non-constructive in the sense that we begin the argument by considering (rather than computing) the set $W_{1‚àíi}$ of positions where the opponent, Player (1‚àí$i$), has a memoryless winning strategy. McNaughton‚Äôs algorithm, one of the classic algorithms for parity games over finite arenas, computes this set iteratively, with repeated recursive calls:</p><blockquote><p>$\textbf{Construction 11.3. } \text{Let a finite parity game }\mathcal{G} &#x3D; (\mathcal{A},\small\text{PARITY} \normalsize(C))\text{ be given. We compute the}\newline\text{winning regions }W_0(\mathcal{G})\text{ and }W_1(\mathcal{G})\text{ as follows. (To avoid confusion we indicate in each attractor}\newline\text{construction explicitly the game it refers to.)}$<br>$\newline<br>\text{Function }\textit{McNaughton}(\mathcal{G})&#x3D;\newline<br>\begin{array}{ll}<br>  \hspace{1cm} 1. &amp; k:&#x3D;\text{ highest color in }\mathcal{G}\newline<br>  \hspace{1cm} 2. &amp; \textbf{if }k&#x3D;0\text{ or }V&#x3D;\varnothing\newline<br>  &amp;\textbf{then return }(V,\varnothing)\newline<br>  \hspace{1cm} 3. &amp; i:&#x3D;k\text{ mod }2\newline<br>  \hspace{1cm} 4. &amp; W_{1-i}:&#x3D;\varnothing\newline<br>  \hspace{1cm} 5. &amp; \textbf{repeat}\newline<br>  &amp;\begin{array}{ll}<br>    \hspace{0.5cm} (a) &amp; \mathcal{G}‚Äô:&#x3D;\mathcal{G}\setminus Attr^i(c^{-1}(k),\mathcal{G})\newline<br>    \hspace{0.5cm} (b) &amp; (W_0‚Äô,W_1‚Äô):&#x3D;\textit{McNaughton}(\mathcal{G}‚Äô)\newline<br>    \hspace{0.5cm} (c) &amp; \textbf{if }(W_{1-i}‚Äô&#x3D;\varnothing)\textbf{ then}\newline<br>    &amp;\begin{array}{rl}<br>      \ \text{i.}  &amp; W_i:&#x3D;V\setminus W_{1-i}\newline<br>      \ \text{ii.} &amp; \textbf{return }(W_0,W_1)\newline<br>    \end{array}\newline<br>    \hspace{0.5cm} (d) &amp; W_{1-i}:&#x3D;W_{1-i}\cup Attr^{1-i}(W_{1-i}‚Äô,\mathcal{G})\newline<br>    \hspace{0.5cm} (e) &amp; \mathcal{G}‚Äô:&#x3D;\mathcal{G}\setminus Attr^{1-i}(c^{-1}(W_{1-i}‚Äô,\mathcal{G})\newline<br>  \end{array}<br>\end{array}$</p></blockquote><h3 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h3><p><strong>(Line 1):</strong> The construction begins by determining the highest color $k$ that appears in the arena. </p><p><strong>(Line 2):</strong> If this color is 0 (or the arena is empty), then Player 0 wins the game from all positions, function ends.</p><p><strong>(Line 3):</strong> Otherwise we continue by analyzing the game from the perspective of Player $i &#x3D; 0$ if $k$ is even and from the perspective of Player $i &#x3D; 1$ if $k$ is odd. </p><p><strong>(Line 4):</strong> We initialize the winning region for the opponent to $\varnothing$ and repeat the following: </p><p><strong>(Line 5a):</strong> First, we eliminate all positions where Player $i$ can enforce a visit to the highest color $k$ (which, if visited infinitely often, is beneficial for Player $i$). </p><p><strong>(Line 5b):</strong> We recursively solve the resulting subgame $\mathcal{G}‚Äô$. </p><p><strong>(line 5c):</strong> If the oppoent does not have any winning positions in the subgame, then we are done: </p><ul><li><p>If the play of $\mathcal{G}$ stays in the subgame, then Player $i$ wins with the winning strategy of the subgame.</p></li><li><p>If the play leaves the subgame, then Player $i$ can enforce a visit to the highest color.</p></li></ul><p>So either the play eventually stays in the subgame forever, and Player $i$ wins there, or it infinitely often leaves the subgame, and Player $i$ wins by visiting the highest color infinitely often. </p><p><strong>(line 5d):</strong> If the opponent wins from some non-empty winning region $W_{1‚àíi}‚Äô$ of the subgame, then we add the opponent‚Äôs attractor of $W_{1‚àíi}‚Äô$ to the winning region of $\mathcal{G}$.</p><ul><li><p>The opponent is sure to win from every position in the attractor by first ensuring a visit to $W_{1‚àíi}‚Äô$ and then staying there forever applying its winning strategy inside $\mathcal{G}‚Äô$.</p></li><li><p>Player $i$ cannot force the game out of the subgame, because $\mathcal{G}‚Äô$ was constructed by removing Player $i$‚Äôs attractor from $\mathcal{G}$.</p></li></ul><p><strong>(line 5e):</strong> We remove the entire attractor from $\mathcal{G}$ (line 5e) and continue with the resulting subgame.</p><h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h3><p>Consider again the example above. </p><p><strong>(line 1):</strong> The highest color is $k&#x3D;4$,<br><strong>(line 3):</strong> k is even, hence $i&#x3D;0$.<br><strong>(line 5a):</strong> We have that $c^{-1}(4)&#x3D;\lbrace v_4, v_8\rbrace$ and $Attr^0(c^{-1}(4))&#x3D;Attr^0(\lbrace v_4,v_8\rbrace)&#x3D;\lbrace v_3,v_4,v_6,v_7,v_8\rbrace$. Hence, $\mathcal{G}‚Äô$ is the subgame consisting of positions $v_0$, $v_1$, $v_2$, and $v_5$:</p><p><img src="/images/notes/uds/agv/11_4_eg1.png"></p><p><strong>(line 5b):</strong> The recursive call returns $W_0‚Äô&#x3D;\varnothing, W_1‚Äô&#x3D;\lbrace v_0,v_1,v_2,v_5\rbrace$. (We skip over the evaluation of the recursive call here, note that Player 1 wins from every position with a strategy that moves from $v_2$ to $v_5$.)<br><strong>(line 5d):</strong> We have that $Attr^1(\lbrace v_0,v_1,v_2,v_5\rbrace)&#x3D;\lbrace v_0,v_1,v_2,v_4,v_5,v_8\rbrace$. Hence, $W_1$ is set to $\lbrace v_0,v_1,v_2,v_4,v_5,v_8\rbrace$,<br><strong>(line 5e):</strong> And $\mathcal{G}$ is reduced to the subgame consisting of positions $v_3$, $v_6$ and $v_7$:</p><p><img src="/images/notes/uds/agv/11_4_eg2.png"></p><p><strong>(line 5b):</strong> Now, the game does not contain any positions with color 4 anymore, we therefore call the algorithm recursively. It returns $W_0‚Äô&#x3D;\lbrace v_3,v_6,v_7\rbrace, W_1‚Äô&#x3D;\varnothing$. (We again skip over the evaluation of the recursive call, note that all plays are winning for Player 0.)<br><strong>(line 5ci):</strong> Since $W_1‚Äô&#x3D;\varnothing$, we set $W_0$ to $V\setminus W_1$,<br><strong>(line 5cii):</strong> Return the final result $W_0&#x3D;\lbrace v_3,v_6,v_7\rbrace$, $W_1&#x3D;\lbrace v_0,v_1,v_2,v_4,v_5,v_8\rbrace$.</p><hr><p>Next chapter: <a href="../agv8811-5/">Muller Games</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 11.3 -- B√ºchi Games</title>
      <link href="/AGV/agv11-3/"/>
      <url>/AGV/agv11-3/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv11-2/">Reachability Games</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Recurrence-Construction"><a href="#Recurrence-Construction" class="headerlink" title="Recurrence Construction"></a>Recurrence Construction</h2><p>In a B√ºchi game, the goal of Player 0 is to visit some accepting position <strong>infinitely often</strong>. The attractor construction checks whether there is a strategy which enforces at least one visit to an accepting position. Reaching an accepting state at least once is indeed a necessary precondition, but we also have to ensure that from this position we can enforce a second visit to some accepting state, then a third, and so forth.</p><p>The <strong>recurrence construction</strong> computes the largest subset of the accepting states from which Player 0 can enforce infinitely many subsequent visits to the subset.</p><blockquote><p>$\textbf{Construction 11.2. } \text{Let an arena }\mathcal{A} &#x3D; (V_0,V_1,E)\text{ with }V&#x3D;V_0\cup V_1\text{ be given. The }\newline\textit{recurrence construction}\text{ on }\mathcal{A}\text{ is defined for all }n\in\mathbb{N}\text{ and }F\subseteq V\text{ as:}$<br>$\begin{array}{lll}<br>\hspace{1cm} \cdot \ W_n^1(F) &amp;&#x3D;&amp; V\setminus Attr^0(Recur_n(F))\newline<br>\hspace{1cm} \cdot \ Recur_{0}(F)&amp;&#x3D;&amp;F \newline<br>\hspace{1cm} \cdot \ Recur_{n+1}(F)&amp;&#x3D;&amp;Recur_{n}(F)\setminus CPre^{1}(W_n^1(F)) \newline<br>\hspace{1cm} \cdot \ Recur(F)&amp;&#x3D;&amp;\underset{n\in\mathbb{N}}{\bigcap} Recur_{n}(R)\newline<br>\end{array}$</p></blockquote><p>The set $W_n^1(F)$ contains those positions in $V$ from which Player 1 can enforce that at most $n$ visits to $F$.</p><p>The set $CPre^{1}(W_n^1(F))$ adds those positions in $V$ from which move to positions in $W_n^1(F)$, meaning that there are at most $n+1$ visits to $F$ in newly added positions.</p><p>The set $Recur_{n}(F)$ contains the subset of $F$ from which Player 0 can enforce at least $n$ <em>further</em> (i.e., a total of at least $n+1$) visits to $F$.</p><p>The set $Recur(F)$ contains the subset of $F$ from which Player 0 can enforce infinitely many visits to $F$. The recurrence construction solves a game with winning condition $\small\text{B√úCHI} \normalsize (F)$ as follows:</p><blockquote><p>$$<br>W_0(\mathcal{G})&#x3D;Attr^0(Recur(F)),\ W_1(\mathcal{G})&#x3D;V\setminus W_0(\mathcal{G})<br>$$</p></blockquote><p>$$<br>\text{Position of Player 0: Circles;}\ \ \text{Positions of Player 1: rectangles.}$$ </p><p><img src="/images/notes/uds/agv/11_3_recur1.png"></p><p><img src="/images/notes/uds/agv/11_3_recur2.png"></p><p><img src="/images/notes/uds/agv/11_3_recur3.png"></p><blockquote><p>$\textbf{Theorem 11.2. } \textit{B√ºchi games are memoryless determined. It holds that}\newline W_0(\mathcal{G})&#x3D;Attr^0(Recur(F)), W_1(\mathcal{G})&#x3D;V\setminus W_0(\mathcal{G})\textit{. Both players have a uniform winning strategy.}$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>We show for all positions $v\in V$ that</p><p>If $v\in Attr^0(Recur(F))$, then $v\in W_0(\mathcal{G})$, with the following uniform memoryless strategy $\sigma$:</p><ul><li><p>We fix some arbitrary total ordering on $V$. For $v\in (Attr^0(Recur(F))\setminus Recur(F))\cap V_0$, we follow the attractor strategy from the proof of <a href="../agv11-2/">Theorem 11.1</a>. </p></li><li><p>For $v\in Recur(F)\cap V_0$, we choose the smallest $v‚Äô\in V$ with $(v,v‚Äô)\in E$ and $v‚Äô\in Attr^0(Recur(F))$. Such a successor must exist, because otherwise $v\in CPre^{1}(W_n^1(F))$ for some $n\in\mathbb{N}$, and hence $v\notin Recur(F)$.</p></li><li><p>Every play that is consistent with $\sigma$ visits $Recur(F)\subseteq F$ infinitely often. Hence, $\sigma$ is winning for Player 0.</p></li></ul><p>If $v\in V\setminus Attr^0(Recur (F))$, then $v\in W_1(\mathcal{G})$, with the following uniform memoryless strategy $\tau$:</p><ul><li><p>We again fix an arbitrary total ordering on $V$. We define the memoryless strategies $\tau$ such taht, for $n\in\mathbb{N}$, if a play starts in $v\in W_n^1&#x3D;V\setminus Attr^0(Recur_n(F))$ and is consistent with $\tau$, there are at most $n$ visits to $F$.</p><ul><li><p>For $n&#x3D;0$ let $\tau(v)$ be the smallest $v‚Äô\in V$ such that $(v,v‚Äô)\in E$ and $v‚Äô\in V\setminus Attr^0(F)$. </p></li><li><p>For $n&gt;0$ let $\tau(v)$ be the smallest $v‚Äô\in W_{n-1}^1(F)$ with $(v,v‚Äô)\in E$ if $v\in CPre^1(W_{n-1}^1(F))$, otherwise be the smallest $v‚Äô$ in $W_{n}^1(F)$ with $(v,v‚Äô)\in E$. Such a $v‚Äô$ always exists as otherwise $v\in Attr^0(Recur (F))$.</p></li></ul></li></ul><h3 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h3><p><strong>Strategy for Player 0</strong></p><ul><li><p>If a position $v$ belongs to $(Attr^0(Recur(F))\setminus Recur(F))\cap V_0$, it must have edges to $Recur(F)$, then choose the smallest $v‚Äô$ among those.</p></li><li><p>If a position $v$ belongs to $Recur(F)\cap V_0$, we need to ensure it will visit $F$ again, so we need to choose an edge that belongs to $Attr^0(Recur(F))$.</p></li></ul><p><strong>Strategy for Player 1</strong></p><ul><li><p>Every position from Player 1 must belong to $W_n^1$, that ensures that only at most n times visits to $F$, otherwise Player 1 has no choice (belongs to $Attr^0(F)$)</p></li><li><p>For such $n &#x3D; 0$, we can ensure it never visit $F$ by choosing smallest $v‚Äô$ that does not move to $Attr^0(F)$.</p></li><li><p>For such $n &gt; 0$, if $v$ belongs to $W_{n-1}^1$, then it must have edge(s) that also belongs to $W_{n-1}^1$, otherwise there exist edge(s) belongs to $W_{n}^1$, so that it can stays in winning region of Player 1 without visiting $Attr^0(F)$.</p></li></ul><hr><p>Next chapter: <a href="../agv11-4/">Parity Games</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 11.2 -- Reachability Games</title>
      <link href="/AGV/agv11-2/"/>
      <url>/AGV/agv11-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv11-1/">Infinite Games (Basic Definitions)</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Reachability-Condition"><a href="#Reachability-Condition" class="headerlink" title="Reachability Condition"></a>Reachability Condition</h2><p>We will now analyze infinite games for various types of winning conditions. We start with the simple <strong>reachability</strong> condition.</p><p>The reachability condition is given as a set $R$ of positions called the reachability set. The reachability condition is satisfied if the play reaches some position in $R$. Formally, for an infinite word $\alpha$ over $\Sigma$, we use $\text{Occ}(\alpha) :&#x3D; \lbrace\sigma\in\Sigma\mid\exists n\in\mathbb{N}.\ \alpha(n)&#x3D;\sigma\rbrace$ to denote the set of all letters occurring in $\alpha$.</p><blockquote><p>$\textbf{Definition 11.11. } \text{The }\textit{reachability condition }\small\text{REACH} \normalsize(R)\text{ on a set of positions }R\subseteq V\text{ is the set}$</p><p>$$<br>\small\text{REACH} \normalsize(R) &#x3D; \lbrace\rho\in V^\omega\mid\text{Occ}(\rho)\cap R\neq\varnothing\rbrace\newline\newline\text{A game }\mathcal{G}&#x3D;(\mathcal{A},\text{Win})\text{ with Win}&#x3D;\small\text{REACH} \normalsize(R)\text{ is called a }\textit{reachability game}\text{ with reachability set }R<br>$$</p></blockquote><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>$$<br>\text{Position of Player 0: Circles;}\ \ \text{Positions of Player 1: rectangles.}$$ </p><p><img src="/images/notes/uds/agv/11_2_reachability.png"></p><p>$$\mathcal{G}&#x3D;(\mathcal{A},\small\text{REACH} \normalsize(R)),\ R&#x3D;\lbrace v_4,v_5\rbrace<br>$$</p><ul><li>The winning region for Player 0: $W_0(\mathcal{G})&#x3D;\lbrace v_3,v_4,v_5,v_6,v_7,v_8\rbrace$<ul><li>Strategy: $\sigma(v_1) &#x3D; v_2, \sigma(v_3) &#x3D; v_4, \sigma(v_7) &#x3D; v_8, \sigma(v_8) &#x3D; v_5$</li></ul></li></ul><h2 id="Attractor-Construction"><a href="#Attractor-Construction" class="headerlink" title="Attractor Construction"></a>Attractor Construction</h2><p>Reachability games can be solved with a simple fixed point construction called the <strong>attractor construction</strong>.</p><p>The attractor construction computes the winning region for Player 0 iteratively by the <strong>reachability set</strong>:</p><ol><li>adds all positions owned by Player 0 that <strong>have an edge</strong> into the winning region,</li><li>then adds all positions owned by Player 1 where <strong>all edges</strong> lead into the winning region. (no choices)</li><li>Repeats until no more positions can be added.</li></ol><p>In the following, we give a slightly more general definition of the attractor construction that can be applied also to Player 1. We do this in preparation for the constructions for other winning conditions, which will use the attractor construction as a subroutine.</p><blockquote><p>$\textbf{Construction 11.1. } \text{Let an arena }\mathcal{A} &#x3D; (V,V_0,V_1,E)\text{ be given. The }\textit{attractor construction}\text{ on}\newline\mathcal{A}\text{ is defined for each Player }i\text{, for all }n\in\mathbb{N}\text{ and }R\subseteq V\text{ as follows.}$<br>$\begin{array}{lll}<br>\hspace{1cm} \cdot \ CPre^{i}(R) &amp;&#x3D;&amp; \lbrace v\in V_i\mid\exists v‚Äô\in V.(v, v‚Äô)\in E\wedge v‚Äô\in R\rbrace\cup\ \newline<br>&amp;&amp;\lbrace v\in V_{1-i}\mid\forall v‚Äô\in V.(v, v‚Äô)\in E\rightarrow v‚Äô\in R\rbrace\newline<br>\hspace{1cm} \cdot \ Attr_{0}^{i}(R)&amp;&#x3D;&amp;R \newline<br>\hspace{1cm} \cdot \ Attr_{n+1}^{i}(R)&amp;&#x3D;&amp;Attr_{n}^{i}(R)\cup CPre^{i}(Attr_{n}^{i}(R)) \newline<br>\hspace{1cm} \cdot \ Attr^{i}(R)&amp;&#x3D;&amp;\underset{n\in\mathbb{N}}{\bigcup} Attr_{n}^{i}(R)\newline<br>\end{array}$</p></blockquote><h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h3><p><img src="/images/notes/uds/agv/11_2_attractor.png"></p><p>In general, the attractor construction solves a game with winning condition $\small\text{REACH} \normalsize(R)$ as follows: $W_0(\mathcal{G})&#x3D;Attr^0(R), W_1(\mathcal{G})&#x3D;V\setminus W_0(\mathcal{G})$. We can furthermore give a uniform memoryless winning strategy. These results are summarized in the following theorem.</p><blockquote><p>$\textbf{Theorem 11.1. } \textit{Reachability games are memoryless determined. It holds that}\newline W_0(\mathcal{G})&#x3D;Attr^0(R), W_1(\mathcal{G})&#x3D;V\setminus W_0(\mathcal{G})\textit{. Both players have a uniform winning strategy.}$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>We show for all positions $v\in V$ that</p><p>If $v\in Attr^0(R)$, then $v\in W_0(\mathcal{G})$, with the following uniform memoryless strategy $\sigma$:</p><ul><li>We fix an arbitrary total ordering on $V$ . For $v\in (Attr^0(R)\setminus R)\cap V_0$, let $n &#x3D; min\lbrace n\in\mathbb{N}\mid v\in Attr_{n}^0(R)\rbrace$. Then, let $\sigma(v)$ be the smallest $v‚Äô\in Attr_{n-1}^0(R)$ with $(v, v‚Ä≤)\in E$</li><li>For every other position $v\in V_0\setminus(Attr^0(R)\setminus R)$, let $\sigma(v)$ be the smallest $v‚Äô\in V$ with $(v, v‚Ä≤)\in E$</li><li>We show, by induction on $n\in\mathbb{N}$, that any play that starts in $v\in Attr_{n}^0(R)$<br>and is consistent with $\sigma$ reaches $R$ within at most $n$ steps.</li></ul><p>If $v\in V\setminus Attr^0(R)$, then $v\in W_1(\mathcal{G})$, with the following uniform memoryless strategy $\tau$:</p><ul><li>We again fix an arbitrary total ordering on $V$. For $v\in V_1\setminus Attr^0(R)$, let $\tau(v)$ be the smallest $v‚Äô\in V\setminus Attr^0(R)$ such that $(v, v‚Ä≤)\in E$. Such a successor $v‚Äô$ always exists, because otherwise $v\in Attr^0(R)$.</li><li>For every other position $v\in V_1\cap Attr^0(R)$ let $\tau(v)$ be the smallest $v‚Äô\in V\setminus Attr^0(R)$ with $(v, v‚Ä≤)\in E$. Now let $\rho$ be an arbitrary play that is consistent with $\tau$.</li><li>We show, by induction on $n$, that $\rho(n)\notin Attr^0(R)$ and, hence, $\rho(n)\notin R$, for all $n\in\mathbb{N}$.</li></ul><h3 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h3><p><strong>Strategy for Player 0</strong></p><ul><li>A position $v$ belongs to $Attr_{n}^0(R)\setminus R$, must have edges to $v‚Äô\in Attr_{n-1}^0(R)$, then choose the smallest $v‚Äô$</li><li>If a position $v$ does not belong to $Attr^0(R)\setminus R$, simply choose the smallest $v‚Äô$ from its edges.</li></ul><p><strong>Strategy for Player 1</strong></p><ul><li>If a position $v$ does not belong to $Attr_{n}^0(R)$, it must have any one edge does not move to $Attr^0(R)$, choose the smallest $v‚Äô$ among those.</li><li>If a position $v$ belongs to $Attr_{n}^0(R)$, since all its edges move to some positions in $Attr_{n}^0(R)$, simply choose the smallest $v‚Äô$ from its edges.</li></ul><hr><p>Next chapter: <a href="../agv11-3/">B√ºchi Games</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 11.1 -- Infinite Games (Basic Definitions)</title>
      <link href="/AGV/agv11-1/"/>
      <url>/AGV/agv11-1/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv10-5/">From semi-deterministic B√ºchi to deterministic Muller</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>We now introduce <em>infinite two-player games on finite graphs</em>. Infinite games are useful to solve the synthesis problem, where we are interested in finding a strategy that guarantees that a given specification is satisfied (cf. <a href="../agv1.2/">Section 1.2</a>). As we will see, games also play a fundamental role in automata theory, in particular for automata over infinite trees.</p><h2 id="Basic-Definitions"><a href="#Basic-Definitions" class="headerlink" title="Basic Definitions"></a>Basic Definitions</h2><p>The game is played on a graph, called the <strong>arena</strong>. The vertices of the graph are called <strong>positions</strong> and are partitioned into the positions of Player 0 and the positions of Player 1. </p><ul><li>A play of the game starts in some initial position</li><li>In any positions, the player who <strong>owns the position chooses the edge</strong> on which the play is continued.</li><li>Player 0 wins if the play is an element of the <strong>winning condition</strong>.</li></ul><p>The winner is determined by a winning condition, which, like the acceptance condition of an automaton on infinite words is a subset of the infinite words over the positions. </p><blockquote><p>$\textbf{Definition 11.1. } \text{A }\textit{game arena}\text{ is a tuple }\mathcal{A} &#x3D; (V,V_0,V_1,E)\text{, where}\newline\begin{array}{l}<br>\hspace{0.5cm} \cdot \ V_0\text{ and }V_1&#x3D;V\setminus V_0\text{ are disjoint sets of positions,}\newline<br>\hspace{1cm} \text{called the positions of Player 0 and Player 1.}\newline<br>\hspace{0.5cm} \cdot \ E\subseteq V\times V\text{ is a set of edges such that every position }v\in V\newline<br>\hspace{1cm} \text{has at least one outgoing edge }(v,v‚Äô)\in E.\newline<br>\end{array}$</p></blockquote><blockquote><p>$\textbf{Definition 11.2. } \text{A }\textit{play}\text{ is an infinite sequence }  \rho\in V^\omega\text{ such that}$<br>$$\forall n\in\mathbb{N}.(\rho(n),\rho(n+1))\in E$$</p></blockquote><p>We say a play $\rho$ starts in a position $v$ iff $v&#x3D;\rho(0)$. We denote the set of all possible plays on $\mathcal{A}$ with $\text{Plays}(\mathcal{A})$ and the set of all possible plays starting in position $v$ with $\text{Plays}(\mathcal{A},v)$.</p><blockquote><p>$\textbf{Definition 11.3. }\text{A }\textit{game }\mathcal{G}&#x3D;(\mathcal{A},\text{Win})\text{ consists of an arena }\mathcal{A}\text{ and a }\textit{winning condition}\newline\text{Win}\subseteq V^\omega\text{. We call a play }\rho\textit{ winning for Player 0}\text{ iif }\rho\in\text{Win and }\textit{winning for Player 1}\text{ otherwise.}$ </p></blockquote><p>When it is Player $i$‚Äôs turn, the current vertex must be a <strong>position</strong> of Player $i$ ($V_i$), all the prefix of the play seen so far (including current vertex) is called the <strong>history</strong> of the <strong>play</strong>, which is an element of $V^\ast V_i$.</p><p>A <strong>strategy</strong> fixes the decisions of a player based on the <strong>history</strong> of the play. A <strong>strategy</strong> for Player $i$ is a function $\sigma:V^\ast V_i\rightarrow V$ that selects for each such history a successor position.</p><blockquote><p>$\textbf{Definition 11.4. }\text{A }\textit{strategy}\text{ for Player }i\text{ is a function }\sigma:V^\ast V_i\rightarrow V\text{ such that }(v,v‚Äô)\in E\newline\text{whenever }\sigma(wv)&#x3D;v‚Äô\text{ for some }w\in V^\ast,v\in V_i$ </p></blockquote><p>In the following, we use $\sigma$ and $\tau$ to denote strategies for Player $i$ and the opponent Player $(1‚àíi)$, respectively.</p><blockquote><p>$\textbf{Definition 11.5. }\text{A play }\rho\text{ is }\textit{consistent}\text{ with a strategy }\sigma\text{ iff}$<br>$$\forall n\in\mathbb{N}.\text{if }\rho(n)\in V_i\text{ then }\rho(n+1)&#x3D;\sigma(\rho[n])$$</p></blockquote><p>We denote the set of all plays that begin in some position $v$ and are consistent with strategy $\sigma$ with $\text{Plays}(\mathcal{A}, \sigma, v)$. Note that the strategies $\sigma$ and $\tau$ of the two players together uniquely identify a specific play: $\mid \text{Plays}(\mathcal{A}, \sigma, v)\cap \text{Plays}(\mathcal{A}, \tau, v)\mid &#x3D; 1$. </p><p>Our definition of a strategy is very general in the sense that the decisions are based on the entire history of the play. Intuitively, this means that the players have infinite memory. It often suffices to work with simpler strategies, such as <strong>memoryless</strong> strategies. <strong>Memoryless</strong> strategies are often also called <strong>positional</strong>.</p><blockquote><p>$\textbf{Definition 11.6. }\text{A strategy }\sigma\text{ for Player }i\text{ is }\textit{memoryless}\text{ iff }\sigma(wv)&#x3D;\sigma(v)\text{ for all }w\in V^\ast,v\in V_i.$</p></blockquote><p>In a slight abuse of notation, memoryless strategies are often given directly as a function $\sigma:V_i\rightarrow V$ that maps the positions owned by Player $i$ to their successor positions. Next, we characterize <strong>winning</strong> strategies:</p><blockquote><p>$\textbf{Definition 11.7. }\text{A strategy }\sigma\text{ for Player }i\text{ is }\textit{winning}\text{ from a position }v\text{ if all plays that}\newline\text{start in }v\text{ and that are consistent with }\sigma\text{ are winning for Player }i.$</p></blockquote><p>Note that this definition refers to a specific position $v$ in which we start the play. The set of all positions where the player has a winning strategy is called the <strong>winning region</strong>.</p><blockquote><p>$\textbf{Definition 11.8. }\text{ The }\textit{winning region }W_i(\mathcal{G})\text{ of Player }i\text{ in a game }\mathcal{G}\text{ is defined as}\newline\text{the set of positions }v\in V\text{ for which there exists a strategy for Player }i\text{ that is winning from }v.$</p></blockquote><p>Note that the strategies for different positions in the winning region may be different. If a strategy $\sigma$ is winning from all positions of the winning region, we call $\sigma$ a <strong>uniform winning strategy</strong>.</p><p>It is easy to see that no position can be in the winning regions of both players. Otherwise there exists a position $v$ and strategies $\sigma$ and $\tau$ that are winning from $v$ for Player 0 and 1, respectively. Then the unique play that is consistent with $\sigma$ and $\tau$ need to be both in Win, because $\sigma$ is winning, and not in Win, because $\tau$ is winning. </p><p>A more difficult question is whether all positions are in some winning region, i.e., whether the winning regions form a partition of $V$. This property is called the <strong>determinacy</strong> of a game:</p><blockquote><p>$\textbf{Definition 11.9. }\text{A }\textit{game }\mathcal{G}\text{ is }\textit{determined }\text{if }V&#x3D;W_0(\mathcal{G})\cup W_1(\mathcal{G})$</p></blockquote><p>If the winning strategies are in fact memoryless, we say the game is <strong>memoryless</strong> (<strong>positionally</strong>) determined.</p><blockquote><p>$\textbf{Definition 11.10. }\text{A game is }\textit{memoryless determined }\text{if for every position }v\in V\text{, there exists}\newline\text{a memoryless stratey that is winning for some player from position }v.$</p></blockquote><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this section, we have learned:</p><ul><li><p><strong>Arena</strong>: the graph of the game, expressed as a tuple $\mathcal{A}&#x3D;(V,V_0,V_1,E)$</p><ul><li><strong>Position</strong>: vertex of Arena $v\in V$</li><li><strong>Positions of Player $i$</strong>: a disjoint set of position $V_i$</li></ul></li><li><p><strong>Play</strong>: an infinite sequence of $\rho\in V^\omega$</p><ul><li><strong>set of all Plays</strong>: $\text{Plays}(\mathcal{A})$</li><li><strong>set of all Plays in position $v$</strong>: $\text{Plays}(\mathcal{A},v)$</li><li><strong>starting position</strong>: $v &#x3D; \rho(0)$</li><li>the player who <strong>owns the position chooses the edge</strong> on which the play is continued ($\rho\in V_i$)</li></ul></li><li><p><strong>Game</strong>: consist of an arena and a winning condition $\mathcal{G}&#x3D;(\mathcal{A},\text{Win})$</p><ul><li><strong>winning condition</strong>: $\text{Win}\subseteq V^\omega$</li><li><strong>winning play for Player 0</strong>: $\rho\in\text{Win}$</li><li><strong>winning play for Player 1</strong>: $\rho\notin\text{Win}$</li></ul></li><li><p><strong>history</strong>: all previous positions $V^\ast$</p></li><li><p><strong>Strategy</strong>: decisions of a player based on history of the play</p><ul><li><strong>Strategy of Player $i$</strong>: $\sigma:V^\ast V_i\rightarrow V$</li><li><strong>Strategy of Player 0</strong>: $\sigma$</li><li><strong>Strategy of Player 1</strong>: $\tau$</li></ul></li><li><p><strong>Memoryless (positional) Strategy</strong>: $\sigma(wv)&#x3D;\sigma(v)\text{ for all }w\in V^\ast,v\in V_i$</p></li><li><p><strong>Winning Region</strong>: set of all positions that Player $i$ has a winning strategy $W_i(\mathcal{G})\in V$  </p><ul><li><strong>Uniform Winning Strategy</strong>: one strategy that can apply to any position in a winning region.</li></ul></li><li><p><strong>Determinacy</strong>: $\mathcal{G}$ is determined if every position is in some player‚Äôs winning region $V&#x3D;W_0(\mathcal{G})\cup W_1(\mathcal{G})$</p><ul><li>A determined game have winning strategy in every positions.</li></ul></li><li><p><strong>Memoryless Game</strong>: all strategies are memoryless in every position of a determined game</p></li></ul><hr><p>Next chapter: <a href="../agv11-2/">Reachability Games</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 10.5 -- From semi-deterministic B√ºchi to deterministic Muller</title>
      <link href="/AGV/agv10-5/"/>
      <url>/AGV/agv10-5/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv10-4/">Semi-Deterministic B√ºchi Automata</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>From the semi-deterministic B√ºchi automaton we now build a deterministic Muller automaton. The idea of the construction is to continuously simulate, in the deterministic automaton, the nondeterministic part of the semi-deterministic automaton and to ‚Äùattempt‚Äù a transition into the deterministic part whenever possible.</p><p>In the state of the deterministic automaton we maintain an ‚Äúarray‚Äù of states that correspond to these attempts. Along each run of the automaton, there may of course be infinitely many such attempts; we only need a finite array, however, because we do not need to keep track of two different attempts to enter the deterministic part, if they both reach the same state (in this case, we simply track the attempt that entered the deterministic part earlier). </p><p>We use an array of size $2m$, where m is the number of states of the deterministic part. The factor two allows us to leave a position of the array empty (‚Äú‚ê£‚Äù) if an attempt is not continued. This is necessary to distinguish a situation where a previously started attempt failed and, at the same time, a new attempt enters the deterministic part, from the situation where the same attempt ran continuously. The deterministic automaton accepts if there is at least one attempt that runs forever after some point and reaches an accepting state infinitely often.</p><hr><p>Next chapter: <a href="../agv11-1/">Infinite Games (Basic Definitions)</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 10.4 -- Semi-Deterministic B√ºchi Automata</title>
      <link href="/AGV/agv10-4/"/>
      <url>/AGV/agv10-4/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv10-3/">Closure Properties of Muller automata Under Boolean Operations</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>To prove McNaughton‚Äôs theorem, in this subsection, we will introdue the <strong>semi-deterministic B√ºchi automata</strong>.</p><ol><li>translate nondeterministic B√ºchi automata into semi-deterministic B√ºchi automata.</li><li>translate from semi-deterministic B√ºchi automata to deterministic Muller automata.</li></ol><h2 id="Semi-deterministic-Buchi-Automata"><a href="#Semi-deterministic-Buchi-Automata" class="headerlink" title="Semi-deterministic B√ºchi Automata"></a>Semi-deterministic B√ºchi Automata</h2><p>A <em>semi-deterministic automaton</em> is a (possibly nondeterministic) automaton where all accepting runs ultimately end up in a <strong>subset of the states</strong> from which all transitions are deterministic.</p><blockquote><p>$\textbf{Definition 10.2. } \text{A B√ºchi automata }\mathcal{A} &#x3D; (\Sigma,Q,I,T,\small\text{B√úCHI} \normalsize(F))\text{ is }\textit{semi-deterministic}\text{ if}\newline Q &#x3D; N \uplus D\text{ is a partition of }Q\text{ such that }F\subseteq D, pr_2(T\cap(D\times\Sigma\times Q))\subseteq D\text{, and }\newline(\Sigma,D,\lbrace d\rbrace,T\cap(D\times\Sigma\times D),\small\text{B√úCHI}\normalsize(F)) \text{ is deterministic for every }d\in D.$</p></blockquote><h3 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h3><p>$Q &#x3D; N \uplus D:$ a <em>disjoint union symbol</em> $\uplus$ indicates that $N$ and $D$ are two seperated subset.</p><p>$D:$ firstly, set of accepting states in part of $D$ ($F\subseteq D$). Then for all transistion starts from $D$ ($T\cap(D\times\Sigma\times Q)$), their successors are also in $D$ ($pr_2(T\cap(D\times\Sigma\times Q))\subseteq D$).</p><p>Therefore, we can split such automaton into nondeterministic part $N$ and determinstic part $D$, and the accepting run will end up stays in $D$.</p><h2 id="From-Nondeterministic-to-Semi-deterministic-Buchi-Automata"><a href="#From-Nondeterministic-to-Semi-deterministic-Buchi-Automata" class="headerlink" title="From Nondeterministic to Semi-deterministic B√ºchi Automata"></a>From Nondeterministic to Semi-deterministic B√ºchi Automata</h2><p>The translation is based on a <strong>subset construction</strong>, where we collect two sets of states:</p><ol><li>the states that are reachable on the given input word, and</li><li>the states that are reachable on some path through an accepting state.</li></ol><p>A state of the semi-deterministic automaton is accepting if the <strong>two sets become equal</strong>; when this happens, the second set is reinitialized with the subset of accepting states that appear in the first component.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p><img src="/images/notes/uds/agv/10_4_nonde.png"></p><p><img src="/images/notes/uds/agv/10_4_subset.png"></p><p>The subset construction produces a <em>deterministic</em> automaton that accepts a subset of the words accepted by the original automaton. If the two sets are equal infinitely often, we can construct a run of the original automaton that goes through accepting states infinitely often:</p><p>intuitively, we can go ‚Äúbackwards‚Äù from each position where the two sets have become equal and select a path segment for the original automaton where an accepting state is visited (in the proof below we give a more precise argument using K√∂nig‚Äôs lemma).</p><p>There is no general guarantee that the set of reachable states from some position of an accepting run and the set of states reachable on a path through some accepting state are the same. This is illustrated by the following example.</p><p><img src="/images/notes/uds/agv/10_4_counter.png"></p><p>Let the input word be $\alpha^\omega$. From the initial position of some run, which starts in the initial state $p$, all states are reachable, but only $r$ and $s$ are reachable on paths from $s$.</p><p>Ultimately, however, every accepting run must reach (and remain in) positions where the <strong>set of reachable states</strong> and the <strong>set of states reachable on a path through some accepting state</strong> are the same. This is because the set of reachable states can only become smaller finitely often; hence, at some point, the set of reachable states will remain the same from all subsequent positions, including those (future) positions of the accepting run where the run visits an accepting state.</p><p>In our semi-deterministic automaton, we therefore start by simulating the given nondeterministic automaton. At any point we allow a nondeterministic transition into the (from then on) deterministic subset construction.</p><blockquote><p>$\textbf{Construction 10.5. } \text{For a B√ºchi automaton }\mathcal{A}&#x3D;(\Sigma,Q,I,T,\small\text{B√úCHI}\normalsize (F))\text{, we construct the semi-}\newline\text{deterministic B√ºchi automaton }\mathcal{A‚Äô} &#x3D; (\Sigma,Q‚Äô,I‚Äô,T‚Äô,\small\text{B√úCHI}\normalsize (F‚Äô))\text{ with }\mathcal{L}(\mathcal{A‚Äô})&#x3D;\mathcal{L}(\mathcal{A})\text{ as follows:}$<br>$\begin{array}{l}<br>\hspace{1cm} \cdot \ Q‚Äô&#x3D;Q\uplus (2^Q\times2^Q)\newline<br>\hspace{1cm} \cdot \ I‚Äô&#x3D;I‚Äô \newline<br>\hspace{1cm} \cdot \ T‚Äô&#x3D;T\cup\lbrace(q,\sigma,(\lbrace q‚Äô\rbrace,\varnothing))\mid(q,\sigma,q‚Äô)\in T\rbrace \newline<br>\hspace{2.85cm}\cup \ \lbrace((L_1,L_2),\sigma,(L‚Äô_1,L‚Äô_2))\mid L_1\neq L_2\newline<br>\hspace{3.8cm}L‚Äô_1&#x3D;pr_2(T\cap L_1\times\lbrace\sigma\rbrace\times Q)\newline<br>\hspace{3.8cm}L‚Äô_2&#x3D;pr_2(T\cap L_1\times\lbrace\sigma\rbrace\times F)\cup pr_2(T\cap L_2\times\lbrace\sigma\rbrace\times Q)\rbrace\newline<br>\hspace{2.85cm}\cup \ \lbrace((L_1,L_2),\sigma,(L‚Äô_1,L‚Äô_2))\mid L_1&#x3D; L_2\newline<br>\hspace{3.8cm}L‚Äô_1&#x3D;pr_2(T\cap L_1\times\lbrace\sigma\rbrace\times Q)\newline<br>\hspace{3.8cm}L‚Äô_2&#x3D;pr_2(T\cap L_1\times\lbrace\sigma\rbrace\times F)\newline<br>\hspace{1cm} \cdot \ F‚Äô&#x3D;\lbrace(L,L)\in(2^Q\times2^Q)\mid L\neq\varnothing\rbrace\newline<br>\end{array}$</p></blockquote><blockquote><p>$\textbf{Lemma 10.1. } \textit{For every B√ºchi automaton }\mathcal{A}\textit{ there exists a semi-deterministic B√ºchi}\newline\textit{automaton }\mathcal{A‚Äô}\textit{ with }\mathcal{L}(\mathcal{A})&#x3D;\mathcal{L}(\mathcal{A‚Äô}).$</p></blockquote><h2 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h2><p>$\mathcal{L}(\mathcal{A‚Äô})\subseteq\mathcal{L}(\mathcal{A})$</p><p>Let $\alpha\in\mathcal{L}(\mathcal{A‚Äô})$ and let $r‚Äô&#x3D;q_0q_1\dots q_{n-1}(L_n,L‚Äô<em>n)(L</em>{n+1},L‚Äô<em>{n+1})\dots$ be an accepting run of $\mathcal{A‚Äô}$ on $\alpha$. Since $r‚Äô$ is accepting, there is an infinite sequence $i_0i_1\dots$ of indices such that $i_0&#x3D;n$, and, for all $j\geq1$, $L</em>{i_j} &#x3D; L‚Äô<em>{i_j}$ and $L‚Äô</em>{i_j}\neq\varnothing$. For every $j\geq1$, and every $q‚Äô\in L_{i_j}$ there exists a state $q\in L_{i_{j‚àí1}}$ and a sequence $q &#x3D; q_{i_{j‚àí1}} , q_{i_{j‚àí1}+1},\dots, q_{i_j} &#x3D; q‚Äô$ such that $(q_k, \alpha(k), q_{k+1})\in T$ for all $k\in \lbrace i_{j‚àí1},\dots,i_j ‚àí 1\rbrace$ and $q_k\in F$ for some $k\in\lbrace i_{j‚àí1}+1,\dots,i_j\rbrace$. We use the following notation: $\textit{predecessor}(q‚Äô,i_j) :&#x3D; q, \textit{run}(q‚Äô,i_0) &#x3D; q_0q_1\dots q_{n‚àí1}q‚Äô$ for $L_{i_0} &#x3D; \lbrace q‚Äô\rbrace$, and $\textit{run}(q‚Äô,i_j)&#x3D;(q_{i_{j‚àí1}+1})(q_{i_{j‚àí1}+2})\dots q_{i_j}$, for $j\geq1$. </p><p>Now consider the  j‚ààN Lij √ó {j} -labeled tree where the root is labeled with (q ‚Ä≤ , 0) for Li0 &#x3D; {q ‚Ä≤}, and the parent of each node with a label (q ‚Ä≤ , j) is labeled with (predecessor(q ‚Ä≤ , ij ), j ‚àí 1). The tree is infinite and finite-branching, and, hence, by K¬®onig‚Äôs Lemma, has an infinite branch (qi0 , i0),(qi1 , i1), . . ., corresponding to an accepting run of A: run(qi0 , i0) ¬∑ run(qi1 , i1) ¬∑ run(qi2 , i2) ¬∑ . . . </p><p>L(A) ‚äÜ L(A‚Ä≤ ): Let Œ± ‚àà L(A) and let r &#x3D; q0, q1, . . . be an accepting run of A on Œ±. Let i ‚àà N be an index s.t. qi ‚àà F and for all j ‚â• i there exists a k &gt; j, such that {q ‚àà Q | qi Œ±[i,k] ‚àí‚àí‚àí‚Üí q} &#x3D; {q ‚àà Q | qj Œ±[j,k] ‚àí‚àí‚àí‚Üí q}. The index i exists: ‚Äù‚äá‚Äù holds for all i, because there is a path through qj . Assume, by way of contradiction, that for all i ‚àà N, there is a j ‚â• i s.t for all k &gt; j ‚Äù‚äã‚Äù holds. Then there exists an i ‚Ä≤ s.t. {q ‚àà Q | qi ‚Ä≤ Œ±[i ‚Ä≤ ,k] ‚àí‚àí‚àí‚àí‚Üí q} &#x3D; ‚àÖ for all k &gt; i‚Ä≤ . Contradiction. We define a run r ‚Ä≤ of A‚Ä≤ : r ‚Ä≤ &#x3D; q0 . . . qi‚àí1({qi}, ‚àÖ)(L1, L‚Ä≤ 1 )(L2, L‚Ä≤ 2 ). . . where Lj and L ‚Ä≤ j are determined by the definition of A‚Ä≤ . To prove that r ‚Ä≤ is accepting, assume otherwise, and let m ‚àà N be an index such that Ln Ã∏&#x3D; L ‚Ä≤ n for all n ‚â• m. Then, let j &gt; m be some index with qj ‚àà F; hence qj ‚àà L ‚Ä≤ j . There exists a k &gt; j such that L ‚Ä≤ k+1 &#x3D; {q ‚àà Q | qj Œ±[j,k] ‚àí‚àí‚àí‚Üí q} &#x3D; {q ‚àà Q | qi Œ±[i,k] ‚àí‚àí‚àí‚Üí q} &#x3D; Lk+1. Contradiction.</p><hr><p>Next chapter: <a href="../agv10-5/">From semi-deterministic B√ºchi to deterministic Muller</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Appium commands that are commonly used on Mac</title>
      <link href="/appium/"/>
      <url>/appium/</url>
      
        <content type="html"><![CDATA[<p>In this example, we will use <a href="https://github.com/appium/appium-inspector">Appium Inspector</a> to start a seesion on your emulator on <a href="https://developer.android.com/studio">Android Studio</a>.</p><h2 id="Start-appium"><a href="#Start-appium" class="headerlink" title="Start appium"></a>Start appium</h2><p><img src="/images/coding/appium/start.png"></p><p>First, start the connection with Appium by <code>cmd appium --allow-cors</code>. It also gives you the <code>remote url</code> and the <code>automationName</code> that can be used in the <a href="https://github.com/appium/appium-inspector">Appium Inspector</a></p><p><img src="/images/coding/appium/inspector.png"></p><h2 id="Start-Session"><a href="#Start-Session" class="headerlink" title="Start Session"></a>Start Session</h2><ul><li><strong>deviceName</strong>:  <code>adb devices</code></li><li><strong>platformName</strong> - <code>appium driver list</code></li><li><strong>platformVersion</strong> -  <code>adb shell getprop ro.build.version.release</code></li></ul><p><img src="/images/coding/appium/session.png"></p><p><img src="/images/coding/appium/inspector2.png"></p><p>Now you can start a session in your emulator, but it always begins from the home page. To directly start a session on certain App, you also need to provide the  <code>appPackage</code> and the <code>appActivity</code>.</p><h2 id="Session-with-Apps"><a href="#Session-with-Apps" class="headerlink" title="Session with Apps"></a>Session with Apps</h2><p>If your app is downloaded from the PlayStore. It is possible that the apk file name&#x2F;path is hidden. However, you can You can simply open the app and check its name by <code>adb shell dumpsys window | grep mCurrentFocus</code>.</p><p>It returns the <code>appPackage</code> and the current <code>appActivity</code> of the App, which are both necessary for our seesion to start. However, sometimes the current activity may not be directly opened. Then we need to check all the possible activities this App contans and try them out.</p><p>To check the activity list, we can use <code>adb shell dumpsys package YOUR_APP_appPackage | grep -i activity</code>.</p><p><img src="/images/coding/appium/activity.png"></p><p>Now, we can start our emulator, and run the command <code>adb shell am start -n YOUR_APP_appPackage/YOUR_APP_appActivity</code> to see whether it can start the App successfully. If it works we can use it in our inspector.</p><p><img src="/images/coding/appium/cici.png"></p>]]></content>
      
      
      <categories>
          
          <category> Coding </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Appium </tag>
            
            <tag> Automation </tag>
            
            <tag> App Testing </tag>
            
            <tag> Android </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Automata, Games, and Verification (Portal)</title>
      <link href="/AGV/agv/"/>
      <url>/AGV/agv/</url>
      
        <content type="html"><![CDATA[<blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1. Introduction"></a>Chapter 1. Introduction</h2><table><thead><tr><th align="left">Sections</th><th align="left">Exercise</th></tr></thead><tbody><tr><td align="left"><a href="../agv1-1/">1.1. Model Checking</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv1-2/">1.2. Synthesis</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv1-3/">1.3. The Logic-Automata Connection</a></td><td align="left"></td></tr></tbody></table><h2 id="Chapter-2-Buchi-Automata"><a href="#Chapter-2-Buchi-Automata" class="headerlink" title="Chapter 2. B√ºchi Automata"></a>Chapter 2. B√ºchi Automata</h2><table><thead><tr><th align="left">Sections</th><th align="left">Exercise</th></tr></thead><tbody><tr><td align="left"><a href="../agv2-1/">2.1. Preliminaries</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv2-2/">2.2. Automata over Infinite Words</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv2-3/">2.3. The B√ºchi Acceptance Condition</a></td><td align="left"></td></tr></tbody></table><h2 id="Chapter-3-Buchi‚Äôs-Characterization-Theorem"><a href="#Chapter-3-Buchi‚Äôs-Characterization-Theorem" class="headerlink" title="Chapter 3. B√ºchi‚Äôs Characterization Theorem"></a>Chapter 3. B√ºchi‚Äôs Characterization Theorem</h2><table><thead><tr><th align="left">Sections</th><th align="left">Exercise</th></tr></thead><tbody><tr><td align="left"><a href="../agv3-1/">3.1. Kleene‚Äôs Theorem</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv3-2/">3.2. $\omega$-regular language</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv3-3/">3.3 Closure Properties of the B√ºchi-recognizable languages (Intersection and Union)</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv3-4/">3.4 Closure Properties of the B√ºchi-recognizable languages (Concatenations)</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv3-5/">3.5 B√ºchi‚Äôs Characterization Theorem</a></td><td align="left"></td></tr></tbody></table><h2 id="Chapter-4-Deterministic-Buchi-Automata"><a href="#Chapter-4-Deterministic-Buchi-Automata" class="headerlink" title="Chapter 4. Deterministic B√ºchi Automata"></a>Chapter 4. Deterministic B√ºchi Automata</h2><table><thead><tr><th align="left">Sections</th><th align="left">Exercise</th></tr></thead><tbody><tr><td align="left"><a href="../agv4-1/">4.1. Deterministic vs. Nondeterministic B√ºchi Automata</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv4-2/">4.2. Complementation of deterministic B√ºchi Automata</a></td><td align="left"></td></tr></tbody></table><h2 id="Chapter-5-Complementation-of-Buchi-automata"><a href="#Chapter-5-Complementation-of-Buchi-automata" class="headerlink" title="Chapter 5. Complementation of B√ºchi automata"></a>Chapter 5. Complementation of B√ºchi automata</h2><table><thead><tr><th align="left">Sections</th><th align="left">Exercise</th></tr></thead><tbody><tr><td align="left"><a href="../agv5-1/">5.1. Infinite Directed Acyclic Graph (DAG)</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv5-2/">5.2. Ranking of DAG</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv5-3/">5.3. Complement B√ºchi Automaton with Odd Ranking</a></td><td align="left"></td></tr></tbody></table><h2 id="Chapter-6-Logics-over-Infinite-Sequences"><a href="#Chapter-6-Logics-over-Infinite-Sequences" class="headerlink" title="Chapter 6. Logics over Infinite Sequences"></a>Chapter 6. Logics over Infinite Sequences</h2><table><thead><tr><th align="left">Sections</th><th align="left">Exercise</th></tr></thead><tbody><tr><td align="left"><a href="../agv6-1/">6.1. Linear-Time Temporal Logic (LTL)</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv6-2/">6.2. Expressing Program Properties using LTL</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv6-3/">6.3. LTL and Counting Languages</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv6-4/">6.4. Quantified Propositional Temporal Logic (QPTL)</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv6-5/">6.5. Monadic Second-Order Logic of One Successor (S1S)</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv6-6/">6.6. Express QPTL using S1S</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv6-7/">6.7. S1S$_0$ and B√ºchi-recognizable LanguageB√ºchi-recognizable</a></td><td align="left"></td></tr></tbody></table><h2 id="Chapter-7-Alternating-Buchi-Automata"><a href="#Chapter-7-Alternating-Buchi-Automata" class="headerlink" title="Chapter 7. Alternating B√ºchi Automata"></a>Chapter 7. Alternating B√ºchi Automata</h2><table><thead><tr><th align="left">Sections</th><th align="left">Exercise</th></tr></thead><tbody><tr><td align="left"><a href="../agv7-1/">7.1. Alternating B√ºchi Automata</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv7-2/">7.2. From LTL to Alternating B√ºchi Automata</a></td><td align="left"><a href="../agv7-2/">$\varphi&#x3D;(\Diamond p)\ \mathcal{U}\ (\square q)$</a></td></tr><tr><td align="left"><a href="../agv7-3/">7.3. Translating Alternating to Nondeterministic automata</a></td><td align="left"></td></tr></tbody></table><h2 id="Chapter-8-Linear-Arithmetic"><a href="#Chapter-8-Linear-Arithmetic" class="headerlink" title="Chapter 8. Linear Arithmetic"></a>Chapter 8. Linear Arithmetic</h2><table><thead><tr><th align="left">Sections</th><th align="left">Exercise</th></tr></thead><tbody><tr><td align="left"><a href="../agv8-1/">8.1. Linear Arithmetic (Theory)</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv8-2/">8.2 Encoding real numbers</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv8-3/">8.3 Translation from Linear Arithmetic to Automata</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv8-4/">8.4 Homogenous Inequality Testing is Automatic</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv8-5/">8.5 From Linear Arithmetic to Automata</a></td><td align="left"></td></tr></tbody></table><h2 id="Chapter-9-LTL-Model-Checking"><a href="#Chapter-9-LTL-Model-Checking" class="headerlink" title="Chapter 9. LTL Model Checking"></a>Chapter 9. LTL Model Checking</h2><table><thead><tr><th align="left">Sections</th><th align="left">Exercise</th></tr></thead><tbody><tr><td align="left"><a href="../agv9-1/">9.1 Automata-based LTL Model Checking with Sequential Circuits</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv9-2/">9.2 Nested depth-first search</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv9-3/">9.3 The Emerson-Lei algorithm</a></td><td align="left"></td></tr></tbody></table><h2 id="Chapter-10-McNaughton‚Äôs-Theorem"><a href="#Chapter-10-McNaughton‚Äôs-Theorem" class="headerlink" title="Chapter 10. McNaughton‚Äôs Theorem"></a>Chapter 10. McNaughton‚Äôs Theorem</h2><table><thead><tr><th align="left">Sections</th><th align="left">Exercise</th></tr></thead><tbody><tr><td align="left"><a href="../agv10-1/">10.1 The Muller Acceptance Condition</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv10-2/">10.2 From B√ºchi automata to Muller automata</a></td><td align="left"></td></tr><tr><td align="left"><a href="../agv10-3/">10.3 Closure Properties of Muller Automata under Boolean Operations</a></td><td align="left"></td></tr></tbody></table><hr><p>Next chapter: <a href="../agv/"></a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cantonese Ch.1-6 -- Tones</title>
      <link href="/Canto/canto1-6/"/>
      <url>/Canto/canto1-6/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Golden Rule of becoming a native Cantonese speaker: <strong>Tones</strong> &gt; Everything!</p></blockquote><p>In this blog, we use <a href="https://jyutping.org/en/docs/english/">Jyutping</a> to indicate the pronunciation of Cantonese characters.</p><p>Previous lesson: <a href="../canto1-3/">Rimes with e</a></p><hr><p>In this lesson, we talk about Rimes with <code>u</code>, <code>yu</code>. Here we use <code>u</code> similar to languages like German or Italian.</p><p>And <code>yu</code> is equivalent to ‚Äú√º‚Äù in German. Let‚Äôs take a look.</p><h2 id="Rimes-with-u"><a href="#Rimes-with-u" class="headerlink" title="Rimes with u"></a>Rimes with <code>u</code></h2><p>For <code>u</code>, <code>ui</code>, <code>un</code>, <code>ut</code>, u sounds like ‚Äúoo‚Äù in ‚Äúfoo‚Äù.</p><p>For <code>ung</code> and <code>uk</code>, u sound like ‚Äúone‚Äù in ‚Äútone‚Äù.</p><table><thead><tr><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th></tr></thead><tbody><tr><td align="left">u</td><td align="left">oo in foo</td><td align="left"><ruby>Â§´<rp>(</rp><rt>fu1</rt><rp>)</rp></ruby></td><td align="left">ut</td><td align="left">oot in boot</td><td align="left"><ruby>Èóä<rp>(</rp><rt>fut3</rt><rp>)</rp></ruby></td></tr><tr><td align="left">ui</td><td align="left">ewy in chewy<sup>1</sup></td><td align="left"><ruby>ÁÅ∞<rp>(</rp><rt>fui1</rt><rp>)</rp></ruby></td><td align="left">ung</td><td align="left">one in tone</td><td align="left"><ruby>È¢®<rp>(</rp><rt>fung1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">un</td><td align="left">oon in cartoon</td><td align="left"><ruby>Ê≠°<rp>(</rp><rt>fun1</rt><rp>)</rp></ruby></td><td align="left">uk</td><td align="left">ook in cook</td><td align="left"><ruby>Á¶è<rp>(</rp><rt>fuk1</rt><rp>)</rp></ruby></td></tr></tbody></table><p><sup>1</sup>‚ÄúChewy‚Äù is two syllables, but in Cantonese this is a diphthong. So try to blend it into one sound, treat the ‚Äúew‚Äù as the major sound and the ‚Äúj‚Äù as a small tip at the end of the syllable.</p><h2 id="Rimes-with-yu"><a href="#Rimes-with-yu" class="headerlink" title="Rimes with yu"></a>Rimes with <code>yu</code></h2><p>Unfortunately, in English there is no word sound exactly as <code>yu</code>.</p><p>But you can imitate it by positioning your tongue more forward, closer to your front teeth (not touching them!), and try to say the word ‚Äúfoo‚Äù.</p><p>In some accents, when people say the word ‚Äúo<strong>ccu</strong>py‚Äù or ‚Äúe<strong>du</strong>cation‚Äù, they may use the <code>yu</code> sound as well.</p><table><thead><tr><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th></tr></thead><tbody><tr><td align="left">yu</td><td align="left">u in occupy</td><td align="left"><ruby>Êõ∏<rp>(</rp><rt>syu1</rt><rp>)</rp></ruby></td><td align="left">yut</td><td align="left">uned in tuned</td><td align="left"><ruby>Èõ™<rp>(</rp><rt>syut3</rt><rp>)</rp></ruby></td></tr><tr><td align="left">yun</td><td align="left">une in tune</td><td align="left"><ruby>ÈÖ∏<rp>(</rp><rt>syun1</rt><rp>)</rp></ruby></td><td align="left"></td><td align="left"></td><td align="left"></td></tr></tbody></table><p>Next lesson: <a href="../canto1-6/">Tones</a></p><hr><p>Further reading: <a href="https://jyutping.org/en/">Jyutping</a>, <a href="https://lshk.org/">The linguistic Society of Hong Kong</a></p>]]></content>
      
      
      <categories>
          
          <category> Cantonese </category>
          
          <category> Full_Course </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cantonese </tag>
            
            <tag> Language Learning </tag>
            
            <tag> Phonology </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV -- (Exercise 7.2) LTL to Alternating B√ºchi Automata</title>
      <link href="/AGV/agv7-2-eg/"/>
      <url>/AGV/agv7-2-eg/</url>
      
        <content type="html"><![CDATA[<p>Previous Exercise: <a href=""></a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><p>This is an example exercise to express LTL formula into Alternating B√ºchi Automata. For further definitions, you may check <a href="../agv7-2/">Section 7.2</a>.</p><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><p>Use the <a href="../agv7-2/">construction from the lecture</a> to construct an alternating B√ºchi automaton $\mathcal{A}$ such that $$\mathcal{L(A)&#x3D;L}((\Diamond p)\ \mathcal{U}\ (\square q))$$</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>we build the following alternating B√ºchi automaton  $\mathcal{A} &#x3D; (2^{p,q},Q,\varphi,\delta,\small\text{B√úCHI} \normalsize(F))$ which recognizes the models of $\varphi&#x3D;(\Diamond p)\ \mathcal{U}\ (\square q)$. First we consider the transition function $\delta$ for an arbitrary symbol $a\in2^{p,q}:$</p><p>$\begin{array}{lll}<br>\hspace{1cm}\bullet &amp;&amp;\delta(\square q,a)\newline<br>&amp;&#x3D;&amp;\delta(\neg(\textit{true}\ \mathcal{U}\ \neg q) ,a)\newline<br>&amp;&#x3D;&amp;\overline{\delta(\textit{true}\ \mathcal{U}\ \neg q ,a)}\newline<br>&amp;&#x3D;&amp;\overline{\delta(\neg q,a)\vee(\delta(\textit{true},a)\wedge(\textit{true}\ \mathcal{U}\ \neg q))}\newline<br>&amp;&#x3D;&amp;\overline{\delta(\neg q,a)}\wedge\overline{(\delta(\textit{true},a)\wedge (\textit{true}\ \mathcal{U}\ \neg q))}&amp;(\textit{true}\wedge \psi&#x3D;\psi)\newline<br>&amp;&#x3D;&amp;\overline{\delta(\neg q,a)}\wedge\overline{(\textit{true}\ \mathcal{U}\ \neg q)}&amp;(\text{Using line 1})\newline<br>&amp;&#x3D;&amp;\overline{\delta(\neg q,a)}\wedge\square q\newline<br>&amp;&#x3D;&amp;\left\lbrace \begin{array}{lll}<br>\square q&amp;\text{if }q\in a\newline<br>\textit{false}&amp;\text{if }q\notin a\newline<br>\end{array}\right.<br>\end{array}<br>\ \newline \ \newline<br>\begin{array}{lll}<br>\hspace{1cm}\bullet &amp;&amp;\delta(\Diamond p,a)\newline<br>&amp;&#x3D;&amp;\delta(\textit{true}\ \mathcal{U}\ p ,a)\newline<br>&amp;&#x3D;&amp;\delta(p,a)\vee(\delta(\textit{true},a)\wedge\Diamond p)&amp;(\textit{true}\wedge \psi&#x3D;\psi)\newline<br>&amp;&#x3D;&amp;\delta(p,a)\vee\Diamond p\newline<br>&amp;&#x3D;&amp;\left\lbrace \begin{array}{lll}<br>\Diamond p&amp;\text{if }p\notin a\newline<br>\textit{true}&amp;\text{if }p\in a\newline<br>\end{array}\right.<br>\end{array}<br>$</p><p>By Substitution above result into $\delta((\Diamond p)\ \mathcal{U}\ (\square q),a)&#x3D;\delta(\square q,a)\vee(\delta(\Diamond p,a)\wedge(\Diamond p)\ \mathcal{U}\ (\square q))$, we have:</p><p>$$\delta((\Diamond p)\ \mathcal{U}\ (\square q),a)&#x3D;\left\lbrace<br>\begin{array}{lll}<br>\Diamond p\wedge((\Diamond p)\ \mathcal{U}\ (\square q))&amp;\text{if }a &#x3D;\varnothing &amp;(\vee\ \textit{false}\text{ is omitted.})\newline<br>(\Diamond p)\ \mathcal{U}\ (\square q)&amp;\text{if }a &#x3D;\lbrace p\rbrace&amp;(\wedge\ \textit{true}\text{ is omitted.})\newline<br>\square q\vee(\Diamond p\wedge((\Diamond p)\ \mathcal{U}\ (\square q)))&amp;\text{if }a &#x3D;\lbrace q\rbrace\newline<br>\square q\vee((\Diamond p)\ \mathcal{U}\ (\square q))&amp;\text{if }a &#x3D;\lbrace p,q\rbrace&amp;(\wedge\ \textit{true}\text{ is omitted.})\newline<br>\end{array}\right.$$</p><p>For each case, when we see $\vee$, that‚Äôs a <strong>nondeterministic transitions</strong>, we need draw two seperate transitions for each successors. On the other hand $\wedge$ is a <strong>universal transitions</strong>, it is a single transition towards both successors, we split the extra branches from the path to indicate that. Thus we have the following automaton $\mathcal{A}$:</p><p><img src="/images/notes/uds/agv/7_2_eg.png"></p><hr><p>Next Exercise: <a href="../agv/"></a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 10.3 -- Closure Properties of Muller automata Under Boolean Operations</title>
      <link href="/AGV/agv10-3/"/>
      <url>/AGV/agv10-3/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv10-2/">From B√ºchi automata to Muller automata</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>We now show that deterministic Muller automata are closed, like nondeterministic B√ºchi automata, under the Boolean operations (<code>complementation</code>, <code>union</code>, and <code>intersection</code>).</p><p>First we introduce the construction of these automaton with operations, then we will prove they are close by the runs under those constructions.</p><h2 id="Automata-construction-of-Complementation"><a href="#Automata-construction-of-Complementation" class="headerlink" title="Automata construction of Complementation"></a>Automata construction of Complementation</h2><blockquote><p>$\textbf{Construction 10.3. } \text{Let }\mathcal{A} &#x3D; (\Sigma,Q,I,T,\small\text{MULLER} \normalsize (\mathcal{F}))\text{ be a complete and deterministic Muller}\newline\text{automaton, where we assume w.l.o.g that }Q\neq\varnothing.\text{ We construct the deterministic Muller}\newline\text{automaton }\mathcal{A}^C &#x3D; (\Sigma,Q,I,T,\small\text{MULLER} \normalsize(2^Q\setminus\mathcal{F}))\text{ with }\mathcal{L(A^C)}&#x3D;\Sigma\setminus\mathcal{L(A)}.$</p></blockquote><h2 id="Automata-construction-of-Intersection"><a href="#Automata-construction-of-Intersection" class="headerlink" title="Automata construction of Intersection"></a>Automata construction of Intersection</h2><p>We use the function $pr_n$ for $n\in\mathbb{N}$ to project to the (n+1)th component of a arbitrary length tuple, for example:</p><ul><li>$pr_0(x, y)&#x3D;x$</li><li>$pr_1(x, y)&#x3D;y$</li><li>$pr_2(x, y),pr_3(x, y),\dots pr_n(x, y) &#x3D;\text{Undefined}$</li></ul><p>We can also apply the projection to a set and return a <strong>set of components</strong>: $pr_n(S) &#x3D; \bigcup_{s‚ààS}{pr_n(s)}.$</p><blockquote><p>$\textbf{Construction 10.4. } \text{For Muller automata }\mathcal{A_1} &#x3D; (\Sigma,Q,I,T,\small\text{MULLER} \normalsize (\mathcal{F_1}))\text{ and}\newline\mathcal{A_2} &#x3D; (\Sigma,Q,I,T,\small\text{MULLER} \normalsize (\mathcal{F_2}))\text{ over the same alphabet }\Sigma.\text{ We construct the Muller Automaton}\newline\mathcal{A}_\cap &#x3D; (\Sigma,Q_1\times Q_2,I_1\times I_2,T_\cap,\small\text{MULLER} \normalsize(\mathcal{F_\cap}))\text{ with }\mathcal{L(A_\cap)}&#x3D;\mathcal{L(A_1)}\cap\mathcal{L(A_2)}\text{ and where }\mathcal{A_\cap}\text{ is}\newline\text{deterministic if }\mathcal{A_1}\text{ and }\mathcal{A_2}\text{ are deterministic, as follows:}$</p><p>$\begin{array}{l}\hspace{1cm}\cdot \ T_\cap&#x3D;\lbrace((q_1,q_2),\sigma,(q‚Äô_1,q‚Äô_2))\mid(q_1,\sigma,q‚Äô_1)\in T_1,(q_2,\sigma,q‚Äô_2)\in T_2\rbrace\newline\hspace{1cm}\cdot \ \mathcal{F}_\cap &#x3D; \lbrace P\subseteq Q_1\times Q_2\mid pr_0(P)\in\mathcal{F_1},pr_1(P)\in\mathcal{F_2}\rbrace\end{array}$</p></blockquote><h2 id="Closure-Properties-of-under-Boolean-Operations"><a href="#Closure-Properties-of-under-Boolean-Operations" class="headerlink" title="Closure Properties of under Boolean Operations"></a>Closure Properties of under Boolean Operations</h2><blockquote><p>$\textbf{Theorem 10.3. } \textit{The languages recognizable by deterministic Muller automata are closed}\newline\textit{under Boolean operations (complementation, union, intersection).}.$</p></blockquote><h3 id="Proof-of-Deterministic-Muller-automata-are-closed-under-complementation"><a href="#Proof-of-Deterministic-Muller-automata-are-closed-under-complementation" class="headerlink" title="Proof of Deterministic Muller automata are closed under complementation"></a>Proof of Deterministic Muller automata are closed under complementation</h3><p>For a deterministic Muller automaton $\mathcal{A}$, the automaton $\mathcal{A‚Äô}$ of Construction 10.3 recognizes the <code>complement</code> language, because any set $F\notin F$ has to be in the <code>complement</code>, i.e., $F\in2^Q\setminus F$.</p><h3 id="Proof-of-Deterministic-Muller-automata-are-closed-under-Intersection"><a href="#Proof-of-Deterministic-Muller-automata-are-closed-under-Intersection" class="headerlink" title="Proof of Deterministic Muller automata are closed under Intersection"></a>Proof of Deterministic Muller automata are closed under Intersection</h3><p>For deterministic Muller automata $\mathcal{A_1}$ and $\mathcal{A_2}$, the automaton $\mathcal{A}_\cap$ of Construction 10.4 recognizes the <code>intersection</code>. Let $r_1 &#x3D; q^1_0q^1_1\dots$ and $r_2 &#x3D; q^2_0q^2_1\dots$ be accepting runs of $\mathcal{A_1}$ and $\mathcal{A_2}$ on some $\alpha$. Then $r&#x3D;(r^1_0,r^2_0)(r^1_1,r^2_1)\dots$ is an accepting run of $\mathcal{A}_\cap$ on $\alpha$ and vice versa.</p><h3 id="Proof-of-Deterministic-Muller-automata-are-closed-under-Union"><a href="#Proof-of-Deterministic-Muller-automata-are-closed-under-Union" class="headerlink" title="Proof of Deterministic Muller automata are closed under Union"></a>Proof of Deterministic Muller automata are closed under Union</h3><p>It can be proved by <a href="https://en.wikipedia.org/wiki/De_Morgan%27s_laws">De Morgan‚Äôs laws</a> if they are closed under <code>complement</code> and <code>intersection</code>:</p><p>$$\Sigma\setminus(\mathcal{L(A_1)}\cap\mathcal{L(A_2)})&#x3D;(\Sigma\setminus\mathcal{L(A_1)})\cup(\Sigma\setminus\mathcal{L(A_2)})$$</p><h2 id="Regular-language-and-Limit-operator"><a href="#Regular-language-and-Limit-operator" class="headerlink" title="Regular language and Limit operator"></a>Regular language and Limit operator</h2><p>Similar to B√ºchi automata in <a href="../agv4-1/">section 4.1</a>, we can define an $\omega$-regular language from regular language, which is recognizable by deterministic Muller Automata:</p><blockquote><p>$\textbf{Theorem 10.4. }\textit{An language }L\textit{ is recognizable by a deterministic Muller Automata if and only}\newline\textit{if }L\textit{ is a Boolean combination of langauges }\overrightarrow{W}\textit{ where }W\subseteq\Sigma^*\text{ is regular.}$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>$‚Äù\Leftarrow‚Äù$<br>If $W$ is regular, then $\overrightarrow{W}$ is recognizable by a deterministic B√ºchi automaton. Hence, $\overrightarrow{W}$ is recognizable by a deterministic Muller automaton. Thus, the boolean combination $\mathcal{L}$ is recognizable by a deterministic Muller automaton.</p><p>$‚Äù\Rightarrow‚Äù$<br>A deterministic Muller automaton $\mathcal{A}$ accepts some word $\alpha$ with a unique run $r$ if for some $F\in\mathcal{F}$ we have that $\text{Inf}(r)&#x3D;F$. Thus, there is some $F\in\mathcal{F}$ such that for all $q\in F$ we have that $\alpha\in\overrightarrow{W_q}$ and for all $q\notin F$ we have that $\alpha\notin\overrightarrow{W_q}$, where $\overrightarrow{W_q}&#x3D;\mathcal{L(A_q)}$ for the finite-word automaton $\mathcal{A}_q&#x3D;(\Sigma,Q,I,T,\lbrace q\rbrace)$. Hence,</p><p>$$\alpha\in\underset{F\in\mathcal{F}}{\bigcup}\left(\underset{q\in F}{\bigcap}\overrightarrow{W_q}\cap\underset{q\notin F}{\bigcap}(\Sigma^\omega\setminus\overrightarrow{W_q})\right)$$</p><hr><p>Next chapter: <a href="../agv10-4/">Semi-Deterministic B√ºchi Automata</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/De_Morgan%27s_laws">De Morgan‚Äôs laws</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 10.2 -- From B√ºchi automata to Muller automata</title>
      <link href="/AGV/agv10-2/"/>
      <url>/AGV/agv10-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv10-1/">The Muller Acceptance Condition</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><p>In this section, we want to prove that Muller automata is equivalent to B√ºchi Automata.</p><h2 id="Translate-Buchi-Automata-into-Muller-Automata"><a href="#Translate-Buchi-Automata-into-Muller-Automata" class="headerlink" title="Translate B√ºchi Automata into Muller Automata"></a>Translate B√ºchi Automata into Muller Automata</h2><blockquote><p>$\textbf{Construction 10.1. } \text{For a (deterministic) B√ºchi Automaton }\mathcal{A} &#x3D; (\Sigma,Q,I,T,\small\text{B√úCHI}\normalsize (F))\newline\text{ we define the (deterministic) Muller automaton } \mathcal{A‚Äô} &#x3D; (\Sigma,Q,I,T,\small\text{MULLER} \normalsize (\mathcal{F}))\text{ using}$</p><p>$$\mathcal{F}&#x3D;\lbrace S\subseteq Q\mid S\cap F\neq\varnothing\rbrace$$</p></blockquote><p>Since the construction does not modify the transitions, the Muller automaton is again deterministic if the B√ºchi automaton is deterministic. It is straightforward to see that the automata recognize the same language.</p><blockquote><p>$\textbf{Theorem 10.1. } \textit{For every (deterministic) B√ºchi automaton }\mathcal{A}\textit{, there is a (deterministic)}\newline\textit{Muller automaton }\mathcal{A‚Äô}\textit{ such that }\mathcal{L(A)}&#x3D;\mathcal{L(A‚Äô)}.$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>The automaton $\mathcal{A‚Äô}$ of Construction 10.1 complies with our requirements, according to previous section:</p><p>$$\small\text{B√úCHI}\normalsize (F)&#x3D;\lbrace\alpha\in Q^\omega\mid\text{Inf}(\alpha)\cap F\neq\varnothing\rbrace&#x3D;\lbrace\alpha\in Q^\omega\mid\text{Inf}(\alpha)\in\mathcal{F}\rbrace&#x3D;\small\text{MULLER}\normalsize(\mathcal{F})$$</p><h2 id="Translate-Muller-Automata-into-Buchi-Automata"><a href="#Translate-Muller-Automata-into-Buchi-Automata" class="headerlink" title="Translate Muller Automata into B√ºchi Automata"></a>Translate Muller Automata into B√ºchi Automata</h2><p>A slightly more difficult construction is to translate the Muller automaton back into a B√ºchi automaton.</p><blockquote><p>$\textbf{Construction 10.2. } \text{Let }\mathcal{A} &#x3D; (\Sigma,Q,I,T,\small\text{MULLER} \normalsize (\lbrace F_1,\dots,F_n\rbrace))\text{ be a Muller automaton}\newline\text{and }&lt;\text{ some arbitrary total order on }Q.\text{ We construct the B√ºchi automaton }\mathcal{A‚Äô} &#x3D; (\Sigma,Q‚Äô,\newline I‚Äô,T‚Äô,\small\text{B√úCHI} \normalsize(F‚Äô))\text{ with }\mathcal{A‚Äô}\textit{ such that }\mathcal{L(A)}&#x3D;\mathcal{L(A‚Äô)}\text{ as follows:}$</p><p>$\begin{array}{llll}<br>\hspace{1cm} \cdot \ Q‚Äô&amp;&#x3D;Q\cup\overset{n}{\underset{i&#x3D;1}{\bigcup}}(\lbrace i\rbrace\times F_i\times F_i)\newline<br>\hspace{1cm} \cdot \ I‚Äô&amp;&#x3D;I\newline<br>\hspace{1cm} \cdot \ T‚Äô&amp;&#x3D;T\cup\lbrace(q,\sigma,(i,q‚Äô,q‚Äô))\mid 1\leq i\leq n,(q,\sigma,q‚Äô)\in T, q‚Äô\in F_i\rbrace\newline<br>&amp;\hspace{0.9cm}{}\cup\lbrace((i,q,p),\sigma,(i,q‚Äô,p‚Äô))\mid 1\leq i\leq n,(q,\sigma,q‚Äô)\in T,\newline<br>&amp;\hspace{1.5cm}p‚Äô&#x3D;\left\lbrace\begin{array}{ll} p &amp;\text{if } q\neq p\newline<br>\text{min}(F_i)&amp;\text{if } q&#x3D;p&#x3D;\text{max}(F_i)\newline<br>\text{min}(F_i\setminus\lbrace r\mid r\leq p\rbrace)&amp;\text{if } q&#x3D;p&lt;\text{max}(F_i),\end{array}\right.\newline&amp;\hspace{1.5cm}q,p,q‚Äô \in F_i\rbrace\newline<br>\hspace{1cm} \cdot \ F‚Äô&amp;&#x3D;\overset{n}{\underset{i&#x3D;1}{\bigcup}}(\lbrace i\rbrace\times \lbrace\text{min}(F_i)\rbrace\times \lbrace\text{min}(F_i)\rbrace)\newline<br>\end{array}$</p></blockquote><h3 id="Explained-in-Human-language"><a href="#Explained-in-Human-language" class="headerlink" title="Explained in Human language"></a>Explained in Human language</h3><p>A run of the B√ºchi automaton first simply simulates (while in states $Q$) the Muller automaton and then ‚Äúguesses‚Äù the accepting subset of the Muller automaton. The accepting subset is express by the states $(\lbrace i\rbrace\times F_i\times F_i)$, where</p><ul><li>The first component &#x3D; the <strong>index</strong> $i$ of the accepting subset,</li><li>The second component &#x3D; the <strong>currently visited state</strong> of the Muller automaton, and</li><li>The third component &#x3D; the <strong>‚Äúnext‚Äù state</strong> (according to the order on the states) we need to see in order to make progress towards accepting the input word.</li></ul><p>The purpose of the order $&lt;$ on the states is that we can ‚Äústep‚Äù through the states of the accepting subset in order to make sure that all states in the accepting subset actually occur infinitely often. In transitions $T‚Äô$, we have the transitions</p><ul><li><p>Transitions for all states $Q$ are described by $T$, same as in the original Muller Automaton,</p></li><li><p>Transitions that contains both states in $Q$ and accepting subset $(\lbrace i\rbrace\times F_i\times F_i)$, it stays in the subset,</p></li><li><p>Transitions inside the subset,</p><ul><li>the <strong>‚Äúnext‚Äù state</strong> remain unchanged until the <strong>currently visited state</strong> visits it $(p&#x3D;q)$,</li><li>if the <strong>currently visited state</strong> visits <strong>‚Äúnext‚Äù state</strong> and it is the last ‚Äústep‚Äù of the subset, it means we visited the entire subset $F_i$ and we should start from the beginning $\text{min}(F_i)$ again.</li><li>otherwise, move one step ahead ($p‚Äô &gt; p$ and $p, p‚Äô\in F_i$)</li></ul></li></ul><p><strong>The B√ºchi automaton accepts if we step through the states of the accepting subset infinitely often</strong>.<br>Recall that we used a similar trick in the construction of the B√ºchi automaton for the <code>intersection</code> of two B√ºchi-recognizable languages in <a href="../agv3-3/">Construction 3.2.</a></p><blockquote><p>$\textbf{Theorem 10.2. } \newline\textit{For every Muller automaton }\mathcal{A}\textit{ there is a B√ºchi automaton }\mathcal{A‚Äô}\textit{ such that }\mathcal{L(A)}&#x3D;\mathcal{L(A‚Äô)}.$</p></blockquote><h3 id="Proof-1"><a href="#Proof-1" class="headerlink" title="Proof"></a>Proof</h3><blockquote><p>$\mathcal{L(A)}\subseteq\mathcal{L(A‚Äô)}$ (all word accepted by $\mathcal{L(A)}$ must also be accepted by $\mathcal{L(A‚Äô)}$):</p></blockquote><p>Let $\alpha\in\mathcal{L(A)}$ and $r&#x3D;q_0q_1q_2\dots$ be an <strong>accepting</strong> run of $\mathcal{A}$ on $\alpha$. As $r$ is accepting, we have that:</p><ul><li><p>$\text{Inf}(r)\in\mathcal{F}$, so $r$ must be in one of the accepting subset, i.e. $\text{Inf}(r)&#x3D;F_i$ for some $1\leq i\leq n$,</p></li><li><p>Let $m$ be the first position that visit some accepting state: $q_j\in\text{Inf}(r)$ for all $j\geq m$,</p></li><li><p>Now consider some run of $\mathcal{A‚Äô}$ on $\alpha:\ r‚Äô &#x3D; q_0q_1\dots q_{m‚àí1}(i, q_m, p_0)(i, q_{m+1}, p_1)(i, q_{m+2}, p_2)\dots$</p><ul><li>it nondeterministically switches to $(i, q_m, p_0)$ at position $m$.</li></ul></li></ul><p>For the sake of contradiction, assume that $r$ is <strong>not accepting</strong>:</p><ul><li>Then there is a position $k\geq 0$ such that $p_j&#x3D;p_k$ for all $j\geq k$ ($q$ never moves to $p_k$,<strong>‚Äúnext‚Äù state</strong> got stuck).</li><li>Then also $q_{m+j}\neq p_j$ for all $j\geq k$. However, this contradicts that $p_k\in F_i$.<br>(if q can never reach $p_k$, then it is not an accepting state and thus contradicts with the definition of the subset)</li></ul><blockquote><p>$\mathcal{L(A)}\supseteq\mathcal{L(A‚Äô)}$ (all word accepted by $\mathcal{L(A‚Äô)}$ must also be accepted by $\mathcal{L(A)}$):</p></blockquote><p>Let $\alpha\in\mathcal{L(A‚Äô)}$, $r‚Äô &#x3D; q_0q_1\dots q_{m‚àí1}(i, q_m, p_0)(i, q_{m+1}, p_1)(i, q_{m+2}, p_2)\dots$ be some accepting run of $\mathcal{A‚Äô}$ on $\alpha$:</p><ul><li>At some position $m$ it switches to some $(i, q_m, p_0)$, otherwise it would not be accepting.</li><li>By construction, $q_j\in\text{Inf}(r)$ for all $j\geq m$ (it starts staying in the accepting subset), and</li><li>For each $p\in F_i$ there are infinitely many positions $k$ such that $q_k&#x3D;p_k&#x3D;p$.<ul><li>($q$ always reach every <strong>‚Äúnext‚Äù state</strong> infinitely often at some positions)</li></ul></li></ul><p>Thus, we can construct an accepting run $r&#x3D;q_0q_1q_2\dots$ of $\mathcal{A}$ on $\alpha$ by using every $q$ state in the run $r‚Äô$, because every second component in the tuple is accepting, i.e. $\text{Inf}(pr_2(r‚Äô))&#x3D;p_k&#x3D;F_i$,</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Now we have proved that we can construct an Muller automaton from B√ºchi automaton and an B√ºchi automaton from Muller automaton. Therefore they are interchangably equivalent. In the next section, we will prove that deterministic Muller automata are actually closed.</p><hr><p>Next chapter: <a href="../agv10-3/">Closure Properties of Muller Automata under Boolean Operations</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 10.1 -- The Muller Acceptance Condition</title>
      <link href="/AGV/agv10-1/"/>
      <url>/AGV/agv10-1/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv9-3/">The Emerson-Lei algorithm</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introdcution"><a href="#Introdcution" class="headerlink" title="Introdcution"></a>Introdcution</h2><p>We already established that while the languages that can be recognized with nondeterministic B√ºchi automata are exactly the $\omega$-regular languages, the languages that can be recognized with deterministic B√ºchi automata are a strictly smaller set.</p><p>We now repair this deficiency with a more expressive acceptance condition, the <strong>Muller condition</strong>. <strong>McNaughton‚Äôs theorem</strong> states that the set of languages recognizable by deterministic Muller automata are again exactly the $\omega$-regular languages.</p><p>We will see later that it is very useful to have a deterministic automaton for a given $\omega$-language, for example in synthesis, where we construct the game between the system and the environment from a deterministic automaton that recognizes the winning plays for the system player.</p><p>Since the complementation of <strong>deterministic Muller automata</strong> is a very simple operation, McNaughton‚Äôs theorem also provides an alternative proof for the result of <a href="../agv5-3/">Section 5</a> that the $\omega$-regular languages are closed under complementation.</p><h2 id="Muller-Acceptance-Condition"><a href="#Muller-Acceptance-Condition" class="headerlink" title="Muller Acceptance Condition"></a>Muller Acceptance Condition</h2><blockquote><p>$\textbf{Definition 10.1. } \text{The }\textit{Muller Acceptance Condition }\small\text{MULLER} \normalsize(\mathcal{F})\text{ on a set of sets of states }\newline\mathcal{F}\subseteq 2^Q\text{ is the set}$</p><p>$$\small\text{MULLER}\normalsize(\mathcal{F})&#x3D;\lbrace\alpha\in Q^\omega\mid\text{Inf}(\alpha)\in\mathcal{F}\rbrace$$</p><p>$\text{An automaton }\mathcal{A} &#x3D; (\Sigma,Q,I,T,Acc) \text{ with }Acc &#x3D; \small\text{MULLER} \normalsize(\mathcal{F})\text{ is called a }\textit{Muller Automaton.}\newline\text{The set }\mathcal{F}\text{ is called the set of }\textit{accepting subsets }(\text{or the }\textit{table})\text{ of }\mathcal{A}.$</p></blockquote><p>Let‚Äôs do a small recap from <a href="../agv2-3/">section 2.3</a>:</p><ul><li><p><strong>B√ºchi Condition</strong></p><ul><li>$\small\text{B√úCHI} \normalsize(F) &#x3D; \lbrace\alpha\in Q^\omega \mid \text{Inf}(\alpha) \cap F \neq \varnothing\rbrace$</li><li>word $\alpha$ visit some state in set $F$ infinitely often.</li></ul></li><li><p><strong>Muller Acceptance Condition</strong></p><ul><li>$\small\text{MULLER}\normalsize(\mathcal{F})$</li><li>word $\alpha$ visit some <strong>set of states</strong> in set $\mathcal{F}$ infinitely often.</li></ul></li></ul><p>We can see Muller Acceptance Condition are <strong>more expressive</strong> in terms of visiting accepting states, because you can require the word to visit a set of states infinitely often instead just one state out of the whole set.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Consider the deterministic automaton over the alphabet $\Sigma&#x3D;\lbrace a, b\rbrace$ shown below.</p><p>For the table $\mathcal{F}&#x3D;\lbrace\lbrace q\rbrace\rbrace$, it means the automaton can only visit $\lbrace q\rbrace$ infinitely often. We obtain the Muller automaton $\mathcal{A}$ recognizing the language $\mathcal{L(A)}&#x3D;(a+b)^\ast b^\omega$;</p><p>For the table $\mathcal{F}‚Äô&#x3D;\lbrace\lbrace q\rbrace\lbrace p,q\rbrace\rbrace$, it means the automaton has to visit either $\lbrace q\rbrace$ or $\lbrace p,q\rbrace$ infinitely often. We obtain the Muller automaton $\mathcal{A‚Äô}$ recognizing $\mathcal{L(A‚Äô)}&#x3D;(a^\ast b)^\omega$.</p><p><img src="/images/notes/uds/agv/10_1_muller.png"></p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>We introduced Muller Acceptance Condition, which is slightly more advanced than the B√ºchi Acceptance Condition:</p><table><thead><tr><th align="left">Aspect</th><th align="left">B√ºchi Acceptance</th><th align="left">Muller Acceptance</th></tr></thead><tbody><tr><td align="left">Acceptance states</td><td align="left">At least one accepting state must appear infinitely often.</td><td align="left">The set of states that visited infinitely often must match a subset in $\mathcal{F}$</td></tr><tr><td align="left">Condition Set</td><td align="left">$F$ is the set of accepting states</td><td align="left">$\mathcal{F}$ is the set of the set of accepting states (subset of the set)</td></tr><tr><td align="left">Expressiveness</td><td align="left">Less expressive (<a href="../agv4-1/">example</a>)</td><td align="left">Fully expressive</td></tr><tr><td align="left">Complexity</td><td align="left">Simpler and easier to implement.</td><td align="left">More complex, requires tracking recurring state sets.</td></tr></tbody></table><p>In the following sections, we will discuss about the translation from B√ºchi automata to Muller automata.</p><hr><p>Next chapter: <a href="../agv10-2/">From B√ºchi automata to Muller automata</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 9.3 -- The Emerson-Lei algorithm</title>
      <link href="/AGV/agv9-3/"/>
      <url>/AGV/agv9-3/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv9-2/">Nested depth-first search</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>As an alternative algorithm for checking language emptiness of B√ºchi automata we now discuss a classic algorithm due to Emerson and Lei. Unlike the <a href="../agv9-2/">depth-first search</a> of the previous subsection, the <strong>Emerson-Lei algorithm</strong> is based on a <strong>breadth-first search</strong> implemented as a fixpoint construction over sets of states.</p><p>A disadvantage of this algorithm is that its running time is <em>quadratic</em>. Nevertheless, algorithms of this type play a major role in <em>symbolic model checking</em>, because the sets of states can often be represented efficiently<br>using data structures like <em>binary decision diagrams</em>.</p><h3 id="Live-states"><a href="#Live-states" class="headerlink" title="Live states"></a>Live states</h3><p>A state $q$ of a B√ºchi automaton is <code>live</code> if some infinite path starting in $q$ visits accepting states infinitely often. This definition is the opposite of <code>safe</code> states, where it never visits accepting states. The idea of the algorithm is to identify the set of <code>live</code> states.  The language of a B√ºchi automaton is <strong>non-empty</strong> iff it has a <strong>live initial state</strong>.</p><p>The <strong>Emerson-Lei algorithm</strong> is based on the following inductive definition:</p><blockquote><p>$\textbf{Definition 9.1. } \text{For a B√ºchi automaton and a number }n\in\mathbb{N}\text{, the set of }\textit{n-live states}\text{ is}\newline\text{defined as follows:}$</p><p>$\begin{array}{l}<br>\hspace{1cm}\cdot\ \text{every state is 0-live}\newline<br>\hspace{1cm}\cdot\ \text{a state q is (n + 1)-live if some path containing at least one transition leads from }q\newline\hspace{1.3cm}\text{to an accepting n-live state}\newline<br>\end{array}$</p></blockquote><h3 id="Fixpoint"><a href="#Fixpoint" class="headerlink" title="Fixpoint"></a>Fixpoint</h3><p>Let $\mathit{live}_n$ denote the set of $n$-live states. It is easy to see that $\mathit{live}_{n} \supseteq \mathit{live}_{n+1}$, because $\mathit{live}_{0}$ represents the set of all states in the automaton, and $\mathit{live}_{1}$ are only those which can reach the accepting states. Then $\mathit{live}_{2}$ are those who can only reach the accepting states through some states in $\mathit{live}_{1}$. Therefore set $\mathit{live}_{n+1}$ can never be larger than its previous set $\mathit{live}_{n}$.</p><p>Since the set of states is finite, there exists a <strong>fixpoint</strong> $\mathit{live}_k$ such that $\mathit{live}_k&#x3D;\mathit{live}_{k+1}$. Then the set $\mathit{live}_k$ is the set of live states.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p><img src="/images/notes/uds/agv/9_2_dfs.png"></p><p>In the example from <a href="../agv9-2/">last section</a>, states $q_0$, $q_1$ and $q_2$ are live; states $q_3$, $q_4$, and $q_5$ are only $0$-$\textit{live}$ (you cannot visit other accepting states starting from $q_3$ even though it is an accepting state).</p><p>To describe the algorithm, we first introduce a construction that implements a backward breadth-first search as a least fixpoint. The construction computes all states from which a given set of states is reachable.</p><blockquote><p>$\textbf{Construction 9.1. } \text{For a B√ºchi Automaton }\mathcal{A} &#x3D; (\Sigma,Q,I,T,\small\text{B√úCHI} \normalsize(F))\text{ and a set of states}\newline R\subseteq Q\text{, we compute the set of backwards reachable states from }R\text{ as follows:}$</p><p>$\begin{array}{llll}<br>\hspace{1cm} \cdot &amp; \textit{Pre}(R)&amp;&#x3D;&amp;\lbrace q\in Q\mid \exists q‚Äô\in R,\sigma\in\Sigma,(q,\sigma,q‚Äô)\in T\rbrace\newline<br>\hspace{1cm} \cdot &amp; \textit{BackwardReach}_0(R)&amp;&#x3D;&amp;R\newline<br>\hspace{1cm} \cdot &amp; \textit{BackwardReach}_{n+1}(R)&amp;&#x3D;&amp;\textit{BackwardReach}_{n}(R)\cup\textit{Pre}(\textit{BackwardReach}_{n}(R))\newline<br>\hspace{1cm} \cdot &amp; \textit{BackwardReach}(R)&amp;&#x3D;&amp;\underset{n\in\mathbb{N}}{\bigcup}\textit{BackwardReach}_{n}(R)\newline<br>\end{array}$</p></blockquote><p>By this construction, it returns a set of states that can reach some states in $R$. For example, $\lbrace q_0,q_1,q_2\rbrace$ can reach $q_3$. Using this construction as a subroutine, we can compute the live states as a greatest fixpoint:</p><blockquote><p>$\textbf{Construction 9.2. } \text{For a B√ºchi Automaton }\mathcal{A} &#x3D; (\Sigma,Q,I,T,\small\text{B√úCHI} \normalsize(F))\text{ we compute the set}\newline\text{of live states as follows:}$</p><p>$\begin{array}{llll}<br>\hspace{1cm} \cdot &amp; \textit{live}_0&amp;&#x3D;&amp;Q\newline<br>\hspace{1cm} \cdot &amp; \textit{live}_{n+1}&amp;&#x3D;&amp;\textit{BackwardReach}(\textit{Pre}(\textit{live}_n\cap F))\newline<br>\hspace{1cm} \cdot &amp; \textit{live}&amp;&#x3D;&amp;\underset{n\in\mathbb{N}}{\bigcap}\textit{live}_{n}\newline<br>\end{array}$</p></blockquote><p>The set of $\textit{live}$ is the smallest subset of all $\textit{live}_n$ in any $n\in\mathbb{N}$. Therefore the function will stop when $\mathit{live}_k$ such that $\mathit{live}_k&#x3D;\mathit{live}_{k+1}$, which is the greatest fixpoint of the set of <code>live</code> states.</p><p>Then we can verify whether the automaton is non-empty, i.e. $q_0\in\textit{live}$.</p><h3 id="Example-cont"><a href="#Example-cont" class="headerlink" title="Example (cont.)"></a>Example (cont.)</h3><p>We compute the live states as follows:</p><p>$\begin{array}{llll}<br>\hspace{1cm} \cdot &amp; \textit{live}_0&amp;&#x3D;&amp;\lbrace q_0,q_1,q_2,q_3,q_4,q_5\rbrace\newline<br>\hspace{1cm} \cdot &amp; \textit{live}_1&amp;&#x3D;&amp;\lbrace q_0,q_1,q_2\rbrace\newline<br>\hspace{1cm} \cdot &amp; \textit{live}_2&amp;&#x3D;&amp;\lbrace q_0,q_1,q_2\rbrace\newline<br>\hspace{1cm} \cdot &amp; \textit{live}&amp;&#x3D;&amp;\lbrace q_0,q_1,q_2\rbrace\newline<br>\end{array}$</p><p>Since the initial state $q_0$ is <code>live</code>, we have that the language of the automaton is <strong>non-empty</strong>.</p><hr><p>Next chapter: <a href="../agv10-1/">The Muller Acceptance Condition</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 9.2 -- Nested depth-first search</title>
      <link href="/AGV/agv9-2/"/>
      <url>/AGV/agv9-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv9-1/">Automata-based LTL Model Checking with Sequential Circuits</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>We now develop an algorithm for checking whether the language of a given B√ºchi automaton is <code>empty</code>. A natural idea is to use <strong>depth-first search (DFS)</strong> twice.</p><p>The language is non-empty $\Leftrightarrow$ it is accepted by some words:</p><ol><li>there exists an accepting state $q$,</li><li>$q$ is reachable from some initial state (discovered by 1st DFS), and</li><li>$q$ can again be reached from $q$ (discovered by 2nd DFS),</li></ol><h2 id="Example-Simple-DFS"><a href="#Example-Simple-DFS" class="headerlink" title="Example (Simple DFS)"></a>Example (Simple DFS)</h2><p>Consider the following B√ºchi automaton (edge labels do not matter and are omitted).</p><p><img src="/images/notes/uds/agv/9_2_dfs.png"></p><p><code>Step 1</code>: discovers $q_0$, $q_1$, and $q_3$.<br><code>Step 2</code>: searches from $q_0$ and $q_3$: not successful; searches from $q_1$: discovers the path back to $q_1$ via $q_2$.</p><p>The drawback of the algorithm discussed so far is its <strong>quadratic running time</strong>: potentially, each state in $F$ discovered by the first DFS requires a fresh second DFS. The quadratic running time can be avoided by stopping the DFS in <code>Step 2</code> whenever a state is encountered that was already visited during <code>Step 2</code>.</p><p>However, this is only sound if the searches in <code>Step 2</code> are executed in the right order. If we first execute the DFS from $q_0$ in Example 9.2, then this search visits all states; in a subsequent search from $q_1$, we would, therefore, no longer discover the successful path back to $q_1$ via $q_2$!</p><p>It turns out that it is sound to restrict the searches in <code>Step 2</code> if they are executed in order of <em>increasing finishing times</em> of the DFS in <code>Step 1</code>. The emptiness check with nested DFS therefore uses <code>Step 1</code> to order the reachable accepting states according to their finishing times; in <code>Step 2</code>, a DFS is initiated from each reachable accepting state in this order until a cycle is detected. <code>Step 2</code> marks the visited states and restricts the searches so that no state is visited twice during <code>Step 2</code>.</p><h2 id="A-Modified-Example-Nested-DFS"><a href="#A-Modified-Example-Nested-DFS" class="headerlink" title="A Modified Example (Nested DFS)"></a>A Modified Example (Nested DFS)</h2><p>Continue from above, a possible annotation of the states with pairs <em>(discovery, finishing)</em> of discovery and finishing times during the DFS in Step 1 is the following:</p><p><img src="/images/notes/uds/agv/9_2_dfs2.png"></p><p>Ordering the accepting states according to increasing finishing times, we obtain the order $q_3$, $q_1$, $q_0$. In Step 2, the DFS from $q_3$ visits (unsuccessfully) $q_3$, $q_4$ and $q_5$. The DFS from $q_1$<br>then only visits $q_1$ and $q_2$, upon which it has successfully discovered the path from $q_2$ to $q_2$.</p><h2 id="Nested-DFS-and-Buchi-Automaton"><a href="#Nested-DFS-and-Buchi-Automaton" class="headerlink" title="Nested DFS and B√ºchi Automaton"></a>Nested DFS and B√ºchi Automaton</h2><blockquote><p>$\textbf{Theorem 9.1. }\textit{For a B√ºchi automaton }\mathcal{A}\textit{, nested DFS is successful iff }\mathcal{L(A)}\textit{ is nonempty.}$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>$‚Äù\Rightarrow‚Äù$<br>If the nested DFS is successful then there exists a state $q$ that is reachable from some initial state such that there is a path from $q$ back to $q$. Hence, $\mathcal{L(A)}$ is non-empty.</p><p>$‚Äù\Leftarrow‚Äù$<br>To show that we can safely ignore the states that were visited in previous searches in <code>Step 2</code>, we consider the situation at the beginning of a DFS from some accepting state $q\in F$ in <code>Step 2</code>. Let $T$ be the set of states visited in previous searches in <code>Step 2</code>. We prove that there is no cycle $q_0,q_1,\dots,q_k$ with $q&#x3D;q_0&#x3D;q_k$ such that $\lbrace q_0,q_1,\dots,q_k\rbrace\cap T\neq \varnothing$ i.e., the states in $T$ can be ignored while looking for $q$-cycles.</p><p>Assume, by way of contradiction, that there is a state $q$ where this condition is violated for the first time. Let $t\in\lbrace q_0,q_1,\dots,q_k\rbrace\cap T$, and let $u\in F$ be the accepting state such that $t$ has been added to $T$ during the DFS in <code>Step 2</code>. This means that the DFS from $u$ was invoked before the DFS from $q$; hence, $u$ has an earlier finishing time than $q$ in den DFS of <code>Step 1</code>.</p><ul><li><p>Case 1: $u$ was discovered before $q$ in the DFS of <code>Step 1</code>. This cannot be the case, because $q$ is reachable from $u$, and, thus, the finishing time of $q$ would have been earlier than that of $u$.</p></li><li><p>Case 2: u was discovered after $q$ in the DFS of <code>Step 1</code>. Then $q$ was still on the stack of the DFS when $u$ was finished. Hence, $u$ is reachable from $q$. Thus, $u$ and $q$ are on a cycle. This cycle (or some other cycle) would have been discovered during the DFS from $u$ in <code>Step 2</code>.</p></li></ul><hr><p>Next chapter: <a href="../agv9-3/">The Emerson-Lei algorithm</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 9.1 -- Automata-based LTL Model Checking with Sequential Circuits</title>
      <link href="/AGV/agv9-1/"/>
      <url>/AGV/agv9-1/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv8-5/">From Linear Arithmetic to Automata</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><p><img src="/images/notes/uds/agv/9_1.png"></p><h3 id="Right-hand-side-Hondeterministic-Buchi-automata"><a href="#Right-hand-side-Hondeterministic-Buchi-automata" class="headerlink" title="Right hand side: Hondeterministic B√ºchi automata"></a>Right hand side: Hondeterministic B√ºchi automata</h3><p>In order to find system executions that violate a given <strong>LTL formula (1)</strong>, we <strong>negate the formula (2)</strong> and build an automaton that is equivent to the negated formula. For this, we can use the translaton from LTL to <strong>alternating automata (3)</strong> from <a href="../agv7-2/">Construction 7.1</a> followed by the Miyano-Hayashi translation from alternating B√ºchi automata to <strong>nondeterministic B√ºchi automata (4)</strong> from <a href="../agv7-3/">Construction 7.2</a>.</p><h3 id="Left-hand-side-Safety-Automaton"><a href="#Left-hand-side-Safety-Automaton" class="headerlink" title="Left hand side: Safety Automaton"></a>Left hand side: Safety Automaton</h3><p>We represent the <strong>system (1)</strong> executions as a <strong>Safety Automaton (2)</strong>, which is then intersected (using <a href="../agv3-3/">Construction 3.2</a> with the B√ºchi automaton for the negated LTL formula. The actual search for a violating execution then happens as the emptiness check of the resulting B√ºchi automaton. In the remainder of this section, we first quickly discuss the representation of the system as a <strong>Safety Automaton</strong>, using <strong>sequential circuits</strong> as an example, and then focus on the emptiness check of B√ºchi automata.</p><h2 id="Model-Checking-Sequential-Circuits"><a href="#Model-Checking-Sequential-Circuits" class="headerlink" title="Model Checking Sequential Circuits"></a>Model Checking Sequential Circuits</h2><p>As an illustration of how automata can be used to represent system behaviors, we consider the representation of sequential circuits to safety automata. For a more general discussion of how to represent different types of systems, such as protocols or software, we refer the reader to textbooks on model checking, such as <a href="https://is.ifmo.ru/books/_principles_of_model_checking.pdf">Principles of Model Checking</a> by Baier and Katoen.</p><h3 id="Sequential-Circuits"><a href="#Sequential-Circuits" class="headerlink" title="Sequential Circuits"></a>Sequential Circuits</h3><blockquote><p>$\textbf{Definition 9.1. } \text{A }\textit{sequential circuit }\text{is given as a tuple }S&#x3D;(I,O,R,\theta,\lambda,\delta)\text{, where}$</p><p>$\begin{array}{lcl}<br>\hspace{1cm}\cdot&amp;I&amp;\text{is a set of input bits}\newline<br>\hspace{1cm}\cdot&amp;O&amp;\text{is a set of output bits}\newline<br>\hspace{1cm}\cdot&amp;R&amp;\text{is a set of registers}\newline<br>\hspace{1cm}\cdot&amp;\theta\subseteq R&amp;\text{is an initial register evaluation}\newline<br>\hspace{1cm}\cdot&amp;\lambda:O\rightarrow(2^{I\cup R}\rightarrow\mathbb{B})&amp;\text{assigns to each output bit a control function }2^{I\cup R}\rightarrow\mathbb{B}\newline<br>\hspace{1cm}\cdot&amp;\delta:R\rightarrow(2^{I\cup R}\rightarrow\mathbb{B})&amp;\text{assigns to each output bit a update function }2^{I\cup R}\rightarrow\mathbb{B}\newline<br>\end{array}$</p></blockquote><h3 id="Safety-Automaton"><a href="#Safety-Automaton" class="headerlink" title="Safety Automaton"></a>Safety Automaton</h3><p>A safety automaton is a B√ºchi automaton where <strong>all states are accepting</strong>. Here, Input $(I)$ and Output $(O)$ are represented as words, and register valuation $(R)$ is represented as states:</p><blockquote><p>$\text{A sequential circuit can be represented as a safety automaton}\newline\mathcal{A}_S&#x3D;(2^{I\cup O},2^R,I,T,\small\text{B√úCHI} \normalsize (Q))\text{, where}$</p><p>$\begin{array}{ll}<br>\cdot\ Q &#x3D; &amp;2^R\hspace{1cm}\text{consist of all valuations of the registers;}\newline<br>\cdot\ I &#x3D;&amp; \lbrace\theta\rbrace\hspace{0.8cm}\text{corresponds to the inital register valuation;}\newline<br>\cdot\ T&#x3D;&amp;\lbrace(q,\sigma,q‚Äô)\mid\lbrace\forall y\in O:y\in \sigma\text{ iff }\lambda(y)(q\cup(\sigma\cap I))\rbrace\wedge\lbrace\forall r\in R:r\in q‚Äô\text{ iff }\delta(r)(q\cup(\sigma\cap I))\rbrace\rbrace\newline<br>&amp;\hspace{1.5cm}\text{reflect the outputs specified by the control functions, and}\newline<br>&amp;\hspace{1.5cm}\text{the new register valuation specified by the update function}\end{array}$</p></blockquote><p>We say that a circuit $S$ <em>satisfies</em> an LTL formula $\varphi$ if $\mathcal{L}(\mathcal{A}_S) ‚äÜ \mathcal{L(\varphi)}$.</p><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>The example circuit shown on the left has input $I &#x3D; \lbrace x\rbrace$, output $O &#x3D; \lbrace y\rbrace$, and a single register $R &#x3D; \lbrace r\rbrace$. The control function of $y$ is $x\text{ XOR }r$, the update function of $r$ is $x\vee r$.</p><p>We assume an initial register valuation $\theta &#x3D; \varnothing$. The circuit is then represented as the automaton shown on the right. Note that that accepting state only have transtions $\lbrace x\rbrace, \lbrace y\rbrace$, becasue if $\lbrace x\rbrace$ holds, $\lbrace y\rbrace$ cannot hold because of the $\text{XOR}$ gate and vice versa.</p><p><img src="/images/notes/uds/agv/9_1_eg.png"></p><p>Suppose now that we wish to verify whether our circuit satisfies the LTL formula $\varphi &#x3D; \square(x\leftrightarrow y)$. We negate $\varphi$, and translate the resulting formula into the nondeterministic B√ºchi automaton shown on the left:</p><p><img src="/images/notes/uds/agv/9_1_auto.png"></p><p>The intersection of the languages of the automaton representing the circuit and the automaton representing the negation of $\varphi$ results in the automaton shown above on the right.</p><p>Since there are some words that can be accepted by both automaton and their intersections, the language of this automaton is not empty: for example, the word $\lbrace x, y\rbrace(\lbrace x\rbrace)^\omega$. The circuit, hence, does not satisfy $\varphi$.</p><hr><p>Next chapter: <a href="../agv9-2/">Nested depth-first search</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 8.5 -- From Linear Arithmetic to Automata</title>
      <link href="/AGV/agv8-5/"/>
      <url>/AGV/agv8-5/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv8-4/">Homogenous Inequality Testing is Automatic</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>With all the setup in the previous sections, We are now ready to prove the main result of this chapter.</p><blockquote><p>$\textbf{Theorem 8.1. }\textit{Let }\varphi\textit{ be a linear arithmetic formula. We can effectively construct a B√ºchi}\newline\textit{Automaton }\mathcal{A}\textit{ such that }\mathcal{L(A)}&#x3D;\lbrace\alpha_\sigma\mid\sigma\models\varphi\rbrace$</p></blockquote><p>We follow the same strategy as for the analogous result for S1S in <a href="../agv6-7/">Section 6.7</a>.</p><ol><li>Introduce a logic with a (slightly) <em>restricted syntax</em> from S1S,</li><li>Show that the restriction does not come at the cost of expressive power, and</li><li>Use structural induction on <em>restricted-syntax formulas</em> to construct our desired automata.</li></ol><h2 id="Restricted-Linear-Arithmetic"><a href="#Restricted-Linear-Arithmetic" class="headerlink" title="Restricted Linear Arithmetic"></a>Restricted Linear Arithmetic</h2><p>The formulas of syntactically restricted linear arithmetic are defined by the following grammar:</p><p>$$\varphi::&#x3D;z&#x3D;1\mid g_1x_1+\dots+g_\ell x_\ell\leq h_1 y_1+\dots+h_m y_m\mid\neg\varphi\mid\varphi\wedge\varphi\mid\exists x.\varphi$$</p><p>where $z, x_1,\dots,x_\ell,y_1,\dots,y_m\in V$ are <strong>variables</strong>, and $p_1,\dots,p_\ell,q_1,\dots,q_m$ are <strong>positive constants</strong>. The restriction is that <strong>all inequalities must be homogenous</strong>, except $z&#x3D;1$ being the only <strong>non-homogenous relation</strong>.</p><h3 id="homogenous-inequalities-conversion"><a href="#homogenous-inequalities-conversion" class="headerlink" title="homogenous inequalities conversion"></a>homogenous inequalities conversion</h3><p>In fact, <strong>‚Äúall inequalities must be homogenous‚Äù</strong> is not a semantic restrictionm, since we can always convert non-homogenous inequalities into a homogenous version:</p><blockquote><p>For a formula $\varphi_0$ contains non-homogenous inequalities, first replace all constants $r$ by $r\cdot z$, where $z$ is a fresh variable to obtain $\varphi‚Äô_0$, then replace $\varphi_0$ with $\varphi::&#x3D;\exists z. (z&#x3D;1\wedge\varphi‚Äô_0)$.</p></blockquote><p>For example, $\varphi_0::&#x3D;y\leq2,\varphi_0‚Äô::&#x3D;y\leq2\cdot z,$ now we have $\varphi_0::&#x3D;\exists z. (z&#x3D;1\wedge(y\leq2\cdot z)))$</p><p>To include all possible expression of the real number $1$, the encoding must be a word of the form $00^\ast(1{$} 0^\omega + {$} 1^\omega)$. It is thus trivial to construct an automaton corresponding to $z&#x3D;1$.</p><h2 id="From-Linear-Arithmetic-to-Automata"><a href="#From-Linear-Arithmetic-to-Automata" class="headerlink" title="From Linear Arithmetic to Automata"></a>From Linear Arithmetic to Automata</h2><p>We use <a href="../agv8-4/">Construction 8.1</a> to construct automata for <strong>homogenous inequalities</strong>. Note that the construction works even when one of the sides of the inequality is equal to $0$ (i.e., the empty sum).</p><p>Now we start with inductive cases. Recall that for any $k$ we can construct an automaton <a href="../agv8-4/">$\mathcal{L(A_{\textsf{valid},k})}$</a> that checks whether a word $\alpha\in(\lbrace 0,1\rbrace^k\cup\lbrace{$}\rbrace)^k)^\omega$ is a well-formed encoding of some valuation $\sigma$ to $k$ free variables.</p><h3 id="Negation-mathcal-A-neg-varphi"><a href="#Negation-mathcal-A-neg-varphi" class="headerlink" title="Negation $\mathcal{A_{\neg\varphi}}$"></a>Negation $\mathcal{A_{\neg\varphi}}$</h3><p>The B√ºchi automaton $\mathcal{A_{\neg\varphi}}$ is obtained through complementation and intersection of B√ºchi automata.</p><p>Let $\varphi$ have $k$ free variables. For negation, we have</p><p>$$\mathcal{L(A_{\neg\varphi})}&#x3D;((\lbrace 0,1\rbrace^k\cup\lbrace{$}\rbrace)^k)^\omega\setminus\mathcal{L(A_\varphi)})\cap\mathcal{L(A_{\textsf{valid},k})}$$</p><h3 id="Conjunction-mathcal-A-varphi-1-wedge-varphi-2"><a href="#Conjunction-mathcal-A-varphi-1-wedge-varphi-2" class="headerlink" title="Conjunction $\mathcal{A_{\varphi_1\wedge\varphi_2}}$"></a>Conjunction $\mathcal{A_{\varphi_1\wedge\varphi_2}}$</h3><p>$\mathcal{A_{\varphi_1\wedge\varphi_2}}$ can be obtained similarly straightforward through the intersection of two B√ºchi automata because</p><p>$$\mathcal{L(A_{\varphi_1\wedge\varphi_2})}&#x3D;\mathcal{L(A_{\varphi_1})}\cap\mathcal{L(A_{\varphi_2})}$$</p><h3 id="Existential-Quantification"><a href="#Existential-Quantification" class="headerlink" title="Existential Quantification"></a>Existential Quantification</h3><p>To handle projection, i.e. construct $\mathcal{A_{\exists x.\varphi}}$ from $\mathcal{A_{\varphi}}$, we first try to see their difference:</p><ul><li>$\mathcal{A_{\varphi}}$ runs over the alphabet $\lbrace 0, 1\rbrace^{k+1}\cup\lbrace{$}\rbrace^{k+1}$ and reads the encoding of a valuation of $\lbrace x,y_1,\dots, y_k\rbrace$.</li><li>$\mathcal{A_{\exists x.\varphi}}$ runs over the alphabet $\lbrace 0, 1\rbrace^k\cup\lbrace{$}\rbrace^k$ and reads the encoding of a valuation of $\lbrace y_1,\dots, y_k\rbrace$,</li></ul><p>Same as before, the principle behind the construction is to create a automaton that simulate identical behaviour with the absence of $x$. This is simple for most of the transitions except for the initial transition.</p><p>For a automaton that does not contain $x$, it has to ‚Äúguess‚Äù an encoding of $x$ such that $\varphi(x,y_1,\dots, y_k)$ holds. However, the given encoding of the valuation of $\lbrace y_1,\dots, y_k\rbrace$ may not be appropriately padded.</p><p>For example, let $y_1 &#x3D; 1$ and we encode it as $01{$}0^\omega$. If we guess $x&#x3D;4$, then two digits of <em>integer part</em> is not enough. The encoding must be ‚Äúpadded‚Äù so to synchronize ‚Äúmay be‚Äù accepted by $\mathcal{A_{\varphi}}$:</p><p>$$\begin{bmatrix}x\newline y_1\end{bmatrix}&#x3D;\begin{bmatrix}0\newline 0\end{bmatrix}<br>\begin{bmatrix}1\newline 0\end{bmatrix}\begin{bmatrix}0\newline 0\end{bmatrix}<br>\begin{bmatrix}0\newline 1\end{bmatrix}\begin{bmatrix}{$}\newline{$}\end{bmatrix}\left(\begin{bmatrix}0\newline 0\end{bmatrix}\right)^\omega$$</p><p>Therefore, when we convert from $c_y$ to $(c_x, c_y)$, We have to repeat the first letter $c_{y,n}$ as padding:</p><p>$$(a_{x,n+j}, a_{y,n})(a_{x,n+j‚àí1}, a_{y,n})\dots(a_{x,n}, a_{y,n}).$$</p><p>Since $c_{y,n}$ is simply repeating, creating transition for each letter of $a_x$ unnecessarily enlarge the size of the automaton. Instead, we can make one initial transition that encapsulate the full padding of the first letter of $c_y$.</p><p>$$(q,(c_{x,1},c_{y_1},\dots,c_{y_k})\dots(c_{x,n},c_{y_1},\dots,c_{y_k}),q‚Äô)\in T‚Äô$$</p><blockquote><p>$\textbf{Construction 8.2. } \text{Let }x,y_1,\dots, y_k\text{ be free variables in the linear arithmetic formula }\varphi,\text{ and}$</p><p>$$\mathcal{A_\varphi}&#x3D;(\lbrace 0, 1\rbrace^{k+1}\cup\lbrace{$}\rbrace^{k+1},Q,I,T,\small\text{B√úCHI}\normalsize (F))$$</p><p>$\text{be a B√ºchi Automaton such that }\mathcal{L(A)}&#x3D;\lbrace\alpha_\sigma\mid\sigma\models\varphi\rbrace.\text{ We construct a B√ºchi Automaton}$</p><p>$$\mathcal{A_{\exists x.\varphi}}&#x3D;(\lbrace 0, 1\rbrace^{k}\cup\lbrace{$}\rbrace^{k},Q\cup\textsf{Inits},\textsf{Inits},T‚Äô,\small\text{B√úCHI}\normalsize (F))$$</p><p>$\text{such that }\mathcal{L(A_{\exists x.\varphi})}&#x3D;\lbrace\alpha_\sigma\mid\sigma\models\exists x.\varphi\rbrace\text{ as follows.}$</p><p>$\begin{array}{l}<br>\hspace{1cm} \cdot \ \textsf{Inits}&#x3D;\lbrace(q,\star)\mid q\in I\rbrace\newline<br>\hspace{1cm} \cdot \ (q,(c_{y_1},\dots,c_{y_k}),q‚Äô)\in T‚Äô\text{ if and only if there exists }c_x\text{ such that }(q,(c_x,c_{y_1},\dots,c_{y_k}),q‚Äô)\in T‚Äô\newline<br>\hspace{1cm} \cdot \ ((q,\star),(c_{y_1},\dots,c_{y_k}),q‚Äô)\in T‚Äô\text{ if and only if there exists a word }c_{x,1}\dots c_{x,n}\in\lbrace0,1\rbrace^{+}\newline<br>\hspace{1cm} \  \text{ such that }(q,(c_{x,1},c_{y_1},\dots,c_{y_k})\dots(c_{x,n},c_{y_1},\dots,c_{y_k}),q‚Äô)\in T‚Äô\end{array}$</p></blockquote><p>Two remarks are in order:</p><ol><li><p>We extended the transition relation $T$ to $Q\times\Sigma^+\times Q$: if $(q,u,q‚Äô)\in T$ and $(q‚Äô,v,q‚Äô‚Äô)\in T$, then $(q,uv,q‚Äô‚Äô)\in T$ (where $\Sigma^+ &#x3D; \Sigma\Sigma^\ast$).</p></li><li><p>The transitions from the freshly added initial states can be readily determined, via, for example, a depth-first search by considering an appropriate subgraph induced by the automaton $\mathcal{A_\varphi}$.</p></li></ol><p>This concludes the final inductive case, and, hence, the proof of Theorem 8.1.</p><hr><p>Next chapter: <a href="../agv9-1/">Automata-based LTL Model Checking with Sequential Circuits</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 8.4 -- Homogenous Inequality Testing is Automatic</title>
      <link href="/AGV/agv8-4/"/>
      <url>/AGV/agv8-4/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv8-3/">Translation from Linear Arithmetic to Automata</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In the previous <a href="../agv8-3/">section</a>, we used $x+y&#x3D;z$ as an example. By extend that into a more general inequality</p><p>$$g_1x_1+\dots+g_\ell x_\ell\leq h_1y_1+\dots +h_my_m$$</p><p>where $x_1,\dots,x_\ell,y_1,\dots,y_m$ are <strong>free variables</strong>, and $g_1,\dots,g_\ell,h_1,\dots,h_m$ are <strong>positive integer constants</strong>. Such inequality can be described by a B√ºchi automaton.</p><blockquote><p>$\textbf{Lemma 8.1. }\textit{Let }\lbrace x_1,\dots,x_\ell,y_1,\dots,y_m\textit{ be a set of free variables, and let }g_1,\dots,g_\ell,h_1,\dots,h_m\newline\textit{be positive integer constants. There exists a B√ºchi automaton }\mathcal{A}\textit{ such that}$</p><p>$$\mathcal{L(A)}&#x3D;\lbrace\alpha_\sigma\mid\sigma\models g_1x_1+\dots+g_\ell g_\ell\leq h_1 y_1+\dots+h_m y_m\rbrace$$</p></blockquote><p>It is easy to start with constructing an automaton $\mathcal{A}_{\textsf{valid},\ell+m}$ that checks whether the word $\alpha_\sigma$ is <em>well-formed</em>:</p><ol><li>checks that the separation symbol $({$},\dots,{$})$ occurs <strong>exactly once</strong>, and</li><li>the separation symbol does <strong>not</strong> appear at <strong>the beginning of the word</strong>.</li></ol><h3 id="A-Generalize-Example"><a href="#A-Generalize-Example" class="headerlink" title="A Generalize Example"></a>A Generalize Example</h3><ul><li><p>$D:\sum_{i}g_ix_i-\sum_{j}h_jy_j\leq0$, where $G&#x3D;\sum_{i}g_i$, and $H&#x3D;\sum_{j}h_j$. We define the  </p></li><li><p>$D_t$ &#x3D; <code>integer part</code>, $[D]_t$ &#x3D; <code>fractional part</code>, and observe that for all $t$:</p></li></ul><p>$$D_1&#x3D;-\sum_{i}g_ic_{x_{i},1}-(-\sum_{j}h_jc_{y_{j},1})&#x3D;\sum_{j}h_jc_{y_{j},1}-\sum_{i}g_ic_{x_{i},1},\newline D_{t+1}&#x3D;2D_t+\sum_{i}g_ic_{x_{i},t+1}-\sum_{j}h_jc_{y_{j},t+1},\newline -H\leq[D]_t\leq G.$$</p><p>The trichotomy is also completely analogous.</p><ul><li>If, for some $t$, we have $D_t&gt;H$, we have that $D&gt;0$, and the formula is violated.</li><li>If, for some $t$, we have $D_t&lt;‚àíG$, we have that $D&lt;0$, and the formula is satisfied.</li><li>If, for all $t$, we have $‚àíG\leq D_t\leq H$ we have that $D&#x3D;0$, and the formula is satisfied.</li></ul><p>Our automaton construction keeps track of $D_t$ using the recurrence above. Due to the trichotomy, we only need compute $D_t$ precisely as long as it is <strong>at least $‚àíG$ and at most $H$</strong>.</p><p>Thus, we have 3 types of states in the automaton:</p><ol><li><em>initialization</em> state</li><li>Precise value states within $‚àíG,\dots,0,\dots,H$ of $D_t$</li><li>trap states ($D_t$ has crossed $‚àíG (‚àí\infty)$ or $H (\infty)$)</li></ol><blockquote><p>$\textbf{Construction 8.1. } \text{Let }x_1,\dots,x_\ell,y_1,\dots,y_m\text{ be free variables, and let }g_1,\dots,g_\ell,\text{ and}\newline h_1,\dots,h_m,\text{ be positive integer constants with }\sum_{i}g_i&#x3D;G\text{ and }\sum_{j}h_j&#x3D;H\text{. We construct a}\newline\text{(deterministic) B√ºchi Automaton}\mathcal{A}&#x3D;(\Sigma,Q,I,T,\small\text{B√úCHI}\normalsize (F))\text{, such that}$</p><p>$$\mathcal{L(A)}&#x3D;\lbrace\alpha_\sigma\mid\sigma\models g_1x_1+\dots+g_\ell g_\ell\leq h_1 y_1+\dots+h_m y_m\rbrace \hspace{1cm}\text{ as follows,}$$</p><p>$\begin{array}{l}\hspace{1cm} \cdot \ \Sigma&#x3D;\lbrace {$}^{l+m}\cup(\lbrace0,1\rbrace^\ell\times\lbrace0,1\rbrace^m)\rbrace\hspace{1cm}((\ell\text{+m)-fold Cartesian product)}\newline<br>\hspace{1cm} \cdot \ Q&#x3D;\lbrace\textsf{init},-\infty,-G,-G+1,\dots,-1,0,1,\dots,H,\infty\rbrace\newline<br>\hspace{1cm} \cdot \ I&#x3D;\lbrace\textsf{init}\rbrace\newline<br>\hspace{1cm} \cdot \ F&#x3D;\lbrace-\infty,-G,-G+1,\dots,-1,0,1,\dots,H\rbrace\newline<br>\hspace{1cm} \cdot \ T\text{ is defined as follows:}\newline<br>\hspace{1.5cm} 1. \ (\textsf{init},(c_{x_1},\dots,c_{y_m}),q‚Äô))\in T\text{ if and only if }q‚Äô\in\sum_{j}h_jc_{y_j}-\sum_{i}g_ic_{x_i}\newline<br>\hspace{1.5cm} 2. \ (q,({$}\dots{$}),q)\in T\text{ for all }q\in Q\setminus\lbrace\textsf{init}\rbrace,\newline<br>\hspace{1.5cm} 3. \ (q_\infty,c,q_\infty)\in T\text{ for all }c\in\Sigma,q_\infty\in\lbrace-\infty,\infty\rbrace,\newline<br>\hspace{1.5cm} 4. \ \text{For }q\in\lbrace-G,\dots,0,\dots,H\rbrace,(q,(c_{x_1},\dots,c_{y_m}),q‚Äô)\in T\text{ if and only if }q‚Äô&#x3D;\textsf{next}\text{, where}\newline<br>\end{array}$<br>$$\textsf{next}&#x3D;\left\lbrace\begin{array}{cll}<br>2q+\sum_{i}g_ic_{x_{i}}-\sum_{j}h_jc_{y_{j}}&amp;\text{if}&amp;-G\leq2q+\sum_{i}g_ic_{x_{i}}-\sum_{j}h_jc_{y_{j}}\leq H \newline<br>\infty&amp;\text{if}&amp;2q+\sum_{i}g_ic_{x_{i}}-\sum_{j}h_jc_{y_{j}}&gt; H \newline<br>-\infty&amp;\text{if}&amp;2q+\sum_{i}g_ic_{x_{i}}-\sum_{j}h_jc_{y_{j}} &lt;-G \end{array}\right.$$</p></blockquote><h3 id="Explanation"><a href="#Explanation" class="headerlink" title="Explanation"></a>Explanation</h3><p>All possible transitions are those the criterion we mentioned above (according to the numbering):</p><ol><li>$D_1&#x3D;\sum_{j}h_jc_{y_{j},1}-\sum_{i}g_ic_{x_{i},1}$</li><li>The separation symbol does <strong>not</strong> appear at <strong>the beginning of the word</strong>.</li><li>$D_t$ has crossed $‚àíG (‚àí\infty)$ or $H (\infty)$ move to <em>trap states</em> and cannot leave</li><li>According to the trichotomy, we only need compute $D_t$ precisely as long as it is $‚àíG\leq D_t\leq H$.</li></ol><p>This completes the proof of Lemma 8.1. We remark that the same construction also works to check the following:</p><ul><li><strong>Strict Inequality:</strong> $g_1x_1+\dots+g_\ell x_\ell &lt; h_1y_1+\dots +h_my_m$ (by setting $F&#x3D;\lbrace‚àí\infty\rbrace$),</li><li><strong>Equality:</strong> $g_1x_1+\dots+g_\ell x_\ell &#x3D; h_1y_1+\dots +h_my_m$ (by setting $F&#x3D;\lbrace‚àíG,\dots,H\rbrace$),</li><li><strong>Reverse Inequality:</strong> $g_1x_1+\dots+g_\ell x_\ell \geq h_1y_1+\dots +h_my_m$ (by setting $F&#x3D;\lbrace‚àíG,\dots,H,\infty\rbrace$),</li><li><strong>Reverse Strict Inequality:</strong> $g_1x_1+\dots+g_\ell x_\ell &gt; h_1y_1+\dots +h_my_m$ (by setting $\infty\rbrace$).</li></ul><hr><p>Next chapter: <a href="../agv8-5/">From Linear Arithmetic to Automata</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 8.3 -- Translation from Linear Arithmetic to Automata</title>
      <link href="/AGV/agv8-3/"/>
      <url>/AGV/agv8-3/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv8-2/">Encoding real numbers</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><p>In this section, we will illustrate the key ideas in the translation from <strong>linear arithmetic</strong> to <strong>automata</strong> through a simple example.</p><p>Consider the formula $x+y&#x3D;z$ and the following encoding of the valuation $x\mapsto1$, $y\mapsto1$, $z\mapsto2$:</p><p>$$\alpha_\sigma&#x3D;\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\begin{bmatrix}0\newline 0\newline 1\end{bmatrix}<br>\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\begin{bmatrix}{$}\newline {$}\newline {$}\end{bmatrix}\left(\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}\right)^\omega &#x3D; \begin{bmatrix}x\newline y\newline z\end{bmatrix} &#x3D; \begin{bmatrix}1\newline 1\newline 2\end{bmatrix}$$</p><h3 id="Homogeneity"><a href="#Homogeneity" class="headerlink" title="Homogeneity"></a>Homogeneity</h3><p>A equation is <em>homogenous</em> if there are <strong>no constant terms</strong>. The key property of <strong>homogeneity</strong> is that we can simply scaling without being <strong>unbounded</strong>. In other words, for a <em>homogenous</em> equation $D$, we have:</p><blockquote><p>$D‚àº0$ (where $‚àº$ is an arbitrary (in)equality) <strong>if and only if</strong>, for all $k\in\mathbb{Z},2^k\cdot D‚àº0$. (Scaling behaviour)</p></blockquote><p>As we can see the equation $x+y&#x3D;z$ is <em>homogenous</em>, i.e., $D: x+y‚àíz &#x3D; 0$ and $2^k\cdot x+2^k\cdot y‚àí2^k\cdot z‚àº0$</p><p>We immediately observe that:</p><ul><li>$2^k\cdot D$ has <strong>constant sign</strong>,</li><li>If $D\neq0$, it is <strong>strictly increasing</strong> in $k$, and thus</li><li>For any threshold $N$, we will have that $|2^k\cdot D|&gt;N$ for all sufficiently large $k$.</li></ul><h3 id="Shifting-the-Delimiter"><a href="#Shifting-the-Delimiter" class="headerlink" title="Shifting the ${$}$ Delimiter"></a>Shifting the ${$}$ Delimiter</h3><p>The key observation is that multiplying by a power of $2$ &#x3D; shifting the ${$}$ delimiter in the binary representation.</p><p>$$\begin{bmatrix}x\newline y\newline z\end{bmatrix} &#x3D;<br>\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\begin{bmatrix}0\newline 0\newline 1\end{bmatrix}<br>\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\begin{bmatrix}{$}\newline{$}\newline{$}\end{bmatrix}<br>\left(\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}\right)^\omega&#x3D;<br>\begin{bmatrix}1\newline 1\newline 2\end{bmatrix},\newline<br>\begin{bmatrix}2^2\cdot x\newline 2^2\cdot y\newline 2^2\cdot z\end{bmatrix} &#x3D;<br>\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\begin{bmatrix}0\newline 0\newline 1\end{bmatrix}<br>\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}<br>\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}\begin{bmatrix}{$}\newline{$}\newline{$}\end{bmatrix}<br>\left(\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}\right)^\omega&#x3D;<br>\begin{bmatrix}2^2\cdot 1\newline 2^2\cdot 1\newline 2^2\cdot 2\end{bmatrix}&#x3D;<br>\begin{bmatrix}4\newline 4\newline 8\end{bmatrix},<br>$$</p><p>For any variable $z$, and $t\geq1$, we denote by $z_t$ the integer encoded by the leftmost $t$ digits of $z$ (the ${$}$ is ignored):</p><p>$$\begin{bmatrix}x\newline y\newline z\end{bmatrix} &#x3D;<br>\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\begin{bmatrix}0\newline 0\newline 1\end{bmatrix}<br>\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}<br>\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}\dots$$</p><p>$<br>\begin{array}{lclc}<br>\hspace{1cm}\cdot\ x_5 &#x3D;&amp; -2^4\cdot0+2^3\cdot0+2^2\cdot0+2^1\cdot1+2^0\cdot1&amp;&#x3D;&amp;3\newline<br>\hspace{1cm}\cdot\ y_3 &#x3D;&amp; -2^2\cdot0+2^1\cdot0+2^0\cdot0&amp;&#x3D;&amp;0\newline<br>\hspace{1cm}\cdot\ z_4 &#x3D;&amp; -2^3\cdot0+2^2\cdot1+2^1\cdot0+2^1\cdot0&amp;&#x3D;&amp;4\newline<br>\hspace{1cm}\cdot\ z_5 &#x3D;&amp; -2^4\cdot0+2^3\cdot1+2^1\cdot0+2^2\cdot0+2^0\cdot0&amp;&#x3D;&amp;8\newline<br>\end{array}<br>$</p><h3 id="key-linear-recurrence"><a href="#key-linear-recurrence" class="headerlink" title="key linear recurrence"></a>key linear recurrence</h3><p>We can see the above definition is initialized as $z_1&#x3D;‚àíc_{z,1}$, and <strong>key linear recurrence</strong> holds for any variable: $z_{t+1}&#x3D;2z_t+c_{z,t+1}$, where $c_{z,t+1}$ is the $(t+1)$-th digit from the left in the encoding of $z$.</p><p>Now, in our example we can define $D_t&#x3D;x_t+y_t‚àíz_t$, and by <strong>linearity</strong>, the same recurrences hold for $D_t$, too:</p><p>$$D_1&#x3D;c_{z,1}-c_{x,1}-c_{y,1}\newline D_{t+1}&#x3D;2D_t+c_{z,t}-c_{x,t}-c_{y,t}$$</p><p>Thus, we have $D_1&#x3D;0,D_2&#x3D;‚àí1,D_3&#x3D;‚àí2$, and $D_t&#x3D;‚àí2$ for subsequent $t$.</p><h3 id="Fractional-part"><a href="#Fractional-part" class="headerlink" title="Fractional part"></a>Fractional part</h3><p>To account for the digits other than the $t$ leftmost digits, we define the fractional part $\lbrack z\rbrack_t &#x3D; \sum_{i&#x3D;1}^{\infty}2^{-i}\cdot c_{z,t+i}$.</p><p>$$\begin{bmatrix}x\newline y\newline z\end{bmatrix} &#x3D;<br>\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\begin{bmatrix}0\newline 0\newline 1\end{bmatrix}<br>\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}<br>\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}\dots$$</p><p>$<br>\begin{array}{lclc}<br>\hspace{1cm}\cdot\ [x]_1 &#x3D;&amp; 2^{-1}\cdot0+2^{-2}\cdot0+2^{-3}\cdot1+2^{-4}\cdot1+\dots&amp;&#x3D;&amp;{1\over4}\newline<br>\hspace{1cm}\cdot\ [y]_2 &#x3D;&amp; 2^{-1}\cdot0+2^{-2}\cdot1+2^{-3}\cdot1+2^{-4}\cdot1+\dots&amp;&#x3D;&amp;{1\over2}\newline<br>\hspace{1cm}\cdot\ [z]_1 &#x3D;&amp; 2^{-1}\cdot1+2^{-2}\cdot0+2^{-3}\cdot0+\dots&amp;&#x3D;&amp;{1\over2}\newline<br>\hspace{1cm}\cdot\ [z]_3 &#x3D;&amp; 2^{-1}\cdot0+2^{-2}\cdot0+2^{-3}\cdot0+\dots&amp;&#x3D;&amp;0\newline<br>\end{array}<br>$</p><p>Here, we can see $0\leq[z]_t\leq1$, and that $z_t+[z]_t &#x3D; 2^k\cdot z$ for some $k\in\mathbb{Z}$.</p><blockquote><p>If the $2^k\cdot z$ doesn‚Äôt seem intuitive to you, check this out:<br>let say we have $z&#x3D;011{$}0111\dots &#x3D; 3+{1\over2}&#x3D;3.5$, and we set $t&#x3D;7$, so $z_7&#x3D;-2^6\cdot0+2^5\cdot1+2^4\cdot1+2^3\cdot0+2^2\cdot1+2^1\cdot1+2^0\cdot1&#x3D;55$ and $[z]_7&#x3D;{1\over2}+{1\over4}+{1\over8}+\cdots&#x3D;1$. Thus we have $z_7+[z]_7 &#x3D; 56 &#x3D; 2^4\cdot 3.5$.</p></blockquote><p>We can then extend the definition of fractional part to $D$ in the obvious way: $[D]_t &#x3D; [x]_t+[y]_t‚àí[z]_t$.<br>We thus have that $‚àí1\leq [D]_t\leq 2$, and that $D_t+[D]_t&#x3D;2^k\cdot D$ for some $k$.</p><ol><li><p>If $D_t&lt;‚àí2$ for some $t$. then $D_t+[D]_t&lt;0$. For the corresponding $k$, we have that $2^k \cdot D&lt;0$. Therefore $x+y-z&lt;0$ and thus we conclude $x+y&lt;z$.</p></li><li><p>If $D_t&gt;1$ for some $t$, then $D_t+[D]_t&gt;0$. For the corresponding $k$, we have that $2^k \cdot D&gt;0$. Therefore $x+y-z&gt;0$ and thus we conclude $x+y&gt;z$.</p></li><li><p>If $‚àí2\leq D_t\leq 1$ for all $t$, then $|D_t+[D]_t|\leq 3$. For arbitrarily large $k$, $|2^k\cdot D|\leq3$. This implies that $x+y&#x3D;z$ (only option left)</p></li></ol><h3 id="From-Linear-Arithmetic-to-Automaton"><a href="#From-Linear-Arithmetic-to-Automaton" class="headerlink" title="From Linear Arithmetic to Automaton"></a>From Linear Arithmetic to Automaton</h3><p>From the above deduction, $x+y&#x3D;z$ holds if and only if $‚àí2\leq D_t\leq 1$. To check whether it holds with an automaton, we use the encoding to compute the sequence $D_t$ <em>term by term</em>, and <strong>accept</strong> if and only if each term is at least $‚àí2$ and at most $1$.</p><p>Indeed, in our example, the sequence of terms is $0,‚àí1,‚àí2,‚àí2,\dots$, and we accept.</p><p>As an example, we could also consider a different encoding of $x\mapsto1$, $y\mapsto1$, $z\mapsto2$:</p><p>$$\alpha‚Äô_\sigma&#x3D;\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\begin{bmatrix}1\newline 1\newline 1\end{bmatrix}<br>\begin{bmatrix}{$}\newline {$}\newline {$}\end{bmatrix}\left(\begin{bmatrix}0\newline 0\newline 1\end{bmatrix}\right)^\omega &#x3D; \begin{bmatrix}x\newline y\newline z\end{bmatrix} &#x3D; \begin{bmatrix}1\newline 1\newline 2\end{bmatrix}$$</p><p>In this example the sequence of $D_t$ is $0, 1, 1, 1,\dots$, which is again bounded, and we accept.</p><p>On the other hand, a rejecting example may look like this:</p><p>$$\alpha_{\sigma‚Äô}&#x3D;\begin{bmatrix}0\newline 0\newline 1\end{bmatrix}\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}<br>\begin{bmatrix}{$}\newline {$}\newline {$}\end{bmatrix}\left(\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\right)^\omega &#x3D; \begin{bmatrix}x\newline y\newline z\end{bmatrix} &#x3D; \begin{bmatrix}1\newline 1\newline -2\end{bmatrix}$$</p><p>The sequence of $D_t$ is $1, 4, 8, 15,\dots$, which is out of bounded, and we reject.</p><hr><p>Next chapter: <a href="../agv8-4/">Homogenous Inequality Testing is Automatic</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 8.2 -- Encoding Real Numbers</title>
      <link href="/AGV/agv8-2/"/>
      <url>/AGV/agv8-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv8-1/">Linear Arithmetic (Theory)</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In last section, we have seen the definiton of Linera Arithmetic, which is similar to S1S. Let see how we can apply it in math and moreover, the connection between logic and automata.</p><h2 id="Encoding-Real-Numbers"><a href="#Encoding-Real-Numbers" class="headerlink" title="Encoding Real Numbers"></a>Encoding Real Numbers</h2><p>We can encode any real number $x\in\mathbb{R}$ into the form $(0+1)(0+1)^\ast{$}(0+1)^\omega$ in two steps:</p><h3 id="Step-1"><a href="#Step-1" class="headerlink" title="Step 1"></a>Step 1</h3><p>For a <em>real number</em> $x\in\mathbb{R}$, represent it as a pair $(x_I,x_F)$ so that $x&#x3D;x_I+x_F$.<br><strong>integer part</strong> &#x3D; $x_I\in\mathbb{Z}$, and <strong>fractional part</strong> &#x3D; $x_F\in[0, 1]$, a <em>real number</em> between $0$ and $1$ (both inclusive)</p><p>For example, the $1.5 &#x3D; (1, 0.5)$, and $-{2\over 3}&#x3D;(‚àí1, {1\over3})$. Note that <strong>integers</strong> always have two different representations depends on setting the <strong>fractional part</strong> as $0$ or $1$, and <strong>Negative sign</strong> can only be represented using the integer part. For example $3&#x3D;(2,1)$ or $(3,0)$</p><h3 id="Step-2"><a href="#Step-2" class="headerlink" title="Step 2"></a>Step 2</h3><p>Then we can further encode $(x_I,x_F)$ as an <strong>infinite word</strong> $w_I{$}\beta_F$,<br>$x_I$ is encoded as $w_I&#x3D;a_na_{n‚àí1}\dots a_0\in\lbrace 0,1\rbrace^\ast$, a <strong>finite nonempty word</strong>, and<br>$x_F$ is encoded as $\beta_F&#x3D;b_1b_2\dots\in\lbrace 0,1\rbrace^\omega$, an <strong>infinite word</strong> such that</p><p>$$x_I&#x3D;-a_n\cdot 2^n+  \sum_{i&#x3D;0}^{n-1}a_i\cdot 2^i<br>\hspace{2cm}\text{and}\hspace{2cm}<br>x_F&#x3D; \sum_{i&#x3D;1}^{\infty}b_i\cdot 2^{-i}$$</p><p>Note that now every pair has (infinitely) many different encodings because <a href="https://www.youtube.com/watch?v=CHbZvyvbu8I&ab_channel=Matt_Parker_2">digits are forever</a>:<br>for example, $(0,{1\over2})$ is encoded by all words in $0^\ast0{$}10^\omega &#x3D; {1\over2}+0+0+\dots$ and $0^\ast0{$}01^\omega&#x3D;0+{1\over4}+{1\over8}+\dots$.</p><p>As you may notice, we can always increase the length of the <strong>finite integer part</strong> by ‚Äòpadding‚Äô arbitrary finitely long $0$ and $1$ on positive and negative number respectively. This is becasue of the following property of the <strong>geometric-series sum</strong>: for all $a$, $n$, $k$, we have that:</p><p>$$-a_n\cdot 2^n&#x3D;-a\cdot 2^{n+k}+  \sum_{j&#x3D;0}^{k}a\cdot 2^{n+j}$$</p><p>For example, $110{$}0^\omega&#x3D;-1\ast2^2+1\ast2^1&#x3D;-2$, $11110{$}0^\omega&#x3D;-1\ast2^4+1\ast2^3+1\ast2^2+1\ast2^1&#x3D;-2$,</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><table><thead><tr><th align="left">$x\in\mathbb{R}$</th><th align="left">$(x_I,x_F)$</th><th align="left">$w_I{$}\beta_F$</th></tr></thead><tbody><tr><td align="left">$1$</td><td align="left">$(1, 0)$</td><td align="left">$0^\ast01{$}0^\omega$ and $0^\ast0{$}1^\omega$</td></tr><tr><td align="left">${4\over 3}$</td><td align="left">$(1, {1\over 3})$</td><td align="left">$0^\ast01{$}(01)^\omega$</td></tr><tr><td align="left">$-{3\over 2}$</td><td align="left">$(-2, {1\over 2})$</td><td align="left">$1^\ast10{$}10^\omega$</td></tr></tbody></table><p>$0^\ast&#x2F;1^\ast$ may be empty so make sure there is at least one $0$ or $1$ to ensure it is positive or negative, respectively.</p><h2 id="Encoding-Valuations-sigma-V‚Äô-rightarrow-mathbb-R"><a href="#Encoding-Valuations-sigma-V‚Äô-rightarrow-mathbb-R" class="headerlink" title="Encoding Valuations $\sigma:V‚Äô\rightarrow\mathbb{R}$"></a>Encoding Valuations $\sigma:V‚Äô\rightarrow\mathbb{R}$</h2><p>Assume there‚Äôs an arbitrary ordering of the <em>free</em> variables $V‚Äô&#x3D;\lbrace x_0,x_1,\dots,x_k\rbrace$. The valuation is then encoded as a word $\alpha_\sigma$ over the alphabet $\lbrace0,1\rbrace^k\cup\lbrace{$}\rbrace^k$. Each letter of the word $\alpha_\sigma$ is a tuple, where the $i$-th position indicates the encoding of $x_i$. Also, we ensure that the encodings of all $x_i$ synchronize on the separation symbol ${$}$</p><p>Continue the example, one possible encoding of the valuation $x_1\mapsto1$, $x_2\mapsto{4\over3}$, $x_3\mapsto-{3\over2}$ is the infinite word</p><p>$$\begin{bmatrix}0\newline 0\newline 1\end{bmatrix}\begin{bmatrix}0\newline 0\newline 1\end{bmatrix}<br>\begin{bmatrix}1\newline 1\newline 0\end{bmatrix}\begin{bmatrix}{$}\newline {$}\newline {$}\end{bmatrix}<br>\begin{bmatrix}0\newline 0\newline 1\end{bmatrix}\left(\begin{bmatrix}0\newline 1\newline 0\end{bmatrix}<br>\begin{bmatrix}0\newline 0\newline 0\end{bmatrix}\right)^\omega$$</p><p>In the next section, we will illustrate an example of translation from linear arithmetic to automata.</p><hr><p>Next chapter: <a href="../agv8-3/">Translation from Linear Arithmetic to Automata</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 8.1 -- Linear Arithmetic (Theory)</title>
      <link href="/AGV/agv8-1/"/>
      <url>/AGV/agv8-1/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv7-3/">Translating Alternating to Nondeterministic automata</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In the previous sections, we have seen that the automata machinery can be applied to logical problems by translating formulas into automata. We now study another application of the powerful connection between logic and automata, this time in the setting of real numbers.</p><h2 id="Theory-of-Linear-Arithmetic"><a href="#Theory-of-Linear-Arithmetic" class="headerlink" title="Theory of Linear Arithmetic"></a>Theory of Linear Arithmetic</h2><h3 id="Definitions-and-Semantics"><a href="#Definitions-and-Semantics" class="headerlink" title="Definitions and Semantics"></a>Definitions and Semantics</h3><p>Let $V$ be a set of <code>(first-order) variables</code>. The <strong>terms</strong> of linear arithmetic are defined by the following grammar:</p><p>$$t::&#x3D;0\mid1\mid x\mid t+t$$</p><p>The <strong>formulas</strong> of linear arithmetic are defined by the following grammar, where $x\in V$ is a variable:</p><p>$$\varphi::&#x3D;t\leq t\mid\neg\varphi\mid\varphi\wedge\varphi\mid\exists x.\varphi$$</p><p>Additionally, we allow the usual <strong>boolean connectives</strong> and introduce the following abbreviations:</p><p>$$\begin{array}{lrllllrll}<br>\cdot&amp;n&amp;:&#x3D;&amp;\overbrace{1+1+\dots+1}^{n\text{ times}},&amp;\hspace{2cm}&amp;\cdot&amp;nx&amp;:&#x3D;&amp;\overbrace{x+x+\dots+x}^{n\text{ times}},\newline<br>\cdot&amp;t\geq t‚Äô&amp;:&#x3D;&amp;t‚Äô\leq t,&amp;\hspace{2cm}&amp;\cdot&amp;t&lt;t‚Äô&amp;:&#x3D;&amp;t\leq t‚Äô\wedge\neg(t&#x3D;t‚Äô)\newline<br>\cdot&amp;t&#x3D;t‚Äô&amp;:&#x3D;&amp;t\leq t‚Äô\wedge t\geq t‚Äô,&amp;\hspace{2cm}&amp;\cdot&amp;t&gt;t‚Äô&amp;:&#x3D;&amp;t‚Äô&lt;t<br>\end{array}$$</p><p>The semantics of a formula is given relative to a valuation $\sigma:V\rightarrow\mathbb{R}$ that assigns to each variable a real number. The value of a term is then defined as follows:</p><p>$$\begin{array}{llll}<br>\hspace{1cm}\cdot\ \lbrack 0\rbrack_{\sigma} &#x3D; 0 &amp;<br>\hspace{1cm}\cdot\ \lbrack 1\rbrack_{\sigma} &#x3D; 1 &amp;<br>\hspace{1cm}\cdot\ \lbrack x\rbrack_{\sigma} &#x3D; \sigma(x) &amp;<br>\hspace{1cm}\cdot\ \lbrack t+u\rbrack_{\sigma} &#x3D;\lbrack t\rbrack_{\sigma}+\lbrack u\rbrack_{\sigma}\end{array}$$</p><p>$\models$ is the smallest relation that satisfies the following:</p><p>$$\begin{array}{lllllllllllll}<br>\cdot&amp;\sigma\models t\leq u&amp;\text{ iff }&amp;\lbrack t\rbrack_{\sigma}\leq\lbrack u\rbrack_{\sigma}\newline<br>\cdot&amp;\sigma\models\neg\varphi&amp;\text{ iff }&amp;\sigma\neg\models\varphi\newline<br>\cdot&amp;\sigma\models\varphi_0\wedge\varphi_1&amp;\text{ iff }&amp;\sigma\models\varphi_0\text{ and }\sigma\models\varphi_1\newline<br>\cdot&amp;\sigma\models\exists x.\varphi&amp;\text{ iff }&amp;\text{there is an }a\in\mathbb{R}\ \text{ s.t. }\ \sigma‚Äô\models\varphi\ \text{ and }\ \sigma‚Äô(y)&#x3D;\left\lbrace\begin{array}{cll}\sigma(y)&amp;\text{if}&amp;y\neq x\newline a&amp;\text{if}&amp;y&#x3D;x\end{array}\right.<br>\end{array}$$</p><p>Let $V‚Äô\subseteq V$ be the set of <strong>free</strong> variables occurring in the formula $\varphi$. The solutions of $\varphi$ are the set of all valuations $\sigma$ of $V‚Äô$ such that $\sigma\models\varphi$.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><table><thead><tr><th align="left"><strong>formula</strong></th><th align="left"><strong>Solution Space</strong></th><th align="left"><strong>Explaination</strong></th></tr></thead><tbody><tr><td align="left">$x‚àí1\geq1$</td><td align="left">$\lbrace x\mapsto a\in\mathbb{R}\mid a\geq2\rbrace$</td><td align="left">$x$ can be any real number, as long as it has to be larger than 2.</td></tr><tr><td align="left">$\exists y.\ x‚àí1\geq y$</td><td align="left">$\lbrace x\mapsto a\mid a\in\mathbb{R}\rbrace$</td><td align="left">For any real number $y$, we can always find an $x$ that is larger than $y$ after minus 1.</td></tr></tbody></table><hr><p>Next chapter: <a href="../agv8-2/">Encoding real numbers</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 7.3 -- Translating Alternating to Nondeterministic automata</title>
      <link href="/AGV/agv7-3/"/>
      <url>/AGV/agv7-3/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv7-2/">From LTL to Alternating B√ºchi Automata</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>The translation from alternating to nondeterministic automata is based on a representation of runs as directed acyclic graphs (DAGs). The idea is similar to the DAG representation we used in the complementation construction for nondeterministic B√ºchi automata in <a href="../agv5-1/">Section 5</a>.</p><p>There the DAG was used to represent the <strong>set of all runs</strong> of the nondeterministic automaton. The complement automaton would then ‚Äùguess‚Äù the DAG level-by-level. Here, the DAG is used to represent the <strong>branches of a (single) run</strong> of the alternating automaton. The idea is illustrated in the following example.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p><img src="/images/notes/uds/agv/7_3_eg.png"></p><blockquote><p>$\textbf{Definition 7.5. } \text{ A } \textit{run DAG }\text{ of an alternating B√ºchi automaton }\mathcal{A}\text{ on an infinite word }\alpha\text{ is a}\newline\text{DAG }(V,E)\text{, with }V\subseteq Q\times\mathbb{N}\text{ and }(q_0,0)\in V\text{, where}$</p><p>$\begin{array}{ll} \hspace{0.5cm} \cdot &amp; E\subseteq \bigcup_{i\in\mathbb{N}}(Q\times\lbrace i\rbrace)\times(Q\times\lbrace i+1\rbrace) \newline \hspace{0.5cm} \cdot &amp; \forall(q,i)\in V \ . \ \exists Y\subseteq Q\text{ s.t. } \newline &amp; Y\models\delta(q,\alpha(i)),Y\times\lbrace i+1\rbrace\subseteq V\text{ and }\lbrace(q,i)\rbrace\times (Y\times\lbrace i+1\rbrace)\subseteq E.\end{array}$</p></blockquote><ul><li>Every vertices are expressed in (state, letter index)</li><li>Edges are all possible paths from current state $q$</li></ul><p>A run DAG is <strong>accepting</strong> if every infinite path has infinitely many visits to $F\times\mathbb{N}$.</p><p>Our construction of the nondeterministic automaton will be <strong>based on run DAGs</strong> rather than trees.<br>However, <strong>not every run tree can be represented as a DAG</strong>. This is illustrated by the following example:</p><h3 id="Example-cont"><a href="#Example-cont" class="headerlink" title="Example (cont.)"></a>Example (cont.)</h3><p>The following run tree cannot be represented as a DAG, because there are two nodes that are both labeled with $\mathbf{q}$ has different children (one transits to $p$ and the other to $q$). We say this tree has <strong>memory</strong>.</p><p><img src="/images/notes/uds/agv/7_3_bold.png"></p><h3 id="Similar-Nodes-and-Memoryless-Tree"><a href="#Similar-Nodes-and-Memoryless-Tree" class="headerlink" title="Similar Nodes and Memoryless Tree"></a>Similar Nodes and Memoryless Tree</h3><p>We call two nodes $x_1, x_2\in\mathcal{T}$ in a run tree $(\mathcal{T},r)$ <strong>similar</strong> if</p><ul><li>$|x_1| &#x3D; |x_2|$ (same index), and</li><li>$r(x_1) &#x3D; r(x_2)$ (same state).</li></ul><p>We call a run tree <strong>memoryless</strong> if the subtrees starting in <strong>similar</strong> nodes have the <strong>same labels</strong>.<br>Memoryless run trees can be represented as DAGs.</p><blockquote><p>$\textbf{Definition 7.5. } \text{ A run tree }(\mathcal{T},r)\text{ is }\textit{memoryless }\text{ if for all similar nodes }x_1\text{ and }x_2\text{ and for all}\newline y\in D^\ast\text{ we have that }(x_1\cdot y\in\mathcal{T}\text{ iff }x_2\cdot y\in\mathcal{T} )\text{ and } r(x_1\cdot y) &#x3D; r(x_2\cdot y).$</p></blockquote><p>The following theorem shows that whenever there is an accepting run tree, there is also an accepting run tree that is memoryless. Hence, we can show some word are accpeted by the automaton by showing the <strong>existence of a memoryless run tree</strong>, or, equivalently, the <strong>existence of an accepting run DAG</strong>.</p><blockquote><p>$\textbf{Theorem 7.2. } \textit{ If an alternating B√ºchi automaton }\mathcal{A}\textit{ accepts a word }\alpha\textit{, then there exists a}\newline\textit{memoryless accepting run of }\mathcal{A}\textit{ on }\alpha.$</p></blockquote><h2 id="Proof-of-Memoryless-Run-exists"><a href="#Proof-of-Memoryless-Run-exists" class="headerlink" title="Proof of Memoryless Run exists"></a>Proof of Memoryless Run exists</h2><p>Let $(\mathcal{T},r)$ be an accepting run tree on $\alpha$ with directions $D$. We construct a memoryless run tree $(\mathcal{T‚Äô},r‚Äô)$ by copying from $(\mathcal{T},r)$. Inuitively, we pick, whenever there are multiple occurrences of the same state in $(\mathcal{T},r)$, the occurrence where the last visit to the accepting states was the <strong>longest time ago</strong>.</p><h3 id="gamma-mathcal-T-rightarrow-mathbb-N-number-of-steps-since-the-last-visit-to-F"><a href="#gamma-mathcal-T-rightarrow-mathbb-N-number-of-steps-since-the-last-visit-to-F" class="headerlink" title="$\gamma:\mathcal{T}\rightarrow\mathbb{N}$: number of steps since the last visit to $F$"></a>$\gamma:\mathcal{T}\rightarrow\mathbb{N}$: number of steps since the last visit to $F$</h3><ul><li><p>Initiate the run tree (root) with zero steps:</p><ul><li>$\gamma(\varepsilon)&#x3D;0$</li></ul></li><li><p>For $n$‚Äôs children $d$, it increase one step from $n$, unless $n$ is an accepting state then it resets to zero</p><ul><li>$\gamma(n\cdot d)&#x3D;\left\lbrace\begin{array}{ll} \gamma(n)+1 &amp; \text{if }r(n)\notin F\newline 0 &amp; \text{if }r(n)\in F\end{array}\right.$</li></ul></li></ul><p>Now, we can define the tree node that the last visit to the accepting states was the <strong>longest time ago</strong> based on $\gamma$.</p><h3 id="Delta-Q-times-mathbb-N-rightarrow-mathcal-T-mapping-to-return-node-visit-F-longest-time-ago"><a href="#Delta-Q-times-mathbb-N-rightarrow-mathcal-T-mapping-to-return-node-visit-F-longest-time-ago" class="headerlink" title="$\Delta:Q\times\mathbb{N}\rightarrow\mathcal{T}$: mapping to return node visit $F$ longest time ago"></a>$\Delta:Q\times\mathbb{N}\rightarrow\mathcal{T}$: mapping to return node visit $F$ longest time ago</h3><p>For state $q\in Q$ and level $n\in\mathbb{N}$, it returns a tree node $y\in\mathcal{T}$ that is the leftmost and visit $F$ longest time ago:</p><p>$$\begin{array}{ll}\Delta(q,n)&#x3D;&amp;\text{the leftmost }y\in\mathcal{T}\text{ with }|y|&#x3D;n\ \text{ s.t. }\ r(y)&#x3D;q\newline &amp; \text{and }\forall z\in\mathcal{T}.\ |z|&#x3D;n\wedge r(z)&#x3D;q\Rightarrow\gamma(z)\leq\gamma(y)\end{array}$$</p><h3 id="Construction-of-Memoryless-Run-Tree-mathcal-T‚Äô-r‚Äô"><a href="#Construction-of-Memoryless-Run-Tree-mathcal-T‚Äô-r‚Äô" class="headerlink" title="Construction of Memoryless Run Tree $(\mathcal{T‚Äô},r‚Äô)$"></a>Construction of Memoryless Run Tree $(\mathcal{T‚Äô},r‚Äô)$</h3><p>We now construct $(\mathcal{T‚Äô},r‚Äô)$ by copying from the nodes in $(\mathcal{T},r)$ indicated by $\Delta$:</p><ul><li><p>Both trees have same initial states (root):</p><ul><li>$\varepsilon\in\mathcal{T‚Äô}\text{ and }r‚Äô(\varepsilon)&#x3D;r(\varepsilon)$</li></ul></li><li><p>Children node $d$ in $\mathcal{T‚Äô}$ are $d$ with longest steps, and of course a child of $n$:</p><ul><li>$d\in\mathcal{T‚Äô}\text{ if and only if }\Delta(r‚Äô(n),|n|)\cdot d\in\mathcal{T}\text{ and } r‚Äô(n\cdot d)&#x3D;r(\Delta(r‚Äô(n),|n|)\cdot d)$</li></ul></li></ul><h3 id="mathcal-T‚Äô-r‚Äô-is-a-run-of-mathcal-A-on-alpha"><a href="#mathcal-T‚Äô-r‚Äô-is-a-run-of-mathcal-A-on-alpha" class="headerlink" title="$(\mathcal{T‚Äô},r‚Äô)$ is a run of $\mathcal{A}$ on $\alpha$"></a>$(\mathcal{T‚Äô},r‚Äô)$ is a run of $\mathcal{A}$ on $\alpha$</h3><ul><li>The root is labeled by the initial state: $r‚Äô(\varepsilon)&#x3D;r(\varepsilon)&#x3D;q_0$.</li><li>For some node $n\in\mathcal{T‚Äô}$, let node $q_n&#x3D;\Delta(r‚Äô(n),|n|)$ ($q_n$ visits $F$ longest time ago among all $n$)</li><li>Then, the set $\lbrace r(q_n\cdot d)\mid d\in D, q_n\cdot d \in \mathcal{T}\rbrace$ satisfies $\delta(r(q_n), \alpha(|q_n|))$ (path of $q_n$ in original tree exists)</li><li>Therefore $\lbrace r‚Äô(n\cdot d)\mid d\in D, n\cdot d \in \mathcal{T‚Äô}\rbrace\models\delta(r‚Äô(n), \alpha(|n|))$ (by the construction above)</li></ul><h3 id="mathcal-T‚Äô-r‚Äô-is-accepting"><a href="#mathcal-T‚Äô-r‚Äô-is-accepting" class="headerlink" title="$(\mathcal{T‚Äô},r‚Äô)$ is accepting"></a>$(\mathcal{T‚Äô},r‚Äô)$ is accepting</h3><p>First, we show that for every $n\in\mathcal{T‚Äô}$, the node obtained from the mapping is indeed the longest path, i.e. $\gamma(n)\leq\gamma(\Delta(r‚Äô(n),|n|))$. This is shown by induction on the length of $n$:</p><ul><li><p>for $n&#x3D;\varepsilon$ we have that $\gamma(n)&#x3D;0$</p></li><li><p>for $n&#x3D;n‚Äô\cdot d$ (where $d\in D$) we have:</p><ul><li>if $r(n‚Äô)\in F$, then $\gamma(n)&#x3D;0$</li><li>if $r(n‚Äô)\notin F$, then</li></ul></li></ul><p>$$\begin{array}{lcl} \gamma(\Delta(r‚Äô(n‚Äô\cdot d),|n‚Äô\cdot d|))&amp;\overset{\text{Def. }\Delta}{\geq}&amp;\gamma(\Delta(r‚Äô(n‚Äô),|n‚Äô|)\cdot d)\overset{\text{Def. }\gamma}{&#x3D;}1+\gamma(\Delta(r‚Äô(n‚Äô),|n‚Äô|))\newline&amp;\overset{\text{IH}}{\geq}&amp;1+\gamma(n‚Äô)\overset{\text{Def. }\gamma}{&#x3D;}\gamma(n‚Äô\cdot d)\end{array}$$</p><p>(Last visit of the Mapping of children of $n‚Äô$ $\geq$ Last visit of mapping of $n$‚Äôs children. By induction hypothesis, the children of $n‚Äô$ through the mapping $\Delta$ is never smaller than any other possible children of $m‚Äô$)</p><p>Assume $(\mathcal{T‚Äô},r‚Äô)$ constructed from a accepting $(\mathcal{T},r)$ is not accepting. Then there is an infinite branch that does not visit $F$ infinitely often, i.e. $n_0, n_1, n_2,\dots$ in $\mathcal{T‚Äô}$ and $\exists k\in\mathbb{N}$ such that $\forall j\geq k. r‚Äô(n_j)\notin F$.</p><p>Let $m_i&#x3D;\Delta(r‚Äô(n_i), |n_i|)\text{ for }i\geq k$. We have,</p><p>$$<br>\begin{array}{ccccc} \gamma(n_k)&amp;&lt;&amp;\gamma(n_{k+1})&amp;&lt;&amp;\dots\newline &#x2F;\mathord{\bigwedge} &amp;&amp; &#x2F;\mathord{\bigwedge}<br>\newline\gamma(m_k)&amp;&lt;&amp;\gamma(m_{k+1})&amp;&lt;&amp;\dots\end{array}<br>$$</p><p>So, for any $j\geq k$ it holds that $\gamma(m_j)\geq j‚àík$ (because there are at least $j-k$ steps without visiting $F$). Since $\mathcal{T}$ is finitely branching, there must be a branch with an infinite suffix of non-$F$ labeled positions. So we can always find the branch in $\mathcal{T}$ identical with the path with $m_i$ This contradicts the assumption $(\mathcal{T},r)$ is accepting.</p><blockquote><p>$\textbf{Corollary 7.1. }\textit{A word }\alpha\textit{ is accepted by an alternating B√ºchi automaton }\mathcal{A}\textit{ if and only if}\newline\mathcal{A}\textit{ has an accepting run DAG on }\alpha$</p></blockquote><h2 id="Translating-alternating-to-nondeterministic-automata"><a href="#Translating-alternating-to-nondeterministic-automata" class="headerlink" title="Translating alternating to nondeterministic automata"></a>Translating alternating to nondeterministic automata</h2><p>We are now ready to translate an alternating B√ºchi automaton into an equivalent nondeterministic B√ºchi automaton. The construction is due to Miyano and Hayashi (1984).</p><blockquote><p>$\textbf{Construction 7.2. }\text{For an alternating B√ºchi automaton }\mathcal{A}&#x3D;(\Sigma,Q,q_0,\delta,\small\text{B√úCHI} \normalsize(F))\text{, we}\newline\text{construct a nondeterministic B√ºchi automaton }\mathcal{A‚Äô}&#x3D;(\Sigma,Q‚Äô,I‚Äô,T‚Äô,\small\text{B√úCHI} \normalsize(F‚Äô))\text{ with }\mathcal{L(A)}&#x3D;\newline\mathcal{L(A‚Äô)}\text{ as follows:}$</p><p>$\begin{array}{ll}<br>\hspace{0.5cm} \cdot \ Q‚Äô&amp;&#x3D; 2^Q\times2^Q \newline<br>\hspace{0.5cm} \cdot \ I‚Äô&amp;&#x3D; \lbrace(\lbrace q_0\rbrace,\varnothing)\rbrace\newline<br>\hspace{0.5cm} \cdot \ T‚Äô&amp;&#x3D; \lbrace((X,\varnothing),\sigma,(X‚Äô,X‚Äô\setminus F))\mid X‚Äô\models\wedge_{q\in X}\delta(q,\sigma)\rbrace\ \cup\newline<br> &amp;\hspace{0.5cm} \lbrace((X,W),\sigma,(X‚Äô,W‚Äô\setminus F))\mid W\neq\varnothing,W‚Äô\subseteq X‚Äô, X‚Äô\models\wedge_{q\in X}\delta(q,\sigma),W‚Äô\models\wedge_{q\in W}\delta(q,\sigma)\rbrace\newline<br>\hspace{0.5cm} \cdot \ F‚Äô&amp;&#x3D; \lbrace(X,\varnothing)\mid X\subseteq Q\rbrace<br>\end{array}$</p></blockquote><h3 id="Modified-Example-from-section-7-1"><a href="#Modified-Example-from-section-7-1" class="headerlink" title="Modified Example from section 7.1"></a>Modified Example from section 7.1</h3><p><img src="/images/notes/uds/agv/7_3_alt.png"></p><table><thead><tr><th align="left"></th><th align="left">Example</th><th align="left">Explaination</th></tr></thead><tbody><tr><td align="left">$Q‚Äô$</td><td align="left">$X&#x3D;\lbrace\lbrace p\rbrace,\lbrace q\rbrace,\lbrace p,q\rbrace\rbrace$ </br>$W &#x3D; \lbrace\varnothing,\lbrace q\rbrace\rbrace$</td><td align="left">States Q‚Äô is a tuple consist of two <strong>set of states</strong> in $Q$, first one must be non-empty and the second one does not contain any states $q\in F$</td></tr><tr><td align="left">$I‚Äô$</td><td align="left">$I‚Äô&#x3D;(\lbrace p\rbrace,\varnothing)$</td><td align="left">1st element is the initial state while the second element is empty</td></tr><tr><td align="left">$T‚Äô$</td><td align="left">$(\lbrace p\rbrace,\varnothing)\overset{b}{\longrightarrow}(\lbrace p,q\rbrace,$ $\lbrace \lbrace p,q\rbrace\setminus\lbrace p\rbrace\rbrace)&#x3D;(\lbrace p,q\rbrace,\lbrace q\rbrace)$</td><td align="left">$X$ represent the behaviour of the original automata, while $W$ tracks whether the original accepting states are visited after the transition.</td></tr><tr><td align="left">$T‚Äô$</td><td align="left">$(\lbrace p,q\rbrace,\lbrace q\rbrace) \overset{b}{\longrightarrow}(\lbrace p,q\rbrace,\varnothing)$ $(\delta(p,b)&#x3D;p\wedge q,\delta(q,b)&#x3D;\textit{true}&#x3D;\varnothing$ $\therefore\delta(p\wedge q,b)&#x3D;p\wedge q.)$</td><td align="left">If $W$ is empty, it means accepting states is reached and next transition we start again on tracking. If $W$ is non-empty, then its behaviour align with $X$</td></tr><tr><td align="left">$F‚Äô$</td><td align="left">$F‚Äô&#x3D;\lbrace(\lbrace p\rbrace,\varnothing), (\lbrace p,q\rbrace,\varnothing)\rbrace$</td><td align="left">The run&#x2F;word is aceepting if $W$ is empty infinite often.</td></tr></tbody></table><blockquote><p>$\textbf{Theorem 7.3. } \text{(Miyano and Hayashi, 1984). }\textit{For every alternating B√ºchi automaton }\mathcal{A}\textit{, we can}\newline\textit{effectively construct a nondeterministic B√ºchi automaton }\mathcal{A‚Äô}\textit{ with }\mathcal{L(A)}&#x3D;\mathcal{L(A‚Äô)}.$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><blockquote><p>$\mathcal{L(A)}\supseteq\mathcal{L(A‚Äô)}$ (all word accepted by $\mathcal{L(A‚Äô)}$ must also be accepted by $\mathcal{L(A)}$):</p></blockquote><p>Let $\alpha\in\mathcal{L(A‚Äô)}$ with an accepting run $r‚Äô&#x3D;(X_0,W_0)(X_1,W_1)(X_2,W_2)\dots$<br>where $W_0 &#x3D;\varnothing$ and $X_0&#x3D;\lbrace q_0\rbrace$. We construct the run DAG $(V,E)$ for $\mathcal{A}$ on $\alpha$:</p><ul><li><p>All vertices in DAG in level $i$ come from the tree in level $i$:</p><ul><li>$V&#x3D;\lbrace (x,i)\mid i\in\mathbb{N}, x\in X_i\rbrace$</li></ul></li><li><p>$X_i$ represent the behaviour of the automaton and $W_i$ is for tracking whether the states are accepting.<br> If the state is not tracked by $W_i$, i.e. $(x\in X_i \setminus W_i)$, that means it is accepted, no extra tracking is needed,<br> If it is tracked, i.e. $(x\in W_i)$, it either moves to some accepting state or it is continue tracked $(F\cup W_{i+1})$:</p><ul><li>$E&#x3D;\lbrace((x,i),(x‚Äô,i+1))\mid i\in\mathbb{N}, x\in X_i \setminus W_i, x‚Äô\in X_{i+1}\rbrace\cup\newline\hspace{0.95cm}\lbrace((x, i),(x‚Äô,i+1))\mid i\in\mathbb{N}, x\in W_i, x‚Äô\in X_{i+1}\cap (F\cup W_{i+1})\rbrace$</li></ul></li></ul><p>First, we show that $(V,E)$ is a run DAG: $(q_0,0)\in V$ and for every $(x,i)\in V$:</p><ul><li>The state is accepted, any transitions from here are valid:<ul><li>if $x\in X_i\setminus W_i,\ X_{i+1}\models\delta(x,\alpha(i))$;</li></ul></li><li>The state is tracked, only transitions to accepting state or continue tracked are valid:<ul><li>if $x\in W_i, x‚Äô\in X_{i+1}\cap (F\cup W_{i+1})\models\delta(x,\alpha(i))$.</li></ul></li></ul><p>Since the automata is accepting, so it has $W_i&#x3D;\varnothing$ exist for infinitely many $i$. So the run DAG is accepting, because there is $x\in X_i\setminus W_i$ infinitely often, every path through the run DAG visits $F$ infinitely often.</p><blockquote><p>$\mathcal{L(A)}\subseteq\mathcal{L(A‚Äô)}$ (all word accepted by $\mathcal{L(A)}$ must also be accepted by $\mathcal{L(A‚Äô)}$):</p></blockquote><p>Let $\alpha\in\mathcal{L(A)}$ and $(V,E)$ be an accepting run DAG of $\mathcal{A}$ on $\alpha$.<br>We construct a run $r‚Äô&#x3D;(X_0,W_0)(X_1,W_1)(X_2,W_2)\dots$ on $\mathcal{A‚Äô}$ as follows:</p><ul><li><p>$X_0&#x3D;\lbrace q_0\rbrace$ and $W_0&#x3D;\varnothing$</p></li><li><p>We simulate the behaviour using $X_i$: for $i\geq 0$, let $X_{i+1} &#x3D; \lbrace x‚Äô\in Q\mid ((x,i),(x‚Äô,i+1))\in E, x\in X_i\rbrace$</p><ul><li>If the state is accepted, align the behaviour with $X$:<br>$W_{i+1} &#x3D; X_{i+1} \setminus F$ if $W_i&#x3D;\varnothing$</li><li>If not, track and see if the accepting condition is fulfiled: $W_{i+1} &#x3D; \lbrace x‚Äô\in Q \setminus F \mid\exists(x,i)\in V, ((x,i),(x‚Äô,i+1))\in E,x\in W_i\rbrace$.</li></ul></li></ul><p>Clearly, $r‚Äô$ is a run: it starts with $(\lbrace q_0\rbrace,\varnothing)$ and obeys $T‚Äô$. That is, $(X_{i+1},W_{i+1})$ contains states in $\delta(x,\alpha(i))$:</p><ul><li>For $x\in X_i\setminus W_i$, we have that $X_{i+1}\models\delta(x,\alpha(i))$;</li><li>For $x\in W_i$, $X_{i+1}\cap (F\cup W_{i+1})$ satisfies $\delta(x,\alpha(i))$.</li></ul><p>The run $r‚Äô$ is accepting, otherwise some state $(X_{i+1},W_{i+1})$ is rejected, and thus rejects the path in $(V,E)$.</p><h3 id="Example-with-the-construction"><a href="#Example-with-the-construction" class="headerlink" title="Example with the construction"></a>Example with the construction</h3><p><img src="/images/notes/uds/agv/7_3_nonde.png"></p><blockquote><p>$\textbf{Corollary 7.2. }\textit{A language is }\omega\textit{-regular if and only if it is recognizable by an alternating B√ºchi automaton.}$</p></blockquote><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In this section, we have proved that any $\omega$-regular language can be recongnized by some alternating B√ºchi automaton. Let see how it is done.</p><ol><li><p>Every accepted word in an alternating B√ºchi automaton has an <strong>Memoryless Accepting Run</strong> (<em>Theorem 7.2</em>).</p></li><li><p>Every <strong>Memoryless Run Tree</strong> can be represented as a <strong>Run DAG</strong></p></li><li><p>Thus, Every accepted word in an alternating B√ºchi automaton has an <strong>Accepting Run DAG</strong> (<em>Corollary 7.1</em>).</p></li><li><p>For every <strong>Alternating B√ºchi Automaton</strong> there exists a <strong>Nondeterministic B√ºchi Automaton</strong> (<em>Theorem 7.3</em>).</p></li><li><p>An $\omega$-language is B√ºchi-recognizable iff it is $\omega$-regular (B√ºchi‚Äôs Characterization Theorem) (<em>Theorem 3.6</em>).</p></li><li><p>An $\omega$-language is <strong>Alternating</strong> B√ºchi-recognizable iff it is $\omega$-regular (<em>Corollary 7.2</em>).</p></li></ol><hr><p>Next chapter: <a href="../agv8-1/">Linear Arithmetic (Theory)</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 7.2 -- From LTL to Alternating B√ºchi Automata</title>
      <link href="/AGV/agv7-2/"/>
      <url>/AGV/agv7-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv7-1/">Alternating B√ºchi Automata</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>It is usually much simpler to translate a logical formula into an alternating automaton than into a nondeterministic automaton. We illustrate this with the translation of LTL formulas into equivalent alternating B√ºchi automata. The states are simply the subformulas of the given formula and their negations (this set is called the <em>closure</em> of the formula). The transition function is derived from the <em>expansion laws</em> of the logic.</p><p>For example, an <code>Until</code> formula $\varphi_1\ \mathcal{U}\ \varphi_2$ holds if:</p><ul><li>$\varphi_2$ holds <strong>or</strong></li><li>$\varphi_1$ holds <strong>and</strong> the entire formula holds in the next step.</li></ul><p>The boolean formula produced by the transition function from the state $\varphi_1\ \mathcal{U}\ \varphi_2$ is therefore:</p><ul><li>a <code>disjunction</code> $(\wedge)$ between the transition function for $\varphi_2$ and</li><li>a <code>conjunction</code> $(\vee)$ between the transition function for $\varphi_1$ and the state $\varphi_1\ \mathcal{U}\ \varphi_2$.</li></ul><h2 id="From-LTL-to-Alternating-Automata"><a href="#From-LTL-to-Alternating-Automata" class="headerlink" title="From LTL to Alternating Automata"></a>From LTL to Alternating Automata</h2><blockquote><p>$\textbf{Construction 7.1. }\text{Let }\varphi\text{ be an LTL formula. We construct the alternating B√ºchi automaton }\newline\mathcal{A_\varphi}&#x3D;(\Sigma,Q,\varphi,\delta,\small\text{B√úCHI} \normalsize(F))\text{ using:}$<br>$\begin{array}{ll}<br>\hspace{0.5cm} \cdot \ Q &#x3D; \text{closure}(\varphi):&#x3D;\lbrace\psi,\neg\psi\mid\psi\text{ is subformula of }\varphi\rbrace \newline<br>\hspace{0.5cm} \cdot \ \delta(p,a)&#x3D;  \left\lbrace \begin{array}{ll}\textit{true}&amp;\text{if }p\in a\newline \textit{false}&amp;\text{if }p\not\in a\end{array}\right. &amp;\cdot \ \delta(\neg\psi,a)&#x3D;\overline{\delta(\psi,a)}\newline<br>\hspace{0.5cm} \cdot \ \delta(\psi_1\wedge\psi_2,a)&#x3D;\delta(\psi_1,a)\wedge\delta(\psi_2,a) &amp;\cdot \ \delta(\psi_1\vee\psi_2,a)&#x3D;\delta(\psi_1,a)\vee\delta(\psi_2,a)\newline<br>\hspace{0.5cm} \cdot \ \delta(\psi_1\ \mathcal{U}\ \psi_2,a)&#x3D;\delta(\psi_2,a)\vee(\delta(\psi_1,a)\wedge\psi_1\ \mathcal{U}\ \psi_2)&amp;\cdot \ \delta(\bigcirc\psi,a)&#x3D;\psi\newline<br>\hspace{0.5cm} \cdot \ F &#x3D; \lbrace\neg(\psi_1\ \mathcal{U}\ \psi_2)\in\text{clousure}(\varphi)\rbrace<br>\end{array}\newline$<br>$\text{where we define }\overline{\varphi}&#x3D;\neg\varphi\text{ for all other }\psi\in Q\text{ and }\overline{\ \cdot\ }\text{ for }\psi,\psi_1,\psi_2\in Q\text{ via:}$<br>$\begin{array}{ll}<br>\hspace{0.5cm} \cdot \ \overline{\neg\varphi}&#x3D;\varphi<br>\hspace{0.5cm} \cdot \ \overline{\psi_1\wedge\psi_2}&#x3D;\overline{\psi_1}\vee\overline{\psi_2}<br>\hspace{0.5cm} \cdot \ \overline{\psi_1\vee\psi_2}&#x3D;\overline{\psi_1}\wedge\overline{\psi_2}<br>\hspace{0.5cm} \cdot \ \overline{\textit{true}}&#x3D;\overline{\textit{false}}<br>\hspace{0.5cm} \cdot \ \overline{\textit{false}}&#x3D;\overline{\textit{true}}<br>\end{array}$</p></blockquote><h2 id="Explanation-and-Examples-in-Human-language"><a href="#Explanation-and-Examples-in-Human-language" class="headerlink" title="Explanation and Examples in Human language"></a>Explanation and Examples in Human language</h2><p>Remember that $\delta$ function returns <em>set of states</em>.</p><p>As we can see most of the function here don‚Äôt actually have a designated successor except for <strong>atomic proposition</strong> $p$, <strong>neXt</strong> $\bigcirc$, and <strong>Until</strong> $\mathcal{U}$.</p><p>For example, here are simple steps to construct a automaton for a formula $p\wedge\bigcirc q$:</p><ol><li><p>List of all possible atomic propositions input: $\sigma&#x3D;\lbrace\lbrace\varnothing\rbrace,\lbrace p\rbrace,\lbrace q\rbrace,\lbrace p,q\rbrace\rbrace$</p></li><li><p>Write a truth table basic on the formula and its corresponding function $\delta$:<br>$\ \newline\hspace{1cm}\delta(p\wedge\bigcirc q,\sigma) &#x3D; \delta(p,\sigma)\wedge\delta(\bigcirc q,\sigma)&#x3D;\delta(p,\sigma)\wedge q<br>\newline\ \newline<br>\hspace{1cm}\cdot \ \delta(\bigcirc q,\sigma)&#x3D;\left\lbrace \begin{array}{ll}<br>q&amp;\text{if }\sigma&#x3D;\lbrace\varnothing\rbrace,\lbrace q\rbrace,\lbrace p\rbrace,\lbrace p,q\rbrace\end{array} \right. \newline\ \newline<br>\hspace{1cm}\cdot \ \delta(p,\sigma)&#x3D;\left\lbrace\begin{array}{ll}<br>\textit{false}&amp;\text{if }\sigma&#x3D;\lbrace\varnothing\rbrace,\lbrace q\rbrace\newline<br>\textit{true}&amp;\text{if }\sigma&#x3D;\lbrace p\rbrace,\lbrace p,q\rbrace\end{array}\right.<br>\hspace{1cm}\cdot \ \delta(q,\sigma)&#x3D;\left\lbrace\begin{array}{ll}<br>\textit{false}&amp;\text{if }\sigma&#x3D;\lbrace\varnothing\rbrace,\lbrace p\rbrace\newline<br>\textit{true}&amp;\text{if }\sigma&#x3D;\lbrace q\rbrace,\lbrace p,q\rbrace\end{array}\right.<br>\newline\ \newline\hspace{1cm}\therefore\ \delta(p\wedge\bigcirc q,\sigma)&#x3D;\left\lbrace\begin{array}{ll}<br>\textit{false}\wedge q &#x3D; \textit{false}&amp;\text{if }\sigma&#x3D;\lbrace\varnothing\rbrace,\lbrace q\rbrace\newline<br>\textit{true}\wedge q &#x3D; q&amp;\text{if }\sigma&#x3D;\lbrace p\rbrace,\lbrace p,q\rbrace\end{array}\right.<br>$</p></li><li><p><strong>Initial state</strong> is always the orginal formula, then we add extra state according to the truth table we constructed. Here, our graph have no <strong>universal</strong> or <strong>nondeterministic</strong> transitions:</p></li></ol><p><img src="/images/notes/uds/agv/7_2_next.png"></p><p>For a more complicated example, i.e. $((\Diamond p)\ \mathcal{U}\ (\square q))$, check <a href="../agv7-2-eg/">here</a> as an extra material</p><blockquote><p>$\textbf{Theorem 7.1. } \textit{For every LTL formula }\varphi\textit{, there is an alternating B√ºchi automaton }\mathcal{A_\varphi}\newline\textit{with }\mathcal{L(A_\varphi)} &#x3D; \mathcal{L(\varphi)}.$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>We can simply prove this by induction. First, any LTL formula $\varphi$ can be recursively seperate into smaller subformula, namely $\psi$.</p><p>Similarly we can construct automaton $\mathcal{A^\psi_\varphi}$ from $\mathcal{A_\varphi}$ according to above construction 7.1. By structural induction on $\psi$, we can then prove that $\mathcal{L(A^\psi_\varphi)&#x3D;L(A_\varphi)}$.</p><hr><p>Next chapter: <a href="../agv7-3/">Translating Alternating to Nondeterministic automata</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 7.1 -- Alternating B√ºchi Automata</title>
      <link href="/AGV/agv7-1/"/>
      <url>/AGV/agv7-1/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv6-7/">S1S$_0$ and B√ºchi-recognizable Language</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Logics are often significantly more concise than automata. For example, in the translation from S1S to B√ºchi automata in the proof of <a href="../agv6-7/">Theorem 6.4</a>, each negation increases the size of the B√ºchi automaton exponentially, resulting in a non-elementary number of states. The blow-up when translating LTL formulas is less dramatic, but still exponential. In this section, we show that the conciseness of the logic and the automata can be brought closer together when the automata are equipped with both <strong>nondeterministic</strong> and <strong>universal</strong> choices.</p><h2 id="Alternating-Automata"><a href="#Alternating-Automata" class="headerlink" title="Alternating Automata"></a>Alternating Automata</h2><h3 id="Nondeterministic-and-Universal"><a href="#Nondeterministic-and-Universal" class="headerlink" title="Nondeterministic and Universal"></a>Nondeterministic and Universal</h3><p>In previous sections, we discussed a lot about <strong>Nondeterministic</strong> transitions. Here we introduce a new concept <strong>Universal</strong> transitions for our new automaton called alternating automaton. We allow for both types of choices by defining, for each state and input letter, a <strong>positive Boolean formula</strong> over the successor states.</p><table><thead><tr><th align="left">Choices</th><th align="left">Symbol</th><th align="left">Definition</th></tr></thead><tbody><tr><td align="left"><strong>Nondeterministic</strong></td><td align="left">disjunction $(\vee)$</td><td align="left">the suffix of an input word is <strong>accepted by SOME</strong> successor state</td></tr><tr><td align="left"><strong>Universal</strong></td><td align="left">conjunction $(\wedge)$</td><td align="left">the suffix of an input word is <strong>accepted by ALL</strong> successor states</td></tr></tbody></table><h3 id="Positive-Boolean-Formulas-mathbb-B-X"><a href="#Positive-Boolean-Formulas-mathbb-B-X" class="headerlink" title="Positive Boolean Formulas $\ \mathbb{B}^+(X)$"></a>Positive Boolean Formulas $\ \mathbb{B}^+(X)$</h3><blockquote><p>$\textbf{Definition 7.1. } \text{The }\textit{positive Boolean formulas }\text{over a set }X\text{, denoted }\mathbb{B}^+(X)\text{, are the formulas}\newline\text{built from elements of }X\text{, conjunction }\wedge\text{, disjunction }\vee,\textit{ true}\text{ and }\textit{false.}$</p></blockquote><p>In our automata construction, elements of $X$ will be <strong>states</strong>. Let say we have a set of states $Y\subseteq X$.<br>We denote $Y\models\varphi$ if $Y$ satisfies a formula $\varphi\in\mathbb{B^+}(X)$. In other words:</p><ul><li>all states in $Y$ will be assigned as $\textit{true}$ by $\varphi$, and</li><li>all states in $X\setminus Y$ will be assigned as $\textit{false}$ by $\varphi$.</li></ul><h3 id="Trees-and-Runs"><a href="#Trees-and-Runs" class="headerlink" title="Trees and Runs"></a>Trees and Runs</h3><blockquote><p>$\textbf{Definition 7.2. } \text{ An } \textit{Alternating automaton over infinite words }\mathcal{A}\newline\text{ is a tuple }\mathcal{A} &#x3D; (\Sigma,Q,q_0,\delta,Acc)\text{, where}\newline\begin{array}{ll}<br>\hspace{1cm} \cdot \ Q &amp;\text{ is a finite set of states} \newline<br>\hspace{1cm} \cdot \ q_0 \in Q&amp; \text{ is the initial states} \newline<br>\hspace{1cm} \cdot \ \delta:Q\times\Sigma\rightarrow\mathbb{B^+}(Q)&amp; \text{ is the } \textit{transition functions}\text{, and} \newline<br>\hspace{1cm} \cdot \ Acc \subseteq Q^\omega&amp; \text{ is an accepting condition.}<br>\end{array}$</p></blockquote><p>For alternating automata, runs generalize from sequences to <strong>trees</strong>. Here we define a tree as a <strong>prefix-closed subset</strong>, guarantees that all nodes must be able to trace all the back the <strong>root</strong> of the tree.</p><blockquote><p><strong>prefix-closed subset</strong>:<br>If a word $w&#x3D;\lbrace ab\rbrace^\omega$ is in the set, then all its prefix (i.e. $\lbrace ab\rbrace,\lbrace aba\rbrace,\lbrace abab\rbrace,\dots$) must also be in the set.</p></blockquote><table><thead><tr><th align="left">Name</th><th align="left">Symbol&#x2F;Functions</th><th align="left">Definition</th></tr></thead><tbody><tr><td align="left"><strong>Set of Squences</strong></td><td align="left">$D^\ast$</td><td align="left">All possible sequence of every word by direction $D$</td></tr><tr><td align="left"><strong>Set of Directions</strong></td><td align="left">$D$</td><td align="left">Branches possible in each node</td></tr><tr><td align="left"><strong>Tree</strong></td><td align="left">$\mathcal{T}$</td><td align="left">Sequence of ONE word, a prefix-closed subset of $D^*$</td></tr><tr><td align="left"><strong>Root</strong></td><td align="left">$\varepsilon$</td><td align="left">The Empty Sequence</td></tr><tr><td align="left"><strong>Node</strong></td><td align="left">$n\in\mathcal{T}$</td><td align="left">Depends on the label, it may be the states or the letters</td></tr><tr><td align="left"><strong>Children of $n$</strong></td><td align="left">$\text{children}(n)&#x3D;\lbrace n\cdot d\in \mathcal{T}\mid d\in D\rbrace$</td><td align="left">Succssor states of $n$ over direction $d$</td></tr><tr><td align="left"><strong>$Q$-labeled tree</strong></td><td align="left">$(\mathcal{T},\ell)$</td><td align="left">A tree that labels nodes with the states</td></tr><tr><td align="left"><strong>$\Sigma$-labeled tree</strong></td><td align="left">$(\mathcal{T},\ell)$</td><td align="left">A tree that labels nodes with the input letters</td></tr><tr><td align="left"><strong>Labeling Function</strong></td><td align="left">$\ell:\mathcal{T}\rightarrow\Sigma$</td><td align="left">Label each node of the tree with the input letters for $\Sigma$-labeled tree</td></tr></tbody></table><p>Below, we define a <strong>run</strong> of an alternating autoamton using <strong>$Q$-labeled tree</strong>:</p><blockquote><p>$\textbf{Definition 7.3. } \text{ A } \textit{run }\text{of an alternating automaton on a word }\alpha\in\Sigma^\omega\newline\text{ is a Q-labeled tree (T , r) with the following properties:}\newline<br>\begin{array}{l}<br>\hspace{1cm} \cdot \ r(\varepsilon)&#x3D;q_0\text{ and}\newline<br>\hspace{1cm} \cdot \ \text{for all }n\in\mathcal{T}\text{, if }r(n)&#x3D;q\text{, then }\lbrace r(n‚Äô)\mid n‚Äô\in\text{children}(n)\rbrace\ \text{ satisfies }\delta(q,\alpha(|n|)).<br>\end{array}$</p></blockquote><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>The following alternating B√ºchi automaton recognizes the language $L&#x3D;((a+b)^\ast b)^\omega$. Universal choice $(\wedge)$ are depicted by connecting the edges with a small arc $(\blacksquare)$. The transition function $(\delta)$ is given as follows:</p><ul><li>$\delta(p,a)&#x3D;p\wedge q$,</li><li>$\delta(p,b)&#x3D;p$,</li><li>$\delta(q,a)&#x3D;q$,</li><li>$\delta(q,b)&#x3D;\textit{true}$.</li></ul><p><img src="/images/notes/uds/agv/7_1_alt.png"></p><p>On the input word $\alpha&#x3D;(aab)^\omega$, our automaton has the following run. Note that, in general, an alternating automaton may have more than one run on a particular word, or also no run at all. We use a <strong>dotted line</strong> to indicate that the subtree repeats infinitely often.</p><p><img src="/images/notes/uds/agv/7_1_tree.png"></p><p>Similar to DAG, we can apply the <strong>acceptance condition</strong> only on <strong>all infinite branches</strong> of the run tree. A <em>branch</em> of a tree $\mathcal{T}$ is a <strong>maximal sequence</strong> of words $n_0n_1n_2\dots$ such that $n_0&#x3D;\varepsilon$ and $n_{i+1}$ is a child of $n_i$ for $i\geq0$.</p><p>Obviously, if every infinite branch is accepting, then the entire tree is thus accepting, i.e. there‚Äôs no way to pick a non-accepting path for to be the run.</p><blockquote><p>$\textbf{Definition 7.4. } \text{A run }(\mathcal{T},r)\text{ is }\textit{accepting }\text{iff, for every infinite branch }n_0n_1n_2\dots,$<br>$$r(n_0)r(n_1)r(n_2)\dots\in Acc.$$</p></blockquote><hr><p>Next chapter: <a href="../agv7-2/">From LTL to Alternating B√ºchi Automata</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 6.7 -- S1S$_0$ and B√ºchi-recognizable Language</title>
      <link href="/AGV/agv6-7/"/>
      <url>/AGV/agv6-7/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv6-6/">Express QPTL using S1S</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>To prepare for the proof that every S1S-definable language is B√ºchi-recognizable, we show in the following lemma that we can focus on a restricted sublogic, called S1S$_0$, which is defined by the following grammar:</p><p>$$\varphi::&#x3D;0\in X\mid x\in Y\mid x&#x3D;0\mid x&#x3D;y\mid x&#x3D;S(y)\mid \neg\varphi\mid\varphi\wedge\varphi\mid\exists x.\varphi\mid\exists X.\varphi$$</p><ul><li><strong>Membership tests</strong> $(\in)$: variables $(x,y,\dots)$ and $0$ only</li><li><strong>Equalities</strong> $(&#x3D;)$: variables $(x,y,\dots)$, $0$ and a <strong>single</strong> successor operation $(S(t))$ only<ul><li>i.e. $S(S(t))$ is not allowed.</li></ul></li></ul><p>Complex formula in S1S can then be simplified by introducing additional variables.</p><h2 id="From-S1S-to-S1S-0"><a href="#From-S1S-to-S1S-0" class="headerlink" title="From S1S to S1S$_0$"></a>From S1S to S1S$_0$</h2><blockquote><p>$\textbf{Lemma 6.1. } \textit{For every S1S formula }\varphi\textit{ there is an S1S}_0\text{ formula }\varphi‚Äô\textit{ such that }\mathcal{L}(\varphi)&#x3D;\mathcal{L}(\varphi‚Äô).$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>We rewrite a given S1S formula $\varphi$ into the S1S$_0$ formula $\varphi$‚Äô using the following rewrite rules:</p><table><thead><tr><th align="left">S1S</th><th align="left">S1S_0</th><th align="left">Explanation</th></tr></thead><tbody><tr><td align="left">$S(t)\in X$</td><td align="left">$\exists y. y&#x3D;S(t)\wedge y\in X$</td><td align="left">only $0$ and <code>First-order variable</code> $(x,y,\dots)$ is allowed on the L.H.S of $\in$</td></tr><tr><td align="left">$0&#x3D;x$</td><td align="left">$x&#x3D;0$</td><td align="left"><code>First-order variable</code> has higher priority than $0$</td></tr><tr><td align="left">$S(t)&#x3D;0$</td><td align="left">$0&#x3D;S(t)$</td><td align="left">successor operation not allowed on L.H.S</td></tr><tr><td align="left">$S(t)&#x3D;x$</td><td align="left">$x&#x3D;S(t)$</td><td align="left">successor operation not allowed on L.H.S</td></tr><tr><td align="left">$S(t)&#x3D;S(t‚Äô)$</td><td align="left">$t&#x3D;t‚Äô$</td><td align="left">successor operation not allowed on L.H.S</td></tr><tr><td align="left">$0&#x3D;0$</td><td align="left">$\exists Y.0\in Y\vee0\notin Y$</td><td align="left">only accept the form $x&#x3D;0$</td></tr><tr><td align="left">$0&#x3D;S(t)$</td><td align="left">$\exists y.y&#x3D;S(t)\wedge y&#x3D;0$</td><td align="left">only accept the form $x&#x3D;0$ or $x&#x3D;S(y)$</td></tr><tr><td align="left">$t&#x3D;S(0)$</td><td align="left">$\exists x.x&#x3D;0\wedge t&#x3D;S(x)$</td><td align="left">only accept the form $x&#x3D;S(y)$</td></tr><tr><td align="left">$t&#x3D;S(S(t‚Äô)$</td><td align="left">$\exists y.y&#x3D;S(t‚Äô)\wedge t&#x3D;S(y)$</td><td align="left">only allow one successor operation</td></tr></tbody></table><h2 id="From-S1S-definable-to-Buchi-recognizable"><a href="#From-S1S-definable-to-Buchi-recognizable" class="headerlink" title="From S1S-definable to B√ºchi-recognizable"></a>From S1S-definable to B√ºchi-recognizable</h2><blockquote><p>$\textbf{Theorem 6.4. } \textit{Every S1S-definable language is B√ºchi-recognizable.}$</p></blockquote><h3 id="Proof-1"><a href="#Proof-1" class="headerlink" title="Proof"></a>Proof</h3><p>Let $\varphi$ be an S1S-formula. We construct a B√ºchi automaton $\mathcal{A}$ with $\mathcal{L}(\varphi)&#x3D;\mathcal{L}(\mathcal{A})$.</p><ul><li>Step 1: We begin by translating $\varphi$ into an equivalent S1S$_0$ according to the above Lemma 6.1.</li><li>Step 2: Express every basic S1S$_0$ formula from the grammar above using B√ºchi automaton.</li></ul><p>Remember in <a href="../agv6-6/">last section</a>, when we translate QPTL to S1S, we defined <code>Second-order variable</code> $X$ as atomic proposition of QPTL. Here same definitions continue:</p><p>First of all, <strong>$A$ is the set of atomic propositions $(A\subseteq AP)$ which is avaliable in the current state</strong>. For example, in state $q_2$, $A &#x3D; \lbrace X,Y\rbrace$, where $AP &#x3D; \lbrace X,Y,Z\rbrace$. Which means in $q_2$ there exists transitions only when proposition $X$ or $Y$ is $\textit{true}$.</p><p>Then, words are defined as a sequence containing atomic propositions. For example, a possible structure for word $\alpha$ may look like this: $$\alpha&#x3D;\lbrace XYYXXYY\dots\rbrace$$</p><p>Finally, our <a href="../agv6-5/">definition</a> of <code>Second-order variable</code> is <strong>set of positions</strong>, and <code>First-order variable</code> are the <strong>positions</strong>. The relationship between proposition and variables in S1S is essentially $\alpha[x] &#x3D; X$, where $x$ is some <code>First-order variable</code> and $X$ is some <code>Second-order variable</code>.</p><p>We can also use the S1S way to interpret, that proposition $X$ holds $\textit{true}$ in position x and y, i.e. $X&#x3D;\lbrace x,y\rbrace$.</p><p>Therefore, when we see transitions like $\lbrace A\mid X\in A\rbrace$, it means if $X$ is part of the avaliable propositions for the current state and holds in certain letter(position), then the automata can take this transition as a path. (Here the position is not specified, will see more examples below)</p><ol><li><p>$0\in X$: This statement holds $\textit{true}$ iff. theres a word that contains $X$ in zero position.<br><img src="/images/notes/uds/agv/6_7_0inX.png"></p></li><li><p>$x\in Y$: This statement holds $\textit{true}$ iff. theres a word that contains $Y$ in $x$ position.<br><img src="/images/notes/uds/agv/6_7_xinY.png"></p></li><li><p>$x&#x3D;0$: This statement holds $\textit{true}$ iff. the word exist some propositions that only holds $\textit{true}$ in $x$-th position, assign $x$ as $0$.<br><img src="/images/notes/uds/agv/6_7_x=0.png"></p></li><li><p>$x&#x3D;y$: This statement holds $\textit{true}$ iff. the word exist some propositions that only holds $\textit{true}$ in $x$-th and $y$-th position, which are indeed the same.<br><img src="/images/notes/uds/agv/6_7_x=y.png"></p></li><li><p>$x&#x3D;S(y)$: This statement holds $\textit{true}$ iff. the word exist some propositions that only holds $\textit{true}$ in $x$-th and $y$-th position, where $x$ and $y$ are different and $x$ is the next position after $y$.<br><img src="/images/notes/uds/agv/6_7_x=S(y).png"></p></li><li><p>$\varphi\wedge\psi$: Let $\mathcal{A_\varphi}$ and $\mathcal{A_\psi}$ be the automata constructed for $\varphi$ and $\psi$, respectively. We obtain the automaton $\mathcal{A}_{\varphi\wedge\psi}$ by constructing the automaton that recognizes the intersection of $\mathcal{L(A_\varphi)}$ and $\mathcal{L(A_\psi)}$.<br>Below is the example of $0\in X \wedge x \in Y$:<br><img src="/images/notes/uds/agv/6_7_and.png"></p></li><li><p>$\neg\varphi$: let $\mathcal{A_{\varphi}}$ be the automaton constructed for $\varphi$. We obtain the automaton $\mathcal{A_{\neg\varphi}}$ by first constructing the automaton that recognizes the complement of $\mathcal{L(A_{\varphi})}$ and then intersecting it with $A_x$ for each <strong>free</strong> <code>first-order variable</code> $x$, which ensures that $x$ appears exactly once. Below we use $\neg(x\in Y)$ as an example:<br><img src="/images/notes/uds/agv/6_7_neg.png"><br>Notice that $(\lbrace x,Y\rbrace\subseteq A)\wedge(x\in A)&#x3D;\lbrace x,Y\rbrace\subseteq A$:<br><img src="/images/notes/uds/agv/6_7_notphi.png"></p></li><li><p>$\exists X.\varphi$: Let $\mathcal{A_{\varphi}}$ be the automaton constructed for $\varphi$. We obtain the automaton $\mathcal{A}_{\exists X. \varphi}$ for by eliminating $X$ from the input alphabet, i.e., we replace each transition $(q,A,q‚Äô)$ by $(q,A\setminus\lbrace X\rbrace,q‚Äô)$.<br>(Because the B√ºchi-recognizable Language only contains the set of <strong>free</strong> atomic propositions)</p></li><li><p>$\exists x. \varphi$: Similarly, we replace each transition $(q,A,q‚Äô)$ by $(q,A\setminus\lbrace x\rbrace,q‚Äô)$.</p></li></ol><hr><p>Next chapter: <a href="../agv7-1/">Alternating B√ºchi Automata</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 6.6 -- Express QPTL using S1S</title>
      <link href="/AGV/agv6-6/"/>
      <url>/AGV/agv6-6/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv6-5/">Monadic Second-Order Logic of One Successor (S1S)</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>We already showed, in <a href="../agv6-4/">Theorem 6.2</a>, that every B√ºchi-recognizable language is QPTL-definable. We now complete a full circle by showing that every QPTL-definable language is S1S-definable, and that every S1S-definable language is B√ºchi-recognizable. <strong>Hence, QPTL, S1S, and B√ºchi automata are equally expressive.</strong></p><blockquote><p>$\textbf{Theorem 6.3. } \textit{Every QPTL-definable language is S1S-definable.}$</p></blockquote><h2 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h2><p>In <a href="../agv6-4/">section 6.4</a>, we defined the language of QPTL as: $\mathcal{L}(\varphi)&#x3D;\lbrace\alpha\in{(2^{AP‚Äô})}^{\omega}\mid\alpha\models\varphi\rbrace$, and</p><p>In <a href="../agv6-5/">section 6.5</a>, we defined the language of S1S as: $\mathcal{L}(\varphi)&#x3D;\lbrace \alpha_{\sigma_1,\sigma_2}\in(2^{V‚Äô_1\cup V‚Äô_2})^\omega\mid\sigma_1,\sigma_2\models\varphi\rbrace$</p><p>Notice main difference comes from $\alpha\models\varphi$ and $\sigma_1,\sigma_2\models\varphi$. Also, QPTL uses <em>propositions</em> but S1S uses <em>term</em>. We thus define S1S formula as $T(\varphi,t)$, where $\varphi$ is a QPTL-formula over $AP$ and $t$ is a S1S-term. Lastly, with $V_2&#x3D;AP$, we can now define a S1S formula for all $\alpha\in(2^{AP})^\omega$,</p><blockquote><p>$$\alpha\lbrack\lbrack t\rbrack_{\sigma_1},\infty\rbrack\models_{QPTL}\varphi\hspace{0.5cm}\text{iff}\hspace{0.5cm}\sigma_1,\sigma_2\models_{S1S}T(\varphi,t)\varphi,\hspace{1cm}\text{where }\ \sigma_2:P\mapsto\lbrace i\in\mathbb{N}\mid P\in\alpha(i)\rbrace$$</p></blockquote><p>$\begin{array}{llll}<br>\hspace{1cm}\cdot&amp;T(P,t)&amp;&#x3D;&amp;t\in P\text{, for }P\in AP\newline<br>\hspace{1cm}\cdot&amp;T(\neg\varphi,t)&amp;&#x3D;&amp;\neg T(\varphi,t)\newline<br>\hspace{1cm}\cdot&amp;T(\varphi\wedge\psi,t)&amp;&#x3D;&amp;T(\varphi,t)\wedge T(\psi,t)\newline<br>\hspace{1cm}\cdot&amp;T(\bigcirc\varphi,t)&amp;&#x3D;&amp;T(\varphi,S(t))\newline<br>\hspace{1cm}\cdot&amp;T(\Diamond\varphi,t)&amp;&#x3D;&amp;\exists x.(x\geq t\wedge T(\varphi, x))\newline<br>\hspace{1cm}\cdot&amp;T(\exists P.\varphi,t)&amp;&#x3D;&amp;\exists P. T(\varphi,t)\newline<br>\end{array}$</p><p>Therefore, the language of $\varphi$ is then defined by the S1S formula $T(\varphi, 0)$.</p><h3 id="Explanation"><a href="#Explanation" class="headerlink" title="Explanation"></a>Explanation</h3><p>We apply every basic QPTL operators into $\varphi$, and transform them using S1S operators.</p><p>For proposition $P$, we can assign its value based on the temporal state when it holds. For example, for $\alpha&#x3D;{PPQPQQQ\dots}$, $P$ is in position $\alpha[0], \alpha[1], \alpha[3]$. So $\sigma_2:P\mapsto\lbrace0,1,3\rbrace$<br>And $T(P,t)$ is true when $t$ have value equals to {1,2,3}.</p><p>For the Finally operator $\Diamond$, it is expressed as true when the value is greater than or equals to t.</p><hr><p>Next chapter: <a href="../agv6-7/">S1S$_0$ and B√ºchi-recognizable Language</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 6.5 -- Monadic Second-Order Logic of One Successor (S1S)</title>
      <link href="/AGV/agv6-5/"/>
      <url>/AGV/agv6-5/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv6-4/">Quantified Propositional Temporal Logic (QPTL)</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Temporal logics like LTL and QPTL refer to the positions of the input word <em>implicitly</em> through the <code>temporal operators</code>. With S1S, we now introduce a logic that allows us to manipulate positions <em>explicitly</em>.</p><p>For example, the mutual exclusion property in LTL is $\square\neg(\ell_1\wedge m_1)$, where the Always operator $\square$ <strong>implicitly quantifies over all positions</strong>. In S1S, we use <strong>explicit universal quantifiers</strong> instead: $\forall x.\neg(x\in P_{\ell_1}\wedge x\in P_{m_1})$.</p><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><ul><li><em><strong>Monadic</strong></em>: the second-order quantification is restricted to <strong>unary relations</strong>, i.e., sets,</li><li><em><strong>One successor</strong></em>: only have a single successor operation.</li></ul><p>Later in the course, we will study monadic second-order logics of two or more successors (S2S, WS1S, etc.), which allow us to describe <em>trees</em> rather than <em>words</em>.</p><h2 id="S1S-syntax"><a href="#S1S-syntax" class="headerlink" title="S1S syntax"></a>S1S syntax</h2><p>In automaton, we use <em>states</em>; in LTL and QPTL, we use <em>propositions</em>, in S1S, we use <strong>positions</strong>.<br>Propositions in QPTL can be interpreted as <strong>set of positions</strong> that holds $\textit{true}$.</p><table><thead><tr><th align="left">basic variables</th><th align="left">Defintiion</th><th align="left">Example</th></tr></thead><tbody><tr><td align="left"><code>first-order variables</code></td><td align="left">store <strong>positions</strong></td><td align="left">$0,1,x,y,\dots$</td></tr><tr><td align="left"><code>second-order variables</code></td><td align="left">store <strong>sets of positions</strong> (refer to $p$ as $\exists p.\varphi$ in QPTL)</td><td align="left">$X,Y,\dots$</td></tr><tr><td align="left"><code>successor operation</code></td><td align="left">$S$, allows us to navigate to the next position (same as $\bigcirc$ in LTL)</td><td align="left">$S(t), S(2),\dots$</td></tr></tbody></table><h3 id="Terms-and-Formulas"><a href="#Terms-and-Formulas" class="headerlink" title="Terms and Formulas"></a>Terms and Formulas</h3><p>Let $V_1&#x3D;\lbrace x, y,\dots\rbrace$ be a set of <code>first-order variables</code> and $V_2&#x3D;\lbrace X, Y,\dots\rbrace$ a set of <code>second-order variables</code>. Then the <strong>terms</strong> of S1S are defined by the following grammar:</p><p>$$t::&#x3D;0\mid x\mid S(t)$$</p><p>The <strong>formulas</strong>&#96;of S1S are defined by the following grammar:</p><p>$$\varphi::&#x3D;t\in X\mid t&#x3D;t\mid\neg\varphi\mid\varphi\wedge\varphi\mid\exists x.\varphi\mid\exists X.\varphi$$</p><p>The precedence order of the operators goes from left (highest precedence) to right (lowest precedence), as denoted by the grammar above. We still allow usual boolean connectives with the following abbreviations:</p><p>$<br>\begin{array}{ll}<br>\hspace{1cm}\cdot\hspace{0.5cm} \forall X.\varphi :&#x3D; \neg\exists X. \neg\varphi&amp; \hspace{3cm}\cdot\hspace{0.5cm} \forall x.\varphi :&#x3D; \neg\exists x. \neg\varphi\newline<br>\hspace{1cm}\cdot\hspace{0.5cm} x\notin Y :&#x3D; \neg(x\in Y)&amp; \hspace{3cm}\cdot\hspace{0.5cm} x\neq y:&#x3D; \neg(x&#x3D;y)<br>\end{array}<br>$</p><h3 id="Variable-Valuations"><a href="#Variable-Valuations" class="headerlink" title="Variable Valuations"></a>Variable Valuations</h3><p>The semantics of an S1S formula is given relative to a valuation of the variables.</p><ul><li><code>First-order Valuation</code>: $\sigma_1:V_1\rightarrow\mathbb{N}$ assigns to each <code>first-order variable</code> a <strong>natural number</strong>.</li><li><code>Second-order Valuation</code>: $\sigma_2:V_2\rightarrow 2^\mathbb{N}$ assigns to each <code>second-order variable</code> a <strong>set of natural numbers</strong>.</li></ul><p>The value of a term is then defined as follows:</p><p>$\begin{array}{lll}<br>\hspace{1cm}\cdot\hspace{0.5cm} \lbrack 0\rbrack_{\sigma_1} &#x3D; 0 &amp;<br>\hspace{4cm}\cdot\hspace{0.5cm} \lbrack x\rbrack_{\sigma_1} &#x3D; \sigma_1(x) &amp;<br>\hspace{3cm}\cdot\hspace{0.5cm} \lbrack S(t)\rbrack_{\sigma_1} &#x3D;[t]_{\sigma_1}+1\newline<br>\end{array}$</p><h2 id="Free-Bound-and-the-Language-of-S1S"><a href="#Free-Bound-and-the-Language-of-S1S" class="headerlink" title="Free, Bound and the Language of S1S"></a>Free, Bound and the Language of S1S</h2><p>Again, we define the subsets of <strong>free</strong> first-order and <strong>free</strong> second-order variables as $V‚Äô_1\subseteq V_1$ and $V‚Äô_2\subseteq V_2$ respectively. An S1S formula $\varphi$ then defines the following language over the alphabet $2^{V‚Äô_1\cup V‚Äô_2}$:</p><p>$$\mathcal{L}(\varphi)&#x3D;\lbrace \alpha_{\sigma_1,\sigma_2}\in(2^{V‚Äô_1\cup V‚Äô_2})^\omega\mid\sigma_1,\sigma_2\models\varphi\rbrace$$</p><p>where $x\in\alpha_{\sigma_1,\sigma_2}(j)\text{ iff }&#x3D;\sigma_1(x)$, and $X\in\alpha_{\sigma_1,\sigma_2}(j)\text{ iff }j&#x3D;\sigma_2(X)$, and $\models$ is the smallest relation that satisfies the following:</p><p>$<br>\begin{array}{llllll}<br>\hspace{1cm}\cdot &amp; \sigma_1,\sigma_2 &amp; \models &amp; t\in X &amp; \text{iff} &amp; \lbrack t\rbrack_{\sigma_1}\in\sigma_2(X)\newline<br>\hspace{1cm}\cdot &amp; \sigma_1,\sigma_2 &amp; \models &amp; t_1&#x3D;t_2 &amp; \text{iff} &amp;\lbrack t_1\rbrack_{\sigma_1}&#x3D;\lbrack t_2\rbrack_{\sigma_1}\newline<br>\hspace{1cm}\cdot &amp; \sigma_1,\sigma_2 &amp; \models &amp; \neg\psi &amp; \text{iff} &amp;\sigma_1,\sigma_2\not\models\psi\newline<br>\hspace{1cm}\cdot &amp; \sigma_1,\sigma_2 &amp; \models &amp; \varphi_0\wedge \varphi_1 &amp; \text{iff} &amp;\sigma_1,\sigma_2\models\varphi_0\text{ and }\sigma_1,\sigma_2\models\varphi_1\newline<br>\hspace{1cm}\cdot &amp; \sigma_1,\sigma_2 &amp; \models &amp; \exists x.\varphi &amp; \text{iff} &amp;\text{there is an }\alpha\in\mathbb{N}\text{ s.t. }\sigma‚Äô_1,\sigma_2\models\varphi\text{ and }\sigma‚Äô_1(y)&#x3D;\left\lbrace\begin{array}{ll}\sigma_1(y)&amp;\text{if }y\neq x \newline a&amp;\text{if }y&#x3D;x\end{array}\right.\newline<br>\hspace{1cm}\cdot &amp; \sigma_1,\sigma_2 &amp; \models &amp; \exists X.\varphi &amp; \text{iff} &amp;\text{there is an }A\in\mathbb{N}\text{ s.t. }\sigma_1,\sigma‚Äô_2\models\varphi\text{ and }\sigma‚Äô_2(Y)&#x3D;\left\lbrace\begin{array}{ll}\sigma_2(Y)&amp;\text{if }Y\neq X\newline A&amp;\text{if }Y&#x3D;X\end{array}\right.<br>\end{array}<br>$</p><p>For Existence Operator $(\exists)$, the definition is similar to QPTL: We have $\sigma‚Äô_1$ that behave exactly the same for every <code>first-order variable</code> $y$. Except for some $x$, there is a value $a$ that $\sigma‚Äô_1$ can assign to $x$ so that $\varphi$ holds. Same definition apply on <code>second-order variable</code> $X$ resepctively.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><table><thead><tr><th align="left">Statement</th><th align="left">Formula</th></tr></thead><tbody><tr><td align="left">$X$ is a subset of $Y$</td><td align="left">$X\subseteq Y\equiv\forall z.\ (z\in X\rightarrow z\in Y)$</td></tr><tr><td align="left">$X$ and $Y$ are equal</td><td align="left">$X &#x3D; Y\equiv X\subseteq Y \wedge Y\subseteq X$</td></tr><tr><td align="left">$X$ is upward closed</td><td align="left">$\textit{Upwardclosed}(X)\equiv\forall y.\ (y\in X\rightarrow S(y)\in X)$</td></tr><tr><td align="left">$x$ is less than or equals to $y$</td><td align="left">$x\leq y\equiv\forall Z.\ (x\in Z\wedge\textit{Upwardclosed}(Z))\rightarrow y\in Z$</td></tr><tr><td align="left">$X$ is a finite set</td><td align="left">$\textit{Fin}(X)\equiv\exists Y.\ (X\subseteq Y\wedge(\exists z.\ z\notin Y)\wedge(\forall z.\ (z\notin Y\rightarrow S(z)\notin Y)))$</td></tr><tr><td align="left">$X$ is the set of even numbers</td><td align="left">$\textit{Even}(X)\equiv0\in X\wedge\neg S(0)\in X \wedge \forall y.\ (y\in X\leftrightarrow S(S(y))\in X)$</td></tr><tr><td align="left">Every even number in $X$ is in $Y$</td><td align="left">$\textit{EvenCount}(X,Y)\equiv\forall w.\ (\exists Z.\ \textit{Even}(Z)\wedge w\in Z)\rightarrow(w\in X\rightarrow w\in Y)$</td></tr></tbody></table><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In the next section, we will try to compare S1S with QPTL and see their expressiveness.</p><hr><p>Next chapter: <a href="../agv6-6/">Express QPTL using S1S</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 6.4 -- Quantified Propositional Temporal Logic (QPTL)</title>
      <link href="/AGV/agv6-4/"/>
      <url>/AGV/agv6-4/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv6-3/">LTL and Counting Languages</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In the last section, we knew that LTL cannot express <code>counting-languages</code>. QPTL, which extends<br>LTL with <strong>quantification over propositions</strong>, repairs this deficiency.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>We knew $L&#x3D;(\varnothing\varnothing)^\ast\lbrace p\rbrace^\omega$ is not LTL-definable. However, similar language $L‚Äô&#x3D;(\varnothing\lbrace q\rbrace)^\ast\lbrace p\rbrace^\omega$ is LTL-definable:</p><p>$$\varphi&#x3D;\neg q\wedge(\neg p\wedge(\neg q\leftrightarrow\bigcirc q))\ \mathcal{U}\ (\square(p\wedge\neg q))$$</p><p>Intuitively, $L‚Äô$ is the same language as $L$, except that there is an additional proposition $q$ that keeps track of odd and even positions. LTL has no means of introducing such ‚Äúhelpful‚Äù propositions that are not already present in the language we wish to define. In QPTL, we can introduce the proposition $q$ using a quantifier. The existential quantification $\exists q$. $\varphi$ expresses that there is a way to evaluate the new proposition $q$ such that, in the such extended word, $\varphi$ is true. In the example, the language of $\exists q.\ \varphi$ is thus precisely $L$.</p><h2 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h2><p>QPTL formulas over a set $AP$ of atomic propositions are generated by the following grammar, where $p\in AP$:</p><p>$$\psi ::&#x3D; p\ \mid\ \neg\psi\ \mid\ \psi\wedge\varphi\ \mid\ \bigcirc\psi\ \mid\ \Diamond\psi\ \mid\ \exists p.\ \psi$$</p><p>The QPTL connectives have the same semantics and precedence as in LTL, except for propositional quantification, which has lowest precedence and the following semantics:</p><p>$$\begin{array}{lcr}\alpha\models\exists p.\ \varphi&amp;\text{ iff }&amp;\text{ there exists }\alpha‚Äô\in(2^{AP})^\omega\text{ such that }\alpha&#x3D;_{AP\setminus\lbrace p\rbrace}\alpha‚Äô\text{ and }\alpha‚Äô\models\varphi\end{array}$$</p><p>where $\alpha&#x3D;_P\alpha‚Äô$ for some $P\subseteq AP$ iff, for all $i\in\mathbb{N},\alpha(i)\cap P&#x3D;\alpha‚Äô(i)\cap P$.</p><blockquote><p>Every $AP$ in $\alpha$ is same as $\alpha‚Äô$, except $\alpha‚Äô$ can modify $p$ so that $\varphi$ holds for $\alpha‚Äô$</p></blockquote><h3 id="Until-operator-mathcal-U-in-QPTL"><a href="#Until-operator-mathcal-U-in-QPTL" class="headerlink" title="Until operator $\mathcal{U}$ in QPTL"></a>Until operator $\mathcal{U}$ in QPTL</h3><p>We can express the Until operator $\mathcal{U}$ in the syntax of QPTL with quantifier and the meaning is equivalent:</p><blockquote><p>$\varphi\ \mathcal{U}\ \psi:$ $\varphi$ must hold $\textit{true}$ until $\psi$ becomes $\textit{true}$.</p></blockquote><p>$$\exists t.\ t\wedge\square(t\rightarrow(\psi\vee(\varphi\wedge\bigcirc t)))\wedge\Diamond\neg t:$$</p><blockquote><ul><li><p>$\exists t.\ t$: For some proposition $t$, $t$ holds at the beginning;</p></li><li><p>$\square(t\rightarrow(\psi\vee(\varphi\wedge\bigcirc t)))$: if $t$ holds, we repeatly check the following</p><ul><li>either $\psi$ becomes $\textit{true}$, or</li><li>$\varphi$ must remain $\textit{true}$ and so as $t$ in the next step<br>(so that this if-clause check again in the next step);\</li></ul></li><li><p>$\Diamond\neg t$ : Eventually, $t$ will no longer hold.</p><ul><li>It enforces $\psi$ must become $\textit{true}$ at some point and then $t$ doesn‚Äôt need to hold anymore</li><li>If it is weak until $\mathcal{W}$ then this part is not necessarily because we don‚Äôt enforce $\psi$ to be $\textit{true}$</li></ul></li></ul></blockquote><h3 id="Free-and-Bound-Atomic-Propositions"><a href="#Free-and-Bound-Atomic-Propositions" class="headerlink" title="Free and Bound Atomic Propositions"></a><code>Free</code> and <code>Bound</code> Atomic Propositions</h3><table><thead><tr><th align="left">Atomic Propositions</th><th align="left">Defintiion</th></tr></thead><tbody><tr><td align="left"><code>Free</code></td><td align="left"><strong>NOT in</strong> the <em>scope of a quantifier</em> over the proposition</td></tr><tr><td align="left"><code>Bound</code></td><td align="left"><strong>In</strong> the <em>scope of a quantifier</em> over the proposition</td></tr></tbody></table><p>Here, <code>Bounded</code> propositions are internal helpers to help us construct some logical conditions of the formula that do not directly appear in the language. (e.g. we need a counter for <code>counting</code>-language, but it doesn‚Äôt belongs to any proposition that refers to the alphabet or language.)</p><h2 id="From-QPTL-formula-to-omega-regular-language"><a href="#From-QPTL-formula-to-omega-regular-language" class="headerlink" title="From QPTL formula to $\omega$-regular language"></a>From QPTL formula to $\omega$-regular language</h2><p>Let‚Äôs defined the set of <strong>free</strong> atomic propositions as $AP‚Äô\subseteq AP$. For every letter in the alphabet, we can describe them in $AP‚Äô$.</p><p>For exmaple, if $\lbrace a,b,c\rbrace&#x3D;\Sigma$, the word $\lbrace ab\rbrace\in\Sigma$ will be $\lbrace a,b,\neg c\rbrace\in AP‚Äô$</p><p>Now, the language of QPTL is essentially the language over alphabet $2^{AP‚Äô}:\mathcal{L}(\varphi)&#x3D;\lbrace\alpha\in{(2^{AP‚Äô})}^{\omega}\mid\alpha\models\varphi\rbrace$</p><p>In fact, it is exactly the $\omega$-regular languages that can be expressed in QPTL. And therefore, we can translate a given B√ºchi automaton with alphabet $2^{AP}$ into a QPTL formula:</p><blockquote><p>$\textbf{Theorem 6.2. } \textit{For every B√ºchi automaton }\mathcal{A}\textit{ over }\Sigma&#x3D;2^{AP}\textit{ there exists a QPTL formula }\varphi_{\mathcal{A}}\newline\textit{such that }\mathcal{L}(\varphi)&#x3D;\mathcal{L}(\mathcal{A}).$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>Reminder: here the automaton using atomic propositions $2^{AP}$, not the alphabet $\Sigma$. To translate states in automata into atomic proposition in QPTL formula, we introduce <em>auxiliary proposition</em> $at_q$ for each <em>state</em> $q\in Q$, where $Q&#x3D;\lbrace q_1, q_2,\dots,q_n\rbrace$</p><p>Then QPTL formula $\varphi_\mathcal{A}$ for the B√ºchi automaton $\mathcal{A}$ so that $\mathcal{L}(\varphi)&#x3D;\mathcal{L}(\mathcal{A})$ is defined as follows:</p><p>$$<br>\begin{array}{rll}<br>\varphi_\mathcal{A}:&#x3D;\exists at_q,\dots,at_{q_n}.&amp;&amp;\underset{q\in I}{\bigvee}at_q\newline<br>&amp;\wedge&amp;\square\left(\underset{(q,A,q‚Äô)\in T}{\bigvee}at_q\wedge\bigcirc at_{q‚Äô}\wedge\left(\underset{p\in A}{\bigwedge}p\right)\wedge\left(\underset{p\in AP\setminus A}{\bigwedge}\neg p\right)\right)\newline<br>&amp;\wedge&amp;\square\left(\overset{n}{\underset{i&#x3D;1}{\bigwedge}}\underset{j\neq i}{\bigwedge}\neg(at_{q_i}\wedge at_{q_j})\right)\newline<br>&amp;\wedge&amp;\square\Diamond\underset{q\in F}{\bigvee}at_q<br>\end{array}<br>$$</p><h3 id="Explained-in-Human-language"><a href="#Explained-in-Human-language" class="headerlink" title="Explained in Human language"></a>Explained in Human language</h3><p>To express a B√ºchi automaton in QPTL, we first need to know what features&#x2F;characteristics we need express.</p><ul><li>Begins with Initial states and reaches the Accepting states infinitely often:</li></ul><p>$$\textsf{Initial states: }\underset{q\in I}{\bigvee}at_q \hspace{3cm} \textsf{Accepting states: }\square\Diamond\underset{q\in F}{\bigvee}at_q$$</p><ul><li>There‚Äôs always transitions for any states, only using the letters available in the current state defined by set $A$:</li></ul><p>$$\square\left(\underset{(q,A,q‚Äô)\in T}{\bigvee}at_q\wedge\bigcirc at_{q‚Äô}\wedge\left(\underset{p\in A}{\bigwedge}p\right)\wedge\left(\underset{p\in AP\setminus A}{\bigwedge}\neg p\right)\right)$$</p><ul><li>Additionally, we also need to ensure that there‚Äôs exactly one current state $q_i$, which is $at_{q_i}$ in propositions:</li></ul><p>$$\square\left(\overset{n}{\underset{i&#x3D;1}{\bigwedge}}\underset{j\neq i}{\bigwedge}\neg(at_{q_i}\wedge at_{q_j})\right)$$</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>As above, we can see that every feature of a B√ºchi automaton can be expressed in QPTL. What‚Äôs next? Can we use simpler syntax to express same formula?</p><hr><p>Next chapter: <a href="../agv6-5/">Monadic Second-Order Logic of One Successor (S1S)</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 6.3 -- LTL and Counting Languages</title>
      <link href="/AGV/agv6-3/"/>
      <url>/AGV/agv6-3/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv6-2/">Expressing Program Properties using LTL</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Semantics"><a href="#Semantics" class="headerlink" title="Semantics"></a>Semantics</h2><p>An LTL formula $\varphi$ over $AP$ defines the following language over the alphabet $2^{AP}$:</p><p>$\hspace{1cm} \mathcal{L}(\varphi)&#x3D;\lbrace\alpha\in(2^{AP})^\omega\mid\alpha\models\varphi\rbrace$</p><p>where $\models$ is the smallest relation satisfying:</p><p>$\begin{array}{lllll}<br>\hspace{1cm} \alpha &amp; \models &amp; p &amp; \text{iff} &amp; p\in\alpha(0) \ \ \ \ (\text{i.e., }\alpha(0)\models p)\newline<br>\hspace{1cm} \alpha &amp; \models &amp; \varphi_1\wedge\varphi_2 &amp; \text{iff} &amp; \alpha\models\varphi_1\ \text{ and }\ \alpha\models\varphi_1\newline<br>\hspace{1cm} \alpha &amp; \models &amp; \neg\varphi &amp; \text{iff} &amp; \alpha\not\models\varphi\newline<br>\hspace{1cm} \alpha &amp; \models &amp; \bigcirc\varphi &amp; \text{iff} &amp; \alpha[1,\infty]&#x3D;\alpha(1)\alpha(2)\alpha(3)\dots\models\varphi\newline<br>\hspace{1cm} \alpha &amp; \models &amp; \varphi_1\ \mathcal{U}\ \varphi_2 &amp; \text{iff} &amp; \exists j\geq0.\ \alpha[j,\infty]\models\varphi_2\ \text{ and }\ \alpha[i,\infty]\models\varphi_1\text{ for all }0\leq i\leq j\newline<br>\end{array}$</p><p>For the temporal operators, the semantics can be visualized as below:</p><p><img src="/../images/notes/uds/agv/6_3_ltl.png"></p><h2 id="From-LTL-to-omega-regular-languages"><a href="#From-LTL-to-omega-regular-languages" class="headerlink" title="From LTL to $\omega$-regular languages"></a>From LTL to $\omega$-regular languages</h2><blockquote><p>All LTL-definable properties are $\omega$-regular, but <strong>NOT ALL</strong> $\omega$-regular languages can be defined in LTL.</p></blockquote><p>Why can‚Äôt we? What is the limitation of LTL formula?</p><h3 id="Counting-and-Non-counting-Languages"><a href="#Counting-and-Non-counting-Languages" class="headerlink" title="Counting and Non-counting Languages"></a>Counting and Non-counting Languages</h3><p>Let say we want to express:</p><blockquote><p>An arbitrary <strong>even</strong> sequence of $\varnothing$ symbols, followed by an infinite sequence of $p$ symbols</p></blockquote><p>In $\omega$-language it is $(\varnothing\varnothing)^\ast\lbrace p\rbrace^\omega$. However, this cannot be defined in LTL, because it is a <code>counting language</code>.</p><blockquote><p>$\textbf{Definition 6.1. }\text{A Language }L\subseteq\Sigma^\omega\text{ is }\textit{non-counting}\text{ iff}$<br>$$\exists n_0\in\mathbb{N}.\ \forall n\geq n_0.\ \forall v,w\in\Sigma^\ast, \alpha\in\Sigma^\omega.\ vw^n\alpha\in L\Leftrightarrow vw^{n+1}\alpha\in L$$</p></blockquote><p>For some threshold $n_0$, and a word with prefix $w$ which repeated $n$ times and $n\geq n_0$. For every $n$ we picked, if we can always find a pair of words $vw^{n}\alpha,vw^{n+1}$ that are both accepted by language $L$, then $L$ is <code>non-counting</code>.</p><p>For example, in $L_1&#x3D;(\varnothing\varnothing)^\ast\lbrace p\rbrace^\omega$, if $(\varnothing)^n\lbrace p\rbrace^\omega\in L_1$, then $(\varnothing)^{n+1}\lbrace p\rbrace^\omega\not\in L_1$, so $L_1$ is <code>counting</code> with $n_0&#x3D;1$.</p><blockquote><p>$\textbf{Theorem 6.1. }\textit{ For every LTL-formula }\varphi,\mathcal{L}(\varphi)\textit{ is non-counting.}$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>We prove the theorem by structural induction on $\varphi$, going through its sematics:</p><p>$\textbf{Case }\varphi&#x3D;p:$<br>$\hspace{1cm}$  Simply choose the length $n_0&#x3D;1$, (because $\alpha\models p\text{ iff }p\in\alpha(0)$)</p><p>$\textbf{Case }\varphi&#x3D;\varphi_1\wedge\varphi_2:$<br>$\hspace{1cm}$ By induction hypothesis, If $\varphi_1$ and $\varphi_2$ are <code>non-counting</code>, then $\mathcal{L}(\varphi_1)$ and $\mathcal{L}(\varphi_2)$ have threshold $n_0‚Äô$ and<br>$\hspace{1cm}$ $n‚Äô‚Äô_0\in\mathbb{N}$ respectively. We can choose $n_0&#x3D;\text{max}\lbrace n‚Äô_0,n‚Äô‚Äô_0\rbrace$ to ensure $\varphi$ is also <code>non-counting</code>. (max. because<br>$\hspace{1cm}$ the larger the $n_0$, less $n$ is required to be <code>non-counting</code>)</p><p>$\textbf{Case }\varphi&#x3D;\neg\varphi_1:$<br>$\hspace{1cm}$ If $\varphi_1$ is <code>non-counting</code>, then $\mathcal{L}(\varphi_1)$ has threshold $n_0‚Äô\in\mathbb{N}$. We choose $n_0&#x3D;n‚Äô_0$</p><p>$\textbf{Case }\varphi&#x3D;\bigcirc\varphi_1:$<br>$\hspace{1cm}$ If $\varphi_1$ is <code>non-counting</code>, then $\mathcal{L}(\varphi_1)$ has threshold $n_0‚Äô\in\mathbb{N}$. We choose $n_0&#x3D;n‚Äô_0+1$ and try to show<br>$$\text{‚ÄúFor }n\geq n_0,\ vw^n\alpha\models\bigcirc\varphi\ \text{ if and only if }\ n\geq n_0,\ vw^{n+1}\alpha\models\bigcirc\varphi‚Äù$$</p><p>$\hspace{1cm}$ We try to perform operations on the fix length prefix $v$ as it doesn‚Äôt affect the finite loop prefix $w$. So we<br>$\hspace{1cm}$ need to consider whether the fix length prefix $v$ is an <em>empty string</em> $(\varepsilon)$, if not, we try to ‚Äúpeel‚Äù one cycle of<br>$\hspace{1cm}$ $w$ and make it so-called ‚Äúfix-length‚Äù prefix.</p><p>$\hspace{1cm}$ A simple example for the operation: if there‚Äôs logic requires $b$ to be reached in the next step, then the same<br>$\hspace{1cm}$ logic without <strong>neXt</strong> operator $\bigcirc$ can be satisfied by removing the first letter. (if $ab\models\bigcirc\varphi$, then $b\models\varphi$)</p><p>$\hspace{1cm}\textbf{Case }\ v\neq\varepsilon:$ Thus $v&#x3D;av‚Äô$ for some $a\in\Sigma,v‚Äô\in\Sigma^\ast$. We have that</p><p>$\begin{array}{lrl}<br>\hspace{2cm}&amp;av‚Äôw^n\alpha&amp;\models\bigcirc\varphi\newline<br>\hspace{2cm}\text{iff}&amp;v‚Äôw^n\alpha&amp;\models\varphi\newline<br>\hspace{2cm}\text{iff}&amp;v‚Äôw^{n+1}\alpha&amp;\models\varphi&amp;\text{(induction hypothesis)}\newline<br>\hspace{2cm}\text{iff}&amp;av‚Äôw^{n+1}\alpha&amp;\models\bigcirc\varphi\newline<br>\end{array}$</p><p>$\hspace{1cm}\textbf{Case }\ v&#x3D;\varepsilon:$ Thus either $w&#x3D;\varepsilon$ (proved trivially), or $w&#x3D;aw‚Äô$ for some $a\in\Sigma,w‚Äô\in\Sigma^\ast$. It follows that</p><p>$\begin{array}{lrl}<br>\hspace{2cm}&amp;(aw‚Äô)^n\alpha&amp;\models\bigcirc\varphi\newline<br>\hspace{2cm}\text{iff}&amp;(aw‚Äô)(aw‚Äô)^{n-1}\alpha&amp;\models\bigcirc\varphi\newline<br>\hspace{2cm}\text{iff}&amp;w‚Äô(aw‚Äô)^{n-1}\alpha&amp;\models\varphi\newline<br>\hspace{2cm}\text{iff}&amp;w‚Äô(aw‚Äô)^{n}\alpha&amp;\models\varphi&amp;\text{(induction hypothesis)}\newline<br>\hspace{2cm}\text{iff}&amp;(aw‚Äô)^{n+1}\alpha&amp;\models\bigcirc\varphi\newline<br>\end{array}$</p><p>$\textbf{Case }\varphi&#x3D;\varphi_1\ \mathcal{U}\ \varphi_2:$<br>$\hspace{1cm}$ If $\varphi_1$ and $\varphi_2$ are <code>non-counting</code>, then $\mathcal{L}(\varphi_1)$ and $\mathcal{L}(\varphi_2)$ have threshold $n_0‚Äô$ and $n‚Äô‚Äô_0\in\mathbb{N}$ respectively. We<br>$\hspace{1cm}$ choose $n_0&#x3D;\text{max}\lbrace n‚Äô_0,n‚Äô‚Äô_0\rbrace+1$ and try to show<br>$$‚Äù\text{For }n\geq n_0,\ vw^n\alpha\models\varphi_1\ \mathcal{U}\ \varphi_2\ \text{ if and only if }\ vw^{n+1}\alpha\models\varphi_1\ \mathcal{U}\ \varphi_2‚Äù$$</p><p>$\hspace{1cm}$ By the semantics of $\mathcal{U}$, $\varphi_1$ keeps holding until $\varphi_2$ is satisfied. Let $j$ be the least index when $\varphi_2$ is satisfied,<br>$\hspace{1cm}$ then we have $vw^n\alpha[j,\infty]\models\varphi_2$ and for all $i&lt;j,\ vw^n\alpha[i,\infty]\models\varphi_1$, respectively applies on $vw^{n+1}\alpha$.</p><p>$\hspace{1cm}$ $\textbf{1. }\textit{If }\ vw^n\alpha\models\varphi_1\ \mathcal{U}\ \varphi_2\textit{, then }\ vw^{n+1}\alpha\models\varphi_1\ \mathcal{U}\ \varphi_2:$<br>$\hspace{2cm}$ Similar to $\bigcirc\varphi$, we try to do the operation with respect to $j$‚Äôs position. So we need to consider whether<br>$\hspace{2cm}$ index $j$ lies within the first cycle of the prefix $|v|+|w|$, or lies in the finite loop of the prefix $|w|$.</p><p>$\hspace{2cm}\textbf{Case }j\leq|v|+|w|:$<br>$\hspace{3cm}$ By induction hypothesis, we assumed $\varphi_1$ and $\varphi_2$ are <code>non-counting</code>. So<br>$\hspace{3cm}$ if $vww^{n‚àí1}\alpha[j,\infty]\models\varphi_2$, then $vww^{n}\alpha[j,\infty]\models\varphi_2$ and analogously,<br>$\hspace{3cm}$ if $vww^{n‚àí1}\alpha[i,\infty]\models\varphi_1$, then $vww^{n}\alpha[i,\infty]\models\varphi_1$ for $i &lt; j$.<br>$\hspace{3cm}$ Hence, $vw^{n+1}\alpha\models\varphi_1\ \mathcal{U}\ \varphi_2$.</p><p>$\hspace{2cm}\textbf{Case }j&gt;|v|+|w|:$<br>$\hspace{3cm}$ By adding one more cycle, we can essentially get the same suffix if $j$ is somewhere in the cycle:<br>$\hspace{3cm}$ if $vw^{n}\alpha[j,\infty]\models\varphi_2$, then $vw^{n+1}\alpha[j+|w|,\infty]\models\varphi_2$, and<br>$\hspace{3cm}$ if $vw^{n}\alpha[i,\infty]\models\varphi_1$, then $vw^{n+1}\alpha[i,\infty]\models\varphi_1$, for each position $|v|+|w|\leq i&lt;j+|w|$.<br>$\hspace{3cm}$ Additionally, by induction hypothesis from the above case, we have that</p><p>$\begin{array}{lrcccll}<br>\hspace{4cm}&amp;|v|+|w|&amp;\leq&amp;i&amp;&lt;&amp;j+|w|\newline<br>\hspace{4cm}\text{iff}&amp;|v|&amp;\leq&amp;i&amp;&lt;&amp;j\newline<br>\hspace{4cm}\text{iff}&amp;&amp;&amp;i&amp;&lt;&amp;j&amp;&amp;(\text{induction hypothesis: }i&lt;|v|+|w|)\newline<br>\end{array}$</p><p>$\hspace{3cm}$ Hence, $vw^{n}\alpha\models\varphi_1\ \mathcal{U}\ \varphi_2$.</p><p>$\hspace{1cm}$ $\textbf{2. }\textit{If }\ vw^{n+1}\alpha\models\varphi_1\ \mathcal{U}\ \varphi_2\textit{, then }\ vw^{n}\alpha\models\varphi_1\ \mathcal{U}\ \varphi_2:$<br>$\hspace{2cm}$ Again, we need consider both cases seperately:</p><p>$\hspace{2cm}\textbf{Case }j\leq|v|+|w|:$<br>$\hspace{3cm}$ By induction hypothesis, we assumed $\varphi_1$ and $\varphi_2$ are <code>non-counting</code>. So<br>$\hspace{3cm}$ if $vww^{n}\alpha[j,\infty]\models\varphi_2$, then $vww^{n-1}\alpha[j,\infty]\models\varphi_2$ and analogously,<br>$\hspace{3cm}$ if $vww^{n}\alpha[i,\infty]\models\varphi_1$, then $vww^{n-1}\alpha[i,\infty]\models\varphi_1$ for $i &lt; j$.<br>$\hspace{3cm}$ Hence, $vw^{n}\alpha\models\varphi_1\ \mathcal{U}\ \varphi_2$.</p><p>$\hspace{2cm}\textbf{Case }j&gt;|v|+|w|:$<br>$\hspace{3cm}$ Simliar to above, by subtracting one more cycle, we can essentially get the same suffix:<br>$\hspace{3cm}$ if $vw^{n+1}\alpha[j,\infty]\models\varphi_2$, then $vw^{n}\alpha[j-|w|,\infty]\models\varphi_2$, and<br>$\hspace{3cm}$ if $vw^{n+1}\alpha[i,\infty]\models\varphi_1$, then $vw^{n}\alpha[i,\infty]\models\varphi_1$, for each position $|v|+|w|\leq i&lt;j-|w|$.<br>$\hspace{3cm}$ Again, by induction hypothesis from the above case, we have that</p><p>$\begin{array}{lrcccll}<br>\hspace{4cm}&amp;|v|+|w|&amp;\leq&amp;i&amp;&lt;&amp;j-|w|\newline<br>\hspace{4cm}\text{iff}&amp;|v|+2|w|&amp;\leq&amp;i&amp;&lt;&amp;j\newline<br>\hspace{4cm}\text{iff}&amp;&amp;&amp;i&amp;&lt;&amp;j&amp;&amp;(\text{induction hypothesis: }i&lt;|v|+|w|)\newline<br>\end{array}$</p><p>$\hspace{3cm}$ Hence, $vw^{n}\alpha\models\varphi_1\ \mathcal{U}\ \varphi_2$.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Unfortunately, LTL is not expressive enough to include all $\omega$-regular languages. However, by extending the syntax of LTL, we can also extend the languages it covers.<br>In the next section, we will Quantified Propositional Temporal Logic (QPTL), and see whether it suffices to solve our problem.</p><hr><p>Next chapter: <a href="../agv6-4/">Quantified Propositional Temporal Logic (QPTL)</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 6.2 -- Expressing Program Properties using LTL</title>
      <link href="/AGV/agv6-2/"/>
      <url>/AGV/agv6-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv6-1/">Linear-Time Temporal Logic (LTL)</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In this section, we consider again our concurrent program $\small{\text{TURN}}$ introduced in <a href="../agv1-1/">section 1.1</a>. As discussed before, a major property of interest is <code>mutual exclusion</code>,i.e., at any given point of time, at most one process is in the $\text{critical}$ region. We can express <code>mutual exclusion</code>, as well as other properties of turn, in <code>LTL</code>.</p><blockquote><p>$\textbf{Example 1.1. }\small{\text{TURN}}:$<br>$$\text{local $t$: boolean where initially $t$ &#x3D; $false$}\newline<br>P_0::\left[ \begin{array}{l}\text{loop forever do}\newline<br>\hspace{1cm}\left[ \begin{array}{l}<br>\ell_0: \text{await }\neg t; \newline<br>\ell_1: \text{critical;} \newline<br>\ell_2: t :&#x3D; true; \newline<br>\end{array} \right]\end{array} \right]<br>\mid\mid P_1::\left[ \begin{array}{l}<br>\text{loop forever do}\newline<br>\hspace{1cm}\left[ \begin{array}{l}<br>m_0: \text{await } t; \newline<br>m_1: \text{critical;} \newline<br>m_2: t :&#x3D; false; \newline<br>\end{array} \right]\end{array} \right]$$</p></blockquote><h2 id="Properties-of-the-Concurrent-Program-small-text-TURN"><a href="#Properties-of-the-Concurrent-Program-small-text-TURN" class="headerlink" title="Properties of the Concurrent Program $\small{\text{TURN}}$"></a>Properties of the Concurrent Program $\small{\text{TURN}}$</h2><h3 id="Mutual-exclusion-square-neg-ell-1-wedge-m-1"><a href="#Mutual-exclusion-square-neg-ell-1-wedge-m-1" class="headerlink" title="Mutual exclusion : $\square\neg(\ell_1\wedge m_1)$"></a><em>Mutual exclusion</em> : $\square\neg(\ell_1\wedge m_1)$</h3><blockquote><p>$\ell_{1}$ and $m_1$ cannot ($\neg$) be true at the same time ($\wedge$) at every point in time ($\square$)</p></blockquote><p>The property can equivalently be formulated as $\neg(\textit{true}\ \mathcal{U}\ (\ell_1\wedge m_1))$, which means that the system remains true, until the a violation of mutual exclusion, i.e., $\ell_1\wedge m_1$, occurs</p><h3 id="Finite-waiting-square-ell-0-rightarrow-Diamond-ell-1-wedge-m-0-rightarrow-Diamond-m-1"><a href="#Finite-waiting-square-ell-0-rightarrow-Diamond-ell-1-wedge-m-0-rightarrow-Diamond-m-1" class="headerlink" title="Finite waiting : $\square((\ell_0\rightarrow\Diamond\ell_1)\wedge(m_0\rightarrow\Diamond m_1))$"></a><em>Finite waiting</em> : $\square((\ell_0\rightarrow\Diamond\ell_1)\wedge(m_0\rightarrow\Diamond m_1))$</h3><blockquote><p>If ($\rightarrow$) $\ell_0$ is reached, eventually ($\Diamond$) it moves to $\ell_1$ and so as $m_0$ and $m_1$, this happens forever ($\square$)</p></blockquote><p>In other words, each process only waits a finite amount of time (in locations $\ell_0$ and $m_0$, respectively) until it enters the $\text{critical}$ region (in locations $\ell_1$ and $m_1$, respectively):</p><p>This property is a <a href="https://en.wikipedia.org/wiki/Safety_and_liveness_properties#Liveness">Liveness</a> conditions, usually involve infinite number of steps. Usually it is only meaningful when it is held under additional assumptions on the <a href="https://en.wikipedia.org/wiki/Linear_time_property#Fairness_properties">fairness</a> of the <strong>scheduler</strong>.</p><h3 id="Finite-waiting-under-Fairness-square-Diamond-P-0-wedge-square-Diamond-P-1-rightarrow-square-ell-0-rightarrow-Diamond-ell-1-wedge-m-0-rightarrow-Diamond-m-1"><a href="#Finite-waiting-under-Fairness-square-Diamond-P-0-wedge-square-Diamond-P-1-rightarrow-square-ell-0-rightarrow-Diamond-ell-1-wedge-m-0-rightarrow-Diamond-m-1" class="headerlink" title="Finite waiting under Fairness : $(\square\Diamond P_0\wedge\square\Diamond P_1)\rightarrow\square((\ell_0\rightarrow\Diamond\ell_1)\wedge(m_0\rightarrow\Diamond m_1))$"></a><em>Finite waiting under Fairness</em> : $(\square\Diamond P_0\wedge\square\Diamond P_1)\rightarrow\square((\ell_0\rightarrow\Diamond\ell_1)\wedge(m_0\rightarrow\Diamond m_1))$</h3><blockquote><p><code>Finite waiting</code> is required if both $P_0$ and $P_1$ will always happens (taking turns)</p></blockquote><p>Let the atomic propositions $P_0$ and $P_1$ denote that the <strong>scheduler</strong> allows the respective process to advance in the current step. The subformula $\square\Diamond P_0$ states that process $P_0$ is scheduled infinitely often (always eventually). The <em>finite waiting property</em> is thus only required to hold if both processes are scheduled infinitely often.</p><h3 id="Bounded-overtaking-square-ell-0-rightarrow-neg-m-1-mathcal-U-m-1-mathcal-U-neg-m-1-mathcal-U-ell-1"><a href="#Bounded-overtaking-square-ell-0-rightarrow-neg-m-1-mathcal-U-m-1-mathcal-U-neg-m-1-mathcal-U-ell-1" class="headerlink" title="Bounded overtaking : $\square(\ell_0\rightarrow(\neg m_1\ \mathcal{U}\ (m_1\ \mathcal{U}\ (\neg m_1\ \mathcal{U}\ \ell_1))))$"></a><em>Bounded overtaking</em> : $\square(\ell_0\rightarrow(\neg m_1\ \mathcal{U}\ (m_1\ \mathcal{U}\ (\neg m_1\ \mathcal{U}\ \ell_1))))$</h3><blockquote><p>If $\ell_0$ is reached, it must leave the location $m_1$, and wait until $\ell_1$ is reached; when it leaves $\ell_1$, then it is allowed to move back to location $m_1$ again. This repeats infinitely.</p></blockquote><p>In program $\small{\text{TURN}}$, the shared variable $t$ ensures that the processes <em>take turns</em> in entering their respective $\text{critical}$ regions. <em>Bounded Overtaking</em> refers to once process $P_0$ reaches location $\ell_0$, process $P_1$ can enter location $m_1$ at most once before Process $P_0$ enters location $\ell_1$.</p><p>This formulization of <em>bounded overtaking</em> requires that Process $P_1$ will eventually reach $\ell_1$. Sometimes we may also prefer a weaker requirement, where <strong>waiting forever</strong> is fine, as long as Process $P_1$ does not get to enter $m_1$ more than once in the meantime. We can simply change the operator into <code>weak until</code>$(\mathcal{W})$ to allow the processes to wait forever: $\square(\ell_0\rightarrow(\neg m_1\ \mathcal{W}\ (m_1\ \mathcal{W}\ (\neg m_1\ \mathcal{W}\ \ell_1))))$</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In the next section, we will define the semantics of the logic for our automaton.</p><hr><p>Next chapter: <a href="../agv6-3/">LTL and Counting Languages</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/Safety_and_liveness_properties">Safety and liveness properties</a>. <a href="https://en.wikipedia.org/wiki/Linear_time_property">Linear time property</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 6.1 -- Linear-Time Temporal Logic (LTL)</title>
      <link href="/AGV/agv6-1/"/>
      <url>/AGV/agv6-1/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv5-3/">Complement B√ºchi Automaton with Odd Ranking</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In the following sections, we introduce several logics for the specification of sets of infinite sequences: <strong>LTL</strong>, <strong>QPTL</strong>, and <strong>S1S</strong>, which can be used to describe $\omega$-regular languages: we can translate a given formula into an automaton that recongnizes the models of the formula.</p><p>As a result, we can use the automata-theoretic machinery to answer logical questions like <code>satisfiability</code> or <code>validity</code>. We can also use the logics as a much more convenient starting point, compared to a direct specification using automata, for <code>verification</code> and <code>synthesis</code>.</p><h2 id="Linear-Time-Temporal-Logic-LTL"><a href="#Linear-Time-Temporal-Logic-LTL" class="headerlink" title="Linear-Time Temporal Logic (LTL)"></a>Linear-Time Temporal Logic (LTL)</h2><p>Linear-time temporal logic (LTL) is a popular logic for the specification of reactive systems. For a given set of <code>atomic propositions</code>$(AP)$, the formulas of <code>LTL</code> define sets of infinite words over the alphabet $2^{AP}$.</p><ul><li><strong>Atomic Propositions:</strong><br>the interface of a system or a component, such as (a boolean representation of) input and output variables</li><li><strong>Words defined by the Formula:</strong><br>the executions of the system that are considered correct (see example in <a href="../agv1-1/">section 1.1</a>).</li></ul><h3 id="Syntax-of-LTL"><a href="#Syntax-of-LTL" class="headerlink" title="Syntax of LTL"></a>Syntax of LTL</h3><p>œÜ has to be true until and including the point where œà first becomes true; if œà never becomes true, œÜ must remain true forever.</p><p>LTL formulars are constructed from <code>proposition logic</code> with extra <code>temporal operators</code>.</p><blockquote><p>$\begin{array}{lrl} \ \textit{Propositional logic}\newline\hspace{1cm} \cdot \ p,\varphi,\dots\in AP&amp;&amp; \ \text{(Atomic Propositions)}\newline\hspace{1cm} \cdot \ \neg\varphi,\varphi\wedge\psi,\dots&amp;&amp; \ \text{(Logical Operators)}\newline \ \textit{Temporal Operator}\newline\hspace{1cm} \cdot \bigcirc\varphi \ &#x2F;\  \mathcal{X}\ \varphi&amp; \ \text{Ne}\textbf{X}\text{t: }&amp;\varphi\text{ has to be }\textit{true}\text{ in next state}\newline\hspace{1cm} \cdot \ \Diamond \ \varphi \ &#x2F;\  \mathcal{F}\ \varphi&amp; \ \textbf{F}\text{inally: }&amp;\varphi\text{ has to be }\textit{true}\text{ eventually}\newline\hspace{1cm} \cdot \ \square \ \varphi \ &#x2F;\  \mathcal{G}\ \varphi&amp; \ \textbf{G}\text{lobally: }&amp;\varphi\text{ has to be }\textit{true}\text{ for now and so on}\newline\hspace{1cm} \cdot \ \varphi \ \mathcal{U} \ \psi&amp; \ \textbf{U}\text{ntil: }&amp;\varphi\text{ has to be }\textit{true}\textit{ at least }\text{until }\psi\text{ becomes }\textit{true}\newline\hspace{1cm} \cdot \ \varphi \ \mathcal{R} \ \psi&amp; \ \textbf{R}\text{elease: }&amp;\psi\text{ has to be }\textit{true}\text{ until }\varphi\text{ becomes true (inclusive)}\newline&amp;&amp;\psi\text{ remains }\textit{true}\textit{ forever}\text{ if } \varphi\text{ never becomes }\textit{true}\newline\hspace{1cm} \cdot \ \varphi \ \mathcal{W} \ \psi&amp; \ \textbf{W}\text{eak until: }&amp;\varphi\text{ has to be }\textit{true}\textit{ at least }\text{until }\psi\text{ becomes }\textit{true}\text{, or}\newline&amp;&amp;\varphi\text{ remains }\textit{true}\textit{ forever}\text{ if }\psi\text{ never becomes }\textit{true}\newline\hspace{1cm} \cdot \ \varphi \ \mathcal{M} \ \psi&amp; \ \textbf{M}\text{ighty Release: }&amp;\psi\text{ has to be }\textit{true}\text{ until }\varphi\text{ becomes true (inclusive)}\end{array}$</p></blockquote><h3 id="Remarks"><a href="#Remarks" class="headerlink" title="Remarks"></a>Remarks</h3><p>When we determine whether a LTL formula is $\textit{true}$ or $\textit{false}$, it only depends on <strong>current and future</strong> states.</p><p>For example, the formula $\varphi\ \mathcal{U}\ \psi$ states that $\varphi$ must remain $\textit{true}$ <strong>UNTIL</strong> $\psi$ become $\textit{true}$. If the current state we have only $\psi&#x3D;\textit{true}$, this formula is still evaluated as $\textit{true}$, even if $\varphi$ never become $\textit{true}$.</p><p>We can conclude that, $\varphi\ \mathcal{U}\ \psi &#x3D; \textit{true}$ if:</p><ol><li>In current state $\psi$ becomes $\textit{true}$ (regardless of $\varphi$‚Äôs condition)</li><li>Eventually $\psi$ becomes $\textit{true}$ in certain state (not now), and from now <strong>Until</strong> that state, $\varphi$ must remain $\textit{true}$</li></ol><h2 id="Sematics-of-LTL"><a href="#Sematics-of-LTL" class="headerlink" title="Sematics of LTL"></a>Sematics of LTL</h2><h3 id="Additional-operators"><a href="#Additional-operators" class="headerlink" title="Additional operators"></a>Additional operators</h3><p>$\mathcal{R}$, $\Diamond\ (\mathcal{F})$, $\square\ (\mathcal{G})$ are considered as <em>additional operators</em>, which can be defined by other LTL operators:</p><ul><li>$\varphi\ \mathcal{R}\ \psi\equiv\neg(\neg\varphi\ \mathcal{U}\ \neg\psi)$</li><li>$\square\ \varphi \equiv\neg\ \Diamond\ \neg\ \varphi\equiv\ \textit{false}\ \mathcal{R}\ \varphi$</li><li>$\Diamond\ \varphi\equiv\textit{true} \ \mathcal{U}\ \varphi$</li></ul><h3 id="Weak-until-mathcal-W-and-Mighty-release-mathcal-M"><a href="#Weak-until-mathcal-W-and-Mighty-release-mathcal-M" class="headerlink" title="Weak until $\mathcal{W}$ and Mighty release $\mathcal{M}$"></a>Weak until $\mathcal{W}$ and Mighty release $\mathcal{M}$</h3><p><strong>W</strong>eak Until is <strong>U</strong>ntil that accepts no stop conditions <strong>F</strong>orever, or <strong>R</strong>elease that include itself as the stop conditions:</p><ul><li>$\varphi\ \mathcal{W}\ \psi\equiv(\varphi\ \mathcal{U}\ \psi) \vee \square\ \psi\equiv\psi\ \mathcal{R}\ (\psi\vee\varphi)$</li></ul><p><strong>M</strong>ighty release is forced to <strong>R</strong>elease <strong>F</strong>inally, or simply <strong>U</strong>ntil both propositions becomes $\textit{true}$:</p><ul><li>$\varphi\ \mathcal{W}\ \psi\equiv(\varphi\ \mathcal{R}\ \psi) \wedge \Diamond\ \varphi\equiv\psi\ \mathcal{U}\ (\psi\wedge\varphi)$</li></ul><h3 id="Distributivity"><a href="#Distributivity" class="headerlink" title="Distributivity"></a>Distributivity</h3><p>$\bigcirc\ (\mathcal{X})$, $\Diamond\ (\mathcal{F})$, $\square\ (\mathcal{G})$, $\mathcal{U}$ satisfied distributivity:</p><ul><li>$\bigcirc(\varphi\vee\psi)\equiv(\bigcirc\varphi)\vee(\bigcirc\psi)$</li><li>$\bigcirc(\varphi\wedge\psi)\equiv(\bigcirc\varphi)\wedge(\bigcirc\psi)$</li><li>$\Diamond(\varphi\vee\psi)\equiv(\Diamond\varphi)\vee(\Diamond\psi)$</li><li>$\square(\varphi\wedge\psi)\equiv(\square\varphi)\wedge(\square\psi)$</li><li>$\rho\ \mathcal{U}\ (\varphi\vee\psi)\equiv(\rho\ \mathcal{U}\ \varphi)\vee(\rho\ \mathcal{U}\ \psi)$</li><li>$(\varphi\wedge\psi)\ \mathcal{U}\ \rho\equiv(\varphi\ \mathcal{U}\ \rho)\wedge(\psi\ \mathcal{U}\ \rho)$</li><li>$\bigcirc(\varphi\ \mathcal{U}\ \psi)\equiv(\bigcirc\varphi)\ \mathcal{U}\ (\bigcirc\psi)$</li></ul><h3 id="Negation-Dual"><a href="#Negation-Dual" class="headerlink" title="Negation Dual"></a>Negation Dual</h3><ul><li>First of all, Ne<strong>X</strong>t is a self dual:<br>$\neg\bigcirc\varphi\equiv\bigcirc\neg\varphi$ (Not in next step &#x3D; Next step won‚Äôt happened)</li><li><strong>F</strong>inally and <strong>G</strong>lobally are dual:<br>$\neg\Diamond\varphi\equiv\square\neg\varphi$ (Never happened eventually &#x3D; Forever never happened)<br>$\neg\square\varphi\equiv\Diamond\neg\varphi$ (Won‚Äôt happen forever &#x3D; eventually won‚Äôt happen anymore)</li><li><strong>U</strong>ntil and <strong>R</strong>elease are dual:<br>$\neg(\varphi\ \mathcal{U}\ \psi)\equiv\neg\varphi\ \mathcal{R}\ \neg\psi$ ($\psi$ won‚Äôt happen until $\varphi$ stops &#x3D; $\psi$ can‚Äôt happen unless $\varphi$ stops)<br>$\neg(\varphi\ \mathcal{R}\ \psi)\equiv\neg\varphi\ \mathcal{U}\ \neg\psi$ (Never stop $\psi$ with $\varphi$ &#x3D; $\varphi$ never happens, if it does, that means $\psi$ has been stopped)</li><li>Similarly, <strong>W</strong>eak Until and <strong>M</strong>ighty Release are also dual:<br>$\neg(\varphi\ \mathcal{W}\ \psi)\equiv\neg\varphi\ \mathcal{M}\ \neg\psi$<br>$\neg(\varphi\ \mathcal{M}\ \psi)\equiv\neg\varphi\ \mathcal{W}\ \neg\psi$</li></ul><h3 id="Special-temporal-properties"><a href="#Special-temporal-properties" class="headerlink" title="Special temporal properties"></a>Special temporal properties</h3><ul><li>$\Diamond\varphi\equiv\Diamond\Diamond\varphi$<br>(<strong>F</strong>inally <strong>F</strong>inally $\varphi$ is $\textit{true}$)</li><li>$\square\varphi\equiv\square\square\varphi$<br>($\varphi$ is always always $\textit{true}$)</li><li>$\varphi\ \mathcal{U}\ \psi\equiv\varphi\ \mathcal{U}\ (\varphi\ \mathcal{U}\ \psi)$<br>($\varphi$ is $\textit{true}$ <strong>U</strong>ntil $\psi$ become $\textit{true}$ &#x3D; $\varphi$ is $\textit{true}$ <strong>U</strong>ntil, if ‚Äú$\varphi$ is $\textit{true}$ <strong>U</strong>ntil $\psi$ become $\textit{true}$‚Äù is $\textit{true}$)</li><li>$\Diamond\varphi\equiv\varphi\vee \bigcirc(\Diamond\varphi)$<br>( $\varphi$ <strong>F</strong>inally becomes $\textit{true}$ &#x3D; either now $\varphi$ is $\textit{true}$ or in ne<strong>X</strong>t step $\varphi$ <strong>F</strong>inally becomes $\textit{true}$)</li><li>$\square\varphi\equiv\varphi\wedge \bigcirc(\square\varphi)$<br>( $\varphi$ is always $\textit{true}$ &#x3D; now $\varphi$ is $\textit{true}$ and in ne<strong>X</strong>t step $\varphi$ is also always $\textit{true}$)</li></ul><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In this section, we have go through basic sytanx and properties of LTL. In next section we will try to apply the formula to some systems and $\omega$-languages.</p><hr><p>Next chapter: <a href="../agv6-2/">Expressing Program Properties using LTL</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 5.3 -- Complement B√ºchi Automaton with Odd Ranking</title>
      <link href="/AGV/agv5-3/"/>
      <url>/AGV/agv5-3/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv5-2/">Ranking of DAG</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In <a href="../agv4-2/">section 4.2</a>, we have shown the complementation construction for <strong>deterministic B√ºchi Automata</strong>.</p><p>Now, by using DAG we can construct complement automaton of any B√ºchi Automata, with the help of the definition of <code>odd ranking</code> and the new function <strong>Level Ranking</strong>.</p><h2 id="Level-Ranking"><a href="#Level-Ranking" class="headerlink" title="Level Ranking"></a>Level Ranking</h2><blockquote><p>$\textbf{Definition 5.3. }\text{(Level Ranking). Consider a B√ºchi Automaton }\mathcal{A}&#x3D;(\Sigma,Q,I,T,\small\text{B√úCHI}\normalsize(F)).\newline\text{A level ranking }\ell\text{ is a pair }(S,g)\text{ such that:}$<br>$\begin{array}{l}<br>\hspace{1cm} \cdot \ S\subseteq Q,\newline<br>\hspace{1cm} \cdot \ g:S\rightarrow\lbrace 0,\dots,2|Q|\rbrace\text{ with }g(q)\text{ necessarily even if }q\in F.\end{array}\newline \ \newline\text{We also denote: }$<br>$\begin{array}{lll}<br>\hspace{1cm} \cdot \ \textsf{Lvlrks}&amp;&#x3D;&amp;\text{the (finite) set of level ranks, and }\newline<br>\hspace{1cm} \cdot \ \textsf{Initrks}&amp;&#x3D;&amp;\text{the set of level ranks s.t. }S&#x3D;I\end{array}\newline \ \newline<br>\hspace{1cm}\text{We say that a level ranking }\ell‚Äô\text{, given by }(S‚Äô,g‚Äô)\text{ cover }\ell\text{, given by }(S,g)\text{ for }\sigma\in\Sigma,\newline\text{if }S‚Äô&#x3D;\lbrace q‚Äô\mid(q,\sigma,q‚Äô)\in T\rbrace\text{ and for all }q\in S,q‚Äô\in S‚Äô\text{ with }(q,\sigma,q‚Äô)\in T\text{, it holds that } g‚Äô(q‚Äô)\leq g(q).$</p></blockquote><p>Here, the <code>level ranking</code> refers to a pair that contains set of states that share the same ranking.</p><h3 id="ell‚Äô-covers-ell"><a href="#ell‚Äô-covers-ell" class="headerlink" title="$\ell‚Äô$ covers $\ell$ ?"></a>$\ell‚Äô$ covers $\ell$ ?</h3><p>The last part of the definition states that one level ranking is <strong>covering</strong> the other if the following satisfied:</p><ul><li>Let $\ell‚Äô&#x3D;(S‚Äô,g‚Äô)$ and $\ell&#x3D;(S,g)$ for $\sigma\in\Sigma$</li><li>$q$ are the states that in the set $S$, so as $q‚Äô$ are in $S‚Äô$</li><li><strong>All states $q‚Äô$ are some successors of some states</strong> $q, \ (S‚Äô&#x3D;\lbrace q‚Äô\mid(q,\sigma,q‚Äô)\in T\rbrace)$</li><li>for all $q\in S,q‚Äô\in S‚Äô, (q,\sigma,q‚Äô)\in T$, <strong>the rank of $q‚Äô$ is lower than $q, \ (g‚Äô(q‚Äô)\leq g(q))$</strong></li></ul><p>That means the whole level‚Äôs successors will never have higher rank than itself.</p><h2 id="Complement-Automaton-Construction"><a href="#Complement-Automaton-Construction" class="headerlink" title="Complement Automaton Construction"></a>Complement Automaton Construction</h2><p>By <a href="../agv5-2/">lemma 5.1</a>, we know that a word $\alpha$ that is rejected by $\mathcal{A}$ has an <code>odd ranking</code> on the run DAG of $\mathcal{A}$ on $\alpha$.<br>Now our complement will do the opposite: it only accepts the word that has <code>odd ranking</code>.</p><p>To achieve this, we construct the <code>odd ranking</code>, level by level, by assigning ranks to vertices.<br>The definition of <code>level ranks</code> and <code>covering</code> for a letter ensure that the requirements of a ranking are satisfied.</p><p>Through the acceptance condition, we ensure that the ranking is <code>odd</code>, i.e., there is no infinite path that consists only of even-ranked vertices.</p><blockquote><p>$\textbf{Construction 5.1. }\text{Given a B√ºchi Automaton }\mathcal{A}&#x3D;(\Sigma,Q,I,T,\small\text{B√úCHI} \normalsize(F))\text{ that recognizes}\newline\text{the language }L\text{, we construct a B√ºchi Automaton}$ $$\newline \mathcal{A‚Äô}&#x3D;(\Sigma,\textsf{Lvlrks}\times\textsf{OnEvenPath},I‚Äô,T‚Äô,\small\text{B√úCHI}\normalsize(F))$$ $\text{that recognizes the language }\Sigma^\omega\setminus L\text{ as follows.}$<br>$\begin{array}{lrl}<br>\hspace{0.5cm} \cdot &amp;\textsf{OnEvenPath} &#x3D; &amp; 2^Q, \text{tracking states in the current level,} \newline<br>\hspace{0.5cm} \cdot &amp;I‚Äô&#x3D; &amp; \lbrace (\ell,R) \mid \ell \in \textsf{InitRks, } \ell \text{ is given by } (S,g) \text{, and } R &#x3D; \lbrace q \mid g(q) \text{ is even} \rbrace \rbrace \newline<br>\hspace{0.5cm} \cdot &amp;T‚Äô&#x3D; &amp; \textsf{NewEvenPaths} \cup \textsf{ContinueEvenPaths}, \text{ where} \newline<br>\hspace{0.5cm} &amp;&amp; \hspace{0.9cm}\textsf{NewEvenPaths}&#x3D;\lbrace ((\ell,\varnothing),\sigma,(\ell‚Äô,R‚Äô)) \mid \ell‚Äô \text{ covers } \ell \text{ for } \sigma, \newline<br>\hspace{0.5cm} &amp;&amp; \hspace{4.8cm} \ell‚Äô \text{ is given by } (S‚Äô,g‚Äô), \newline<br>\hspace{0.5cm} &amp;&amp; \hspace{4.8cm} \text{and } R‚Äô &#x3D; \lbrace q‚Äô \mid g‚Äô(q‚Äô) \text{ is even} \rbrace \rbrace \newline<br>\hspace{0.5cm} &amp;&amp; \textsf{ContinueEvenPaths} &#x3D; \lbrace ((\ell,R),\sigma,(\ell‚Äô,R‚Äô)) \mid R \neq \varnothing, \ell‚Äô \text{ covers } \ell \text{ for } \sigma,\newline<br>\hspace{0.5cm} &amp;&amp; \hspace{4.8cm} \ell‚Äô \text{ is given by } (S‚Äô,g‚Äô)\text{, and}\newline<br>\hspace{0.5cm} &amp;&amp; \hspace{4.8cm} R‚Äô &#x3D; \lbrace q‚Äô \mid (q,\sigma,q‚Äô) \in T, q \in R, \text{ and } g‚Äô(q‚Äô) \text{ is even} \rbrace \rbrace \newline<br>\hspace{0.5cm} \cdot &amp;F‚Äô &#x3D; &amp; \textsf{Lvlrks} \times \lbrace \varnothing \rbrace.<br>\end{array}$</p></blockquote><h3 id="Explanation"><a href="#Explanation" class="headerlink" title="Explanation"></a>Explanation</h3><p>$Q‚Äô &#x3D; \textsf{Lvlrks}\times\textsf{OnEvenPath}:$ all states contain their <code>level ranking</code> and set of all states that is tracked currently (states would be dropped if it leads to odd-ranked vertex).</p><p>$I‚Äô:$ The initial state contains the initial <code>level ranking</code> ($\textsf{Lvlrks}$), and the set of all <code>even ranking</code> states ($R$).</p><p>$T‚Äô:$ We have transitions $\textsf{NewEvenPaths}$ and $\textsf{ContinueEvenPaths}$. Both share some properties in common.</p><ul><li>all the states are <code>covered</code> by their successors,</li><li>their successors only keep track on <strong>even ranking</strong> states,</li><li>$\textsf{ContinueEvenPaths}$ requires that the current states must keep track on <strong>even ranking</strong> states already</li></ul><p>$F‚Äô:$ Accepting states are those has no infinite path that consists only of <code>even-ranked</code> vertices.(<code>odd ranking</code>).</p><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>Now we can try to verify the Lemma with our construction:</p><blockquote><p>$\textbf{Lemma 5.2. }\textit{The automaton of Construction 5.1 has an accepting run on input }\alpha\newline\textit{if and only if the run DAG of }\mathcal{A}\textit{ on }\alpha\textit{ has an odd ranking.}$</p></blockquote><p>The run of the automaton on the input word builds a potential ranking, level by level. Note that the level-by-level guessing of the ranking is the only source of non-determinism. But if the guess is indeed an <code>odd ranking</code>, then the automaton has a unique run.</p><p>In the construction, we used <code>level rankings</code> to ensure the definition of <code>ranking</code> is satisified, so instead of verify whether it is <code>odd ranking</code>, we only need to verify that in the guessed ranking, there is no infinite path of even-ranked vertices.</p><p>At any given point, the second component ($\textsf{OnEvenPath}&#x2F;R$) in the state of the constructed automaton tracks a ‚Äúbatch‚Äù of paths that traverse <strong>solely through even-ranked vertices</strong>. Paths that hit an <strong>odd-ranked vertex</strong> are dropped from the batch. The <strong>acceptance condition</strong> enforces that every batch that is followed must be eventually be <strong>emptied</strong>.</p><blockquote><p><em><strong>Odd ranking &#x3D; no infinite path of even-ranked vertices &#x3D; eventually every batch are emptied</strong></em></p></blockquote><p>So we can rephrase the lemma as ‚ÄúThe run is accepting if and only if <strong>eventually every batch are emptied</strong>‚Äú.</p><h3 id="If-the-run-is-accepting-then-eventually-every-batch-are-emptied"><a href="#If-the-run-is-accepting-then-eventually-every-batch-are-emptied" class="headerlink" title="If the run is accepting, then eventually every batch are emptied"></a>If the run is accepting, then eventually every batch are emptied</h3><p>This condition is clearly necessary for the guessed ranking to be odd: if there is eventually a batch that is never emptied, this corresponds to an infinite path of <code>even-ranked</code> vertices in the run DAG, violating <strong>requirement 3 (The rank cannot increase upon traversing an edge)</strong>.</p><p>Why? Because as long as we have one empty batch, the ranking of that batch will definitely be hihger than the those which are not empty (consider the definition of <code>rank</code> function and pruning), and any states will never have high rank than their successors.</p><h3 id="If-eventually-every-batch-are-emptied-then-the-run-is-accepting"><a href="#If-eventually-every-batch-are-emptied-then-the-run-is-accepting" class="headerlink" title="If eventually every batch are emptied, then the run is accepting"></a>If eventually every batch are emptied, then the run is accepting</h3><p>Assume we have non accepting run that have emptied batch, which means there is an infinite path of <code>even-ranked</code> vertices in the run DAG.</p><p>Now suppose this run has the batch-tracking set $\textsf{OnEvenPath}$ is emptied infinitely often. That means in the infinite path of <code>even-ranked</code> vertices there is an level $n$ so that $\textsf{OnEvenPath}$ is emptied at step $n$.</p><p>Because this is an infinite path of even-ranked vertices, once $\textsf{OnEvenPath}$ is emptied at step $n$, the next transition will be $\textsf{NewEvenPath}$. Which means there is a successor in level $n+1$ that has an <code>even rank</code>.</p><p>Since the path is infinite, subsequent transitions will be $\textsf{ContinueEvenPaths}$, and the even-rank vertices will be remained in the set of $\textsf{OnEvenPath}$. Which contradicts that the run have emptied batch. Therefore this non accepting run that have emptied batch do not exist.</p><hr><p>Next chapter: <a href="../agv6-1/">Linear-Time Temporal Logic (LTL)</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 5.2 -- Ranking of DAG</title>
      <link href="/AGV/agv5-2/"/>
      <url>/AGV/agv5-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv5-1/">Infinite Directed Acyclic Graph (DAG)</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Ranking"><a href="#Ranking" class="headerlink" title="Ranking"></a>Ranking</h2><p>last section, we have introduced the <strong>DAG</strong> and the <strong>pruning method</strong> to reason about the run of the word on a non-deterministic B√ºchi automaton. We know that pruning can be use to prove the <strong>non-acceptance</strong> of the word by automaton is we obtains an empty graph eventually.</p><p><img src="/../images/notes/uds/agv/5_1_g1.png"></p><p>In this section, we will introduce <strong>ranking</strong>, which can formalize our pruning construction.</p><blockquote><p>$\textbf{Definition 5.2. }\text{(Ranking). A }\textit{ranking}\text{ on a run DAG } G&#x3D;(V,E)\text{ is a function }f:V\rightarrow\newline\lbrace 0,\dots,2|Q|\rbrace\text{ such that:}$<br>$\begin{array}{l}\hspace{1cm} 1. \ \text{ If }q\in F\text{, then }f((q,i))\text{ is even for all }i.\newline\hspace{1cm} 2. \ \text{ If }(v,v‚Äô)\in E\text{, we have that }f(v‚Äô)\leq f(v).\end{array}\newline$<br>$\text{A ranking } f\text{ is }\textit{odd}\text{ if, for each even }j\text{, there is no infinite path in }G\text{ that consists only }\newline\text{of verticies }v\text{ such that }f(v)&#x3D;j.$</p></blockquote><p>By the above definition, we can see:</p><ol><li>All verticies that contains state q (the accepting state) are marked as even rank.</li><li>Verticies will never have lower rank than their successors.</li></ol><p>Most importantly, it introduced a new concept: <strong>Odd Ranking</strong>. Meaning that the run of the DAG is rejected.</p><h2 id="From-Ranking-to-Rank"><a href="#From-Ranking-to-Rank" class="headerlink" title="From Ranking to Rank"></a>From Ranking to Rank</h2><p>Now, let‚Äôs consider the function $rank:V\rightarrow\lbrace 0,\dots,2|Q|\rbrace$, where</p><ul><li>$rank(q,i)&#x3D;2j$ iff $(q,i)$ is <strong>endangered</strong> in $G_{2j}$, and</li><li>$rank(q,i)&#x3D;2j+1$ iff $(q,i)$ is <strong>safe</strong> in $G_{2j+1}$.</li></ul><p><img src="/../images/notes/uds/agv/5_2_dag.png"></p><p>By tracking our pruning procedure, we can easily identify their rank now.<br>Blue verticies that remove in $G_1$ are <strong>safe</strong>, thus their rank are 1, and so as orange (2), green (3) and red (4).</p><h2 id="From-Rank-to-Odd-Ranking"><a href="#From-Rank-to-Odd-Ranking" class="headerlink" title="From Rank to Odd Ranking"></a>From Rank to Odd Ranking</h2><p>Now back to odd ranking, by our new function $rank$, we can prove the following lemma.</p><blockquote><p>$\textbf{Lemma 5.1. }\newline\textit{A B√ºchi automaton }\mathcal{A}\textit{ reject the word }\alpha\textit{ iff the run DAG of }\mathcal{A}\textit{ on }\alpha\textit{ has an odd ranking}$</p></blockquote><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><blockquote><p><strong>If the run DAG of $\mathcal{A}$ on $\alpha$ has an odd ranking, then $\alpha$ is rejected</strong></p></blockquote><p>By the definition above, we know that graph with odd ranking has <strong>no infinite path that settles on only even rank $f(v)&#x3D;j$</strong>. Which means:</p><ul><li>every run of $\mathcal{A}$ on $\alpha$ <strong>gets stuck</strong>, or,</li><li>eventually <strong>settles on vertices with a constant odd rank</strong>, since ranks are not increasing.</li></ul><p>In which case the run eventually only visits states that are not accepting.</p><blockquote><p><strong>If $\alpha$ is rejected, then the run DAG of $\mathcal{A}$ on $\alpha$ has an odd ranking</strong></p></blockquote><p>Since we know pruning leads to rejecting with function $rank$. Therefore, instead of using odd ranking directly, we try to show the function $rank$ is the odd ranking. To prove this, we need to show that:</p><ol><li>All vertices are indeed pruned away, latest by step $2|Q|$.</li><li>Accepting vertices must have an even rank</li><li>The rank cannot increase upon traversing an edge.</li><li>There is no infinite path that consists only of vertices of even rank.</li></ol><h3 id="Requirement-1-All-vertices-are-indeed-pruned-away-latest-by-step-2-Q"><a href="#Requirement-1-All-vertices-are-indeed-pruned-away-latest-by-step-2-Q" class="headerlink" title="Requirement 1: All vertices are indeed pruned away, latest by step $2|Q|$"></a>Requirement 1: All vertices are indeed pruned away, latest by step $2|Q|$</h3><p>Here, we define the <strong>width</strong> of a level $j$ in a graph $G_i$ as the number of vertices of the form $(q,j)$ in $G_i$.<br><img src="/../images/notes/uds/agv/5_2_width.png"></p><p>Assume we are in step $2j$, it removes all <code>endangered</code> vertices from $G_{2j}$. Then how would $G_{2j+1}$ become?</p><ol><li>become empty (all vertices in $G_{2j}$ are <code>endangered</code>)</li><li>still has infinitely many vertices<br>(by definition, vertices that not <code>endangered</code> always have some infinite path, also because $\infty-n&#x3D;\infty$)</li></ol><p>In scenario <strong>2</strong>, since our <code>premise</code> is that the word is <strong>rejected</strong>, there must exist a <code>safe</code> vertex in $G_{2j+1}$. If there‚Äôs no <code>safe</code> vertex, then those vertices are either accepting, or has a path to accepting vertex, which contradicts to our premise.</p><blockquote><p><em><strong>a) Each iteration there must be at least one <code>safe</code> vertex being removed</strong></em></p></blockquote><p>Among all the <code>safe</code> vertices in $G_{2j+1}$, consider the vertex $(q,m)$ which has the smallest $m$ (closest to the beginning). All descendants of this vertex in $G_{2j+1}$ are also <code>safe</code> (because <code>safe</code> refers to the whole path).</p><p>Therefore, these <code>safe</code> vertices will be pruned away in step $2j+1$. Observe the affect towards the width after these deletions:</p><ul><li>At the beginning of iteration $0$, each level has width at most $|Q|$ (max. no. of states).</li><li>In every iteration $j$, the widths of all levels $i\geq m$ decrease by at least 1.<br>(because vertex $(q,m)$ and all its descendants in $i\geq m$ are removed)</li></ul><blockquote><p><em><strong>b) If one <code>safe</code> vertex is removed, all its descendants will also be removed</strong></em></p></blockquote><p>By <em><strong>a)</strong></em> and <em><strong>b)</strong></em>, we can ensure that after $|Q|$ iterations of <code>safe</code> vertices removal there must be some level $m$ contains no more vertices, which means now the graph terminate in $m$ and it is a <strong>finite graph</strong>.</p><p>By including the iteration of <code>endangered</code> vertices, we can conclude that in step $2|Q|$, $G_{2|Q|}$ must be a finite graph, all vertices are <code>endangered</code>, thus it will prune all vertices away.</p><h3 id="Requirement-2-Accepting-vertices-must-have-an-even-rank"><a href="#Requirement-2-Accepting-vertices-must-have-an-even-rank" class="headerlink" title="Requirement 2: Accepting vertices must have an even rank"></a>Requirement 2: Accepting vertices must have an even rank</h3><p>Since accepting vertices are not <code>safe</code>, and our premise it that the word is rejected. That means the path contains accepting verticeis can only be <strong>finite</strong>, which means they are always <code>endangered</code>.</p><p>In our rank function, <code>endangered</code> vertices have even rank and thus accepting vertices always have even rank.</p><h3 id="Requirement-3-The-rank-cannot-increase-upon-traversing-an-edge"><a href="#Requirement-3-The-rank-cannot-increase-upon-traversing-an-edge" class="headerlink" title="Requirement 3: The rank cannot increase upon traversing an edge"></a>Requirement 3: The rank cannot increase upon traversing an edge</h3><p>Suppose there is a $(q‚Äô,i+1)$ that is pruned later than $(q,i)$. Consider the step $j$ at which $(q,i)$ is pruned. The graph $G_j$ would have contained both vertices, along with their edge.</p><p>If $j$ is even, it means that $(q,i)$ has even rank, and <code>endangered</code> in $G_j$ , and hence so must be its successor $(q‚Äô,i+1)$, meaning that it is pruned at step $j$.</p><p>If $j$ is odd, then $(q,i)$ was established to be <code>safe</code> in Gj , implying the safety of its successor too. In both cases, the pruning of $(q‚Äô,i+1)$ in the same step is inevitable.</p><h3 id="Requirement-4-There-is-no-infinite-path-of-only-even-ranked-vertices"><a href="#Requirement-4-There-is-no-infinite-path-of-only-even-ranked-vertices" class="headerlink" title="Requirement 4: There is no infinite path of only even-ranked vertices"></a>Requirement 4: There is no infinite path of only even-ranked vertices</h3><p>If such a path exists, since ranks do not increase along a path, and there are only finitely many ranks, this path will eventually consist only of vertices of rank $2j$.</p><p>However, only <code>endangered</code> verticies will have even rank in $G_{2j}$, and endangered vertices only have finite paths.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>With the above properties and proofs, we know that:</p><ul><li>the run DAG of $\mathcal{A}$ on $\alpha$ has an odd ranking &#x3D; $\alpha$ is rejected</li><li>Pruning method with $rank$ function &#x3D; odd ranking</li></ul><blockquote><p>So if a word is rejected, its run DAG always becomes an empty graph after pruning, and if a run DAG eventually becomes an empty graph after pruning, it must be rejected by $\mathcal{A}$.</p></blockquote><p>With these definition, we can now construct complementation of B√ºchi automaton $\mathcal{A}$ using the run DAG of $\mathcal{A}$ and the odd ranking. Let see how is it done in the next section.</p><hr><p>Next chapter: <a href="../agv5-3/">Complement B√ºchi Automaton with Odd Ranking</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 5.1 -- Infinite Directed Acyclic Graph (DAG)</title>
      <link href="/AGV/agv5-1/"/>
      <url>/AGV/agv5-1/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv4-2/">Complementation of deterministic B√ºchi Automata</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Reasoning-about-all-runs-of-an-automaton"><a href="#Reasoning-about-all-runs-of-an-automaton" class="headerlink" title="Reasoning about all runs of an automaton"></a>Reasoning about all runs of an automaton</h2><p>Since complementation inevitably introduce <strong>nondeterminism</strong>, we need to check whether <strong>all</strong> runs of the automaton on the word are <strong>rejecting</strong> to determine whether a word is in the complement of the language recognized by this B√ºchi automaton.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Consider the following nondeterministic B√ºchi automaton $\mathcal{A}$. Its language consists of all infinite words over $\lbrace a,b\rbrace$ with infinitely many <em>b</em>s, i.e., $(a^*b)^\omega$:</p><p><img src="/../images/notes/uds/agv/5_1_eg.png"></p><blockquote><p>$\textbf{Definition 5.1. }\text{Let }\mathcal{A}&#x3D;(\Sigma,Q,I,T,\small\text{B√úCHI} \normalsize(F))\text{ be a B√ºchi automaton. The run DAG of }\mathcal{A}\newline\text{on a word }\alpha\in\Sigma^\omega\text{ is the directed acylic graph }G&#x3D;(V,E)\text{, where}$<br>$\begin{array}{lll}<br>\hspace{1cm} \cdot \ V&amp;&#x3D;&amp;\cup_{i\geq0}(Q_i\times\lbrace i\rbrace)\text{ with }Q_0&#x3D;I\text{ and}\newline<br>\hspace{1.1cm} \ Q_{i+1}&amp;&#x3D;&amp;\lbrace q‚Äô\mid(q,\alpha(i),q‚Äô)\in T\text{ for some }q\in Q\rbrace\newline<br>\hspace{1cm} \cdot \ E&amp;&#x3D;&amp;\lbrace((q,i),(q‚Äô,i+1))\mid i\geq 0,(q,\alpha(i),q‚Äô)\in T\rbrace.\end{array}$<br>$\text{For a natural number }i\text{, we refer to the set }Q_i\text{ as the }\textit{level }i\text{ of the DAG.}$</p></blockquote><p>Using <strong>infinite directed acyclic graph (DAG)</strong> to represent the set of all runs on a particular word, e.g., $ababa^\omega$.</p><p><img src="/../images/notes/uds/agv/5_1_g1.png"></p><p>In the above example: the word $\alpha&#x3D;ababa^\omega$ has only two <em>b</em>‚Äòs and hence must be rejected by $\mathcal{A}$.</p><p>Since the automaton is nondeterministic, a single word of $\mathcal{A}$ will have multiple runs on $\alpha$, represented by each <em>path in DAG</em>. The path is called accepting <strong>if and only if</strong> its corresponding run is accepting, i.e., the path visits $F\times\mathcal{A}$ infinitely often.</p><h2 id="Graph-Pruning"><a href="#Graph-Pruning" class="headerlink" title="Graph Pruning"></a>Graph Pruning</h2><p>To show the <strong>non-acceptance</strong> of $\alpha$ by $\mathcal{A}$, we can systematically identifying and pruning away vertices of the run DAG that only lead to rejecting paths until the graph is empty using the following definitions:</p><table><thead><tr><th align="left">Vertices in DAG</th><th align="left">Defintiion</th></tr></thead><tbody><tr><td align="left"><code>Endangered</code></td><td align="left">when they only have <strong>finitely many descendants</strong></td></tr><tr><td align="left"><code>Safe</code></td><td align="left">when they are <strong>not in</strong> $F\times\mathcal{A}$, and <strong>none of its descendants</strong> are in $F\times\mathcal{A}$ either</td></tr></tbody></table><p>We start with a graph $G_0&#x3D;G$. Each iteration $j\geq 0$ of our pruning will consist of two steps:</p><ol><li>in step $2j$, the graph &#x3D; $G_{2j}$, remove all <code>endangered</code> vertices, graph after removal &#x3D; $G_{2j+1}$</li><li>in step $2j+1$, the graph &#x3D; $G_{2j+1}$, remove all <code>safe</code> vertices, graph after removal &#x3D; $G_{2j+2}$</li></ol><h3 id="Step-0-Remove-endangered-vertices"><a href="#Step-0-Remove-endangered-vertices" class="headerlink" title="Step 0: Remove endangered vertices"></a>Step 0: Remove <code>endangered</code> vertices</h3><ul><li>Input: $G_0$ ‚Üë (using example above), Output: $G_1$ ‚Üì</li></ul><p>Since there‚Äôs no <code>endangered</code> verticies, $G_0$ &#x3D; $G_1$</p><p><img src="/../images/notes/uds/agv/5_1_g1.png"></p><h3 id="Step-1-Remove-safe-vertices-marked-as-blue"><a href="#Step-1-Remove-safe-vertices-marked-as-blue" class="headerlink" title="Step 1: Remove safe vertices (marked as blue)"></a>Step 1: Remove <code>safe</code> vertices (marked as blue)</h3><ul><li>Input: $G_1$ ‚Üë, Output: $G_2$ ‚Üì</li></ul><p>As we can see all vertices that in state r stay in r forever (accepting state is q). Therefore those path can never be accepted and they are safe.</p><p><img src="/../images/notes/uds/agv/5_1_g2.png"></p><h3 id="Step-2-Remove-endangered-vertices-marked-as-red"><a href="#Step-2-Remove-endangered-vertices-marked-as-red" class="headerlink" title="Step 2: Remove endangered vertices (marked as red)"></a>Step 2: Remove <code>endangered</code> vertices (marked as red)</h3><ul><li>Input: $G_2$ ‚Üë, Output: $G_3$ ‚Üì</li></ul><p>After <code>safe</code> verticies in r are removed, paths towards r from q become dead end. Therefore they are now <code>endangered</code>.</p><p><img src="/../images/notes/uds/agv/5_1_g3.png"></p><h3 id="Step-3-Remove-safe-vertices-marked-as-blue"><a href="#Step-3-Remove-safe-vertices-marked-as-blue" class="headerlink" title="Step 3: Remove safe vertices (marked as blue)"></a>Step 3: Remove <code>safe</code> vertices (marked as blue)</h3><ul><li>Input: $G_3$ ‚Üë, Output: $G_4$ ‚Üì</li></ul><p>Now all the vertices starting from (p,3) stay in p forever. Therefore they are <code>safe</code> as well.</p><p><img src="/../images/notes/uds/agv/5_1_g4.png"></p><h3 id="Step-4-Remove-endangered-vertices-marked-as-red"><a href="#Step-4-Remove-endangered-vertices-marked-as-red" class="headerlink" title="Step 4: Remove endangered vertices (marked as red)"></a>Step 4: Remove <code>endangered</code> vertices (marked as red)</h3><ul><li>Input: $G_4$ ‚Üë, Output: $G_5$ ‚Üì</li></ul><p>Now the graph is finite, meaning all the vertices in the graph are <code>endangered</code>.</p><p><img src="/../images/notes/uds/agv/5_1_g5.png"></p><p>Therefore, graph $G_5$ will be an empty graph, which means there‚Äôs no accepting path and thus the word $ababa^\omega$ is rejected.</p><h3 id="Explained-in-Human-language"><a href="#Explained-in-Human-language" class="headerlink" title="Explained in Human language"></a>Explained in Human language</h3><p>We start from removing <code>endangered</code> verticies in <strong>step 0</strong> because they can never infinitely reach the accepting states. Then we can remove all <code>Safe</code> verticies in <strong>step 1</strong> because they never visit accepting states anymore.</p><p>For the subsequent pruning, if a vertex v of the original run DAG is pruned away in step $2j$ because it is <code>endangered</code> in $G_{2j}$, it means that all paths from v in the original run DAG can reach were pruned away in the earlier steps.</p><p>Similarly, if a vertex v of the original run DAG is pruned away in step $2j+1$ because it is <code>safe</code> in $G_{2j+1}$, it means that v corresponds to a <strong>non-accepting state</strong>. And furthermore, all paths from v in the original run DAG either avoid accepting vertices, or eventually reach a vertex that was pruned away in the earlier steps.</p><p>So we can see that if a vertex is pruned away, all paths from that vertex are rejecting. Hence, if our scheme eventually obtains the empty graph, the pruning is a proof of the non-acceptance of the word by the automaton.</p><p>We formalize this type of reasoning as a <code>ranking</code>, which labels the vertices with numbers. We will define <code>ranking</code> in the next chapter. </p><hr><p>Next chapter: <a href="../agv5-2/">Ranking of DAG</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 4.2 -- Complementation of deterministic B√ºchi Automata</title>
      <link href="/AGV/agv4-2/"/>
      <url>/AGV/agv4-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv4-1/">Deterministic vs. Nondeterministic B√ºchi Automata</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>For regular languages, Complementation is very simple: one translates a given complete deterministic automaton $\mathcal{A}$ that recognizes some language $L\subseteq\Sigma^*$ into an automaton $\mathcal{A‚Äô}$ that recognizes the complement $\Sigma^*\setminus L$ by complementing the set of final states, i.e., $F‚Äô&#x3D;Q\setminus F$.</p><p>For deterministic B√ºchi automata, the construction is tricky, because it introduces <strong>nondeterminism</strong></p><blockquote><p>$\textbf{Construction 4.1. }\text{Let }\mathcal{A}&#x3D;(\Sigma,Q,I,T,\small\text{B√úCHI} \normalsize(F))\text{ be a complete deterministic B√ºchi}\newline\text{automaton, where we assume w.l.o.g. that } Q\neq\varnothing. \text{ We construct a B√ºchi automaton}\newline\mathcal{A‚Äô}&#x3D;(\Sigma,Q‚Äô,I‚Äô,T‚Äô,\small\text{B√úCHI} \normalsize (F‚Äô))\text{ with }\mathcal{L}(\mathcal{A‚Äô})&#x3D;\Sigma^\omega\setminus\mathcal{L}(\mathcal{A})\text{ as follows:}$<br>$\begin{array}{lrll}<br>\hspace{1cm} \cdot &amp;Q‚Äô&amp;&#x3D;&amp;(Q\times\lbrace 0\rbrace)\cup((Q\setminus F)\times\lbrace 1\rbrace)\newline<br>\hspace{1cm} \cdot &amp;I‚Äô&amp;&#x3D;&amp;I\times\lbrace 0\rbrace\newline<br>\hspace{1cm} \cdot &amp;T‚Äô&amp;&#x3D;&amp;\lbrace ((q,0),\sigma,(q‚Äô,i))\mid(q,\sigma,q‚Äô)\in T,i\in\lbrace 0,1\rbrace,(q‚Äô,i)\in Q‚Äô\rbrace \cup \newline<br>\hspace{1cm} \ &amp;&amp;&amp;\lbrace ((q,1),\sigma,(q‚Äô,1))\mid(q,\sigma,q‚Äô)\in T,q‚Äô,q‚Äô\in Q\setminus F\rbrace\newline<br>\hspace{1cm} \cdot &amp;F‚Äô&amp;&#x3D;&amp;(Q\setminus F)\times\lbrace 1\rbrace<br>\end{array}$</p></blockquote><table><thead><tr><th align="left"></th><th align="left">Explaination</th></tr></thead><tbody><tr><td align="left">$Q‚Äô$</td><td align="left">Uses two copies of the given automaton $\mathcal{A}$, mark them seperately using $\lbrace 0\rbrace$ and $\lbrace 1\rbrace$, notice that all <strong>accpeting states</strong> from $\lbrace 1\rbrace$ are eliminated</td></tr><tr><td align="left">$I‚Äô$</td><td align="left">The complemented automaton starts from initial states from $\lbrace 0\rbrace$.</td></tr><tr><td align="left">$T‚Äô$</td><td align="left">The switch from $\lbrace 0\rbrace$ and $\lbrace 1\rbrace$ happens nondeterministically. And once you enter the second copy $\lbrace 1\rbrace$, it stays forever.</td></tr><tr><td align="left">$F‚Äô$</td><td align="left">The automaton $\mathcal{A‚Äô}$ accepts if the run ends up in the second copy, which means that, on the unique run of $\mathcal{A}$ on the input word, the accepting states of $\mathcal{A}$ are only visited <strong>finitely often</strong>.</td></tr></tbody></table><p>Note that the resulting automaton is <strong>nondeterministic</strong>. This is, in general, <strong>unavoidable</strong>.</p><p>This is because there are languages, such as $L&#x3D;(b^*a)^\omega$ where the language itself is recognizable by a deterministic Buchi automaton, while its complement $\Sigma^\omega\setminus L$ can only be recognized by a nondeterministic B√ºchi automaton.</p><blockquote><p>$\textbf{Theorem 4.3. }\textit{For every deterministic B√ºchi automaton }\mathcal{A}\textit{, there exists a B√ºchi automaton }\mathcal{A‚Äô}\newline\textit{ such that }\mathcal{L}(\mathcal{A‚Äô})&#x3D;\Sigma^\omega \setminus\mathcal{L}(\mathcal{A}).$</p></blockquote><h3 id="Explained-in-Human-Language"><a href="#Explained-in-Human-Language" class="headerlink" title="Explained in Human Language"></a>Explained in Human Language</h3><p>$\mathcal{L}(\mathcal{A‚Äô})\subseteq\Sigma^\omega \setminus\mathcal{L}(\mathcal{A}):$</p><p>To prove that ‚ÄúIf $\alpha$ is accepted by $\mathcal{L}(\mathcal{A‚Äô})$, then it is also accepted by the complement of $\mathcal{L}(\mathcal{A})$‚Äù, we can show that every state in $\mathcal{A‚Äô}$ is same as $\mathcal{A}$, but as long as it switched to $\lbrace 1\rbrace$, it stays forever and there is no accepting states of $\mathcal{A}$.</p><p>Therefore, every accepted word in $\mathcal{L}(\mathcal{A‚Äô})$ is also accepted in $\Sigma^\omega \setminus\mathcal{L}(\mathcal{A})$.</p><p>$\mathcal{L}(\mathcal{A‚Äô})\supseteq\Sigma^\omega \setminus\mathcal{L}(\mathcal{A}):$</p><p>To prove that ‚ÄúIf $\alpha$ is accepted by the complement of $\mathcal{L}(\mathcal{A})$, then it is also accepted by $\mathcal{L}(\mathcal{A‚Äô})$‚Äù, we assume there‚Äôs a word $\alpha$ that is not accepted by $\mathcal{L}(\mathcal{A})$.</p><p>Since $\mathcal{A}$ is <strong>complete</strong> and <strong>deterministic</strong>, so the run on $\alpha$ is still infinite, yet <strong>never</strong> visit the accepted states <strong>infinitely often</strong>. i.e. starting from certain position, it will never visit the accepting states anymore.</p><p>We can treat that position as the switch from $\lbrace 0\rbrace$ and $\lbrace 1\rbrace$ in $\mathcal{A‚Äô}$ occurs. And therefore $\alpha$ is an accepted word in $\mathcal{L}(\mathcal{A‚Äô})$.</p><h3 id="Formal-Proof"><a href="#Formal-Proof" class="headerlink" title="Formal Proof"></a>Formal Proof</h3><p>Let $\mathcal{A‚Äô}$ be constructed from the given deterministic B√ºchi automaton $\mathcal{A}$ (which we<br>assume, w.l.o.g., to be complete) by <em>Construction 4.1.</em> We prove that $\mathcal{L}(\mathcal{A‚Äô})&#x3D;\Sigma^\omega \setminus\mathcal{L}(\mathcal{A}).$</p><p>$\mathcal{L}(\mathcal{A‚Äô})\subseteq\Sigma^\omega \setminus\mathcal{L}(\mathcal{A}):$</p><p>For every word $\alpha\in\mathcal{L}(\mathcal{A‚Äô})$ we have an accepting run: $r‚Äô:(q_0,0)(q_1,0)\dots(q_j,0)(q‚Äô_0,1)(q_1,1)\dots$ on $\mathcal{A}$. Hence, $r:q_0q_1\dots q_jq_0‚Äôq_1‚Äô\dots$ is the unique run of $\mathcal{A}$ on $\alpha$. Since $q_0‚Äô,q_1‚Äô,\dots\in Q\setminus F$, we have that $\text{Inf}(r)\subseteq Q\setminus F$. Hence, $r$ is not accepting and $\alpha\in\Sigma^\omega\setminus\mathcal{L}(\mathcal{A})$.</p><p>$\mathcal{L}(\mathcal{A‚Äô})\supseteq\Sigma^\omega \setminus\mathcal{L}(\mathcal{A}):$</p><p>Let $\alpha\notin\mathcal{L}(\mathcal{A‚Äô})$ be some word that is not in the language of $\mathcal{A}$. Since $\mathcal{A}$ is complete and deterministic, there exists a unique run $r:q_0q_1q_2\dots$ of $\mathcal{A}$ on $\alpha$ and  $\text{Inf}(r)\cap F&#x3D;\varnothing$. Thus, there exists a $k\in\mathbb{N}$ such that $q_j\notin F$ for all $j &gt; k$.</p><p>This gives us the run: $r‚Äô:(q_0,0)(q_1,0)\dots(q_j,0)(q‚Äô_0,1)(q_1,1)\dots$ of $\mathcal{A‚Äô}$ on $\alpha$ with $\text{Inf}(r)\subseteq ((Q\setminus F)\times\lbrace 1\rbrace)&#x3D;F‚Äô$. Hence, $r‚Äô$ is accepting and therefore $\alpha\in\mathcal{L}(\mathcal{A‚Äô})$.</p><h3 id="Example-mathcal-L-mathcal-A-b-ast-a-omega-and-mathcal-L-mathcal-A‚Äô-a-b-ast-b-omega"><a href="#Example-mathcal-L-mathcal-A-b-ast-a-omega-and-mathcal-L-mathcal-A‚Äô-a-b-ast-b-omega" class="headerlink" title="Example: $\mathcal{L}(\mathcal{A})&#x3D;(b^\ast a)^\omega$ and $\mathcal{L}(\mathcal{A‚Äô})&#x3D;(a+b)^\ast b^\omega$"></a>Example: $\mathcal{L}(\mathcal{A})&#x3D;(b^\ast a)^\omega$ and $\mathcal{L}(\mathcal{A‚Äô})&#x3D;(a+b)^\ast b^\omega$</h3><p><img src="/../images/notes/uds/agv/4_2_eg.png"></p><p>Note that, since not all $\omega$-regular languages can be recognized by deterministic B√ºchi automata, Construction 4.1 does not provide us with a complementation construction for all $\omega$-regular languages. Such a general construction is the subject of the following section.</p><hr><p>Next chapter: <a href="../agv5-1/">Infinite Directed Acyclic Graph (DAG)</a></p><p>Further Reading: <a href=""></a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 4.1 -- Deterministic vs. Nondeterministic B√ºchi Automata</title>
      <link href="/AGV/agv4-1/"/>
      <url>/AGV/agv4-1/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv3-5/">B√ºchi‚Äôs Characterization Theorem</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In the theory of automata over finite words, we have <a href="https://en.wikipedia.org/wiki/Powerset_construction">Rabin-Scott powerset construction</a>, which converts a <em>nondeterministic automaton</em> over finite words into a <em>deterministic automaton</em> that <strong>recognizes the same language</strong>. This shows that nondeterminism does not make automata over finite words more expressive (but makes it more concise as the construction produces an exponential number of states).</p><p>The situation is different for B√ºchi automata: even though the language $L &#x3D; (a+b)^*b^\omega$ is clearly <em>B√ºchi-recognizable</em>, there is, as the following theorem shows, <strong>no deterministic B√ºchi automaton that recognizes L</strong>.</p><h2 id="Deterministic-vs-nondeterministic-Buchi-automata"><a href="#Deterministic-vs-nondeterministic-Buchi-automata" class="headerlink" title="Deterministic vs. nondeterministic B√ºchi automata"></a>Deterministic vs. nondeterministic B√ºchi automata</h2><blockquote><p>$\textbf{Theorem 4.1. }\textit{Language $L&#x3D;(a+b)^*b^\omega$ is not recognizable by deterministic B√ºchi Automata}$</p></blockquote><p>Starting a base case $b^\omega$, we add $(a+b)$ as the prefix one by one. Can we express the  <strong>kleene star</strong>?<br>That is, is the automaton only accept <strong>finitely many</strong> $(a+b)$?</p><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>Assume, by way of contradiction, that $L$ is recognizable by the deterministic B√ºchi automaton $\mathcal{A}&#x3D;(\Sigma,Q,I,T,\small\text{B√úCHI}\normalsize(F))$. Since $\alpha_0&#x3D;b^\omega$ is in $L$, there is an unique run</p><p>$$r_0&#x3D;r_0(0)r_0(1)r_0(2)\dots$$</p><p>of $\mathcal{A}$ on $\alpha_0$ with $r_0(n_0)\in F$ for some $n_0\in\mathbb{N}$. Similarly, $\alpha_1&#x3D;b^{n_0}ab^\omega$ in $L$ and there is a unique run</p><p>$$r_1&#x3D;r_0(0)r_0(1)r_0(2)\dots r_0(n_0)r_1(n_0+1)r_1(n_0+2)\dots$$</p><p>of $\mathcal{A}$ on $\alpha_1$ with $r_1(n_1)\in F$ for some $n_1&gt;n_0$. Since $\mathcal{A}$ is deterministic, $r_0$ &amp; $r_1$ are identical up to position $n_0$.</p><p>By repeating this argument infinitely often, we obtain a word $\alpha&#x3D;b^{n_0}ab^{n_1}ab^{n_2}a\dots$ and a run $r$ with infinitely many visits to $F$. Hence, $\alpha$ is accepted by $\mathcal{A}$. However, $\alpha$ is not an element of $L$. This contradicts $L &#x3D; \mathcal{L}(\mathcal{A})$.</p><h2 id="Limit-Operator"><a href="#Limit-Operator" class="headerlink" title="Limit Operator"></a>Limit Operator</h2><p>We start by defining a <em>Limit Operator</em> to generate $\omega$-language using regular language. For the regular language $W$, $\overrightarrow{W}$ contains all the words that they all contain words in $W$ as substrings.</p><blockquote><p>$\textbf{Definition 4.1. }\text{(Limit). The}\textit{ limit }\overrightarrow{W}\text{ of a language }W\subseteq\Sigma^* \text{ over finite words}\newline\text{is the following language over infinite words:}$ $$\overrightarrow{W}&#x3D;\lbrace\alpha\in\Sigma^\omega\mid\text{there exist infinitely many }n\in\mathbb{N}\text{ s.t. }\alpha[0,n]\in W\rbrace.$$</p></blockquote><p>And From regular language, now we can define an $\omega$-regular language that is recognizable by deterministic B√ºchi Automata:</p><blockquote><p>$\textbf{Theorem 4.2. }\textit{An }\omega\textit{-language }L\subseteq\Sigma^\omega\textit{ is recognizable by a deterministic B√ºchi Automata}\newline\textit{iff there is a regular langauge }W\subseteq\Sigma^*\textit{ s.t. }L&#x3D;\overrightarrow{W}.$</p></blockquote><h3 id="Explained-in-Human-language"><a href="#Explained-in-Human-language" class="headerlink" title="Explained in Human language"></a>Explained in Human language</h3><p>Basically, we are trying to prove $\mathcal{L}(\mathcal{A_B})&#x3D;\overrightarrow{\mathcal{L}(\mathcal{A_F})}$, where $\mathcal{L}(\mathcal{A_B})$ is a deterministic B√ºchi Automata and $\mathcal{L}(\mathcal{A_F})$ is a a deterministic automaton over finite words.</p><p>As we can see, an accepted word $\alpha\in\mathcal{L}(\mathcal{A_B})$ with have substring $\alpha[0,n]$ that is accepted by $\mathcal{L}(\mathcal{A_F})$ with infinitely many $n\in\mathbb{N}$, by the definition of the <em>limit operator</em>.</p><p>We can prove regular language $W$ exists if $\alpha$ exists using $\overrightarrow{W}$. Automata that accepts $W$ and $\overrightarrow{W}$ should exist, namely $\mathcal{L}(\mathcal{A_F})$ and $\overrightarrow{\mathcal{L}(\mathcal{A_F})}$ respectively.</p><h3 id="Formal-Proof"><a href="#Formal-Proof" class="headerlink" title="Formal Proof"></a>Formal Proof</h3><p>We claim that the languages of a deterministic B√ºchi automaton $\mathcal{A}_B$ and of a deterministic<br>automaton over finite words $\mathcal{A}_F$, where the automata $\mathcal{A}_B&#x3D;(\Sigma,Q,I,T,\small\text{B√úCHI}\normalsize(F))$ and $\mathcal{A}_F&#x3D;(\Sigma,Q,I,T,F)$, constructed from the same components, are related as follows:</p><p>$$\mathcal{L}(\mathcal{A_B})&#x3D;\overrightarrow{\mathcal{L}(\mathcal{A_F})}.$$</p><p>Since every regular language is recognized by a deterministic automaton over finite words,<br>the theorem follows. To prove the claim, we consider an infinite word $\alpha\in\Sigma^\omega$.</p><p>$\hspace{1cm}\alpha\in\mathcal{L}(\mathcal{A_B})\newline<br>\text{iff} \hspace{0.5cm}\text{for the unique run $r$ of $\mathcal{A_B}$ on $\alpha$, Inf($r$) $\cap$ $F\neq\varnothing$}\newline \text{iff} \hspace{0.5cm} \alpha[0,n]\in\mathcal{L}(\mathcal{A_F})\text{ for infinitely many }n\in\mathbb{N}\newline<br>\text{iff} \hspace{0.5cm} \alpha\in\mathcal{L}(\mathcal{A_F})$</p><hr><p>Next chapter: <a href="../agv4-2/">Complementation of deterministic B√ºchi Automata</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/Powerset_construction">powerset construction</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 3.5 -- B√ºchi&#39;s Characterization Theorem</title>
      <link href="/AGV/agv3-5/"/>
      <url>/AGV/agv3-5/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv3-4/">Closure Properties of the B√ºchi-recognizable languages (Concatenations)</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><p>We are now ready to prove B√ºchi‚Äôs Characterization Theorem, a result from 1962.</p><blockquote><p>$\textbf{Theorem 3.6. }\text{(B√ºchi‚Äôs Characterization Theorem) }\newline\textit{An $\omega$-language is B√ºchi-recognizable iff it is $\omega$-regular.}$</p></blockquote><h3 id="Explained-in-Human-language"><a href="#Explained-in-Human-language" class="headerlink" title="Explained in Human language"></a>Explained in Human language</h3><blockquote><p>p.s. B√ºchi-recognizable means the language can be described by a B√ºchi automata.</p></blockquote><p>$‚Äù\Leftarrow‚Äù$<br>We have to prove if the language is <strong>$\omega$-regular</strong>, then it is <strong>B√ºchi-recognizable</strong>.<br>In <a href="../agv3-2/">section 3.2</a>, we learn that an $\omega$-regular language contains 3 operators:</p><ul><li><strong>union</strong> of $\omega$-regular languages, $W_1+W_2$ (proved by Theorem <a href="../agv3-3/">3.2</a>),</li><li><strong>infinite concatenation</strong> of a <strong>non-empty</strong> regular language $E^\omega$ (proved by Theorem <a href="../agv3-4/">3.4</a>), and</li><li><strong>concatenation</strong> of regular languages and $\omega$-regular language $E\cdot W$ (proved by Theorem <a href="../agv3-4/">3.5</a>)</li></ul><p>$‚Äù\Rightarrow‚Äù$<br>We have to prove if the language is <strong>B√ºchi-recognizable</strong>, then it is <strong>$\omega$-regular</strong>.<br>Here, we try to construct a B√ºchi-recognizable using all <strong>$\omega$-regular</strong> operators.</p><p>We begin by constructing a <strong>regular language</strong> $W_{q,q‚Äô}$. <strong>Words</strong> of the language $w$ is accepted by some finite-word automata, with a pair of state $q,q‚Äô\in Q$ being the <strong>initial and accepting states</strong> respectively.</p><p>Then we try to prove that a <strong>B√ºchi-recognizable language</strong> $\mathcal{L}(\mathcal{A})$ equals to the regular language <strong>concatenates</strong> (<a href="../agv3-4/">3.5</a>) with the <strong>infinite concatenated</strong>, <strong>non-empty</strong> (<a href="../agv3-4/">3.4</a>) starting from the previous accepting state. That is $W_{q,q‚Äô}\cdot(W_{q‚Äô,q‚Äô}\setminus\lbrace\varepsilon\rbrace)^\omega$.</p><p>On top of that, we do a set union (<a href="../agv3-3/">3.2</a>) for each pair of <strong>initial and accepting states</strong> $q,q‚Äô\in Q$, that is $\bigcup_{q\in I,q‚Äô\in F}$</p><blockquote><p>Therefore, now we only need to prove that $\mathcal{L}(\mathcal{A})&#x3D;\bigcup_{q\in I,q‚Äô\in F}W_{q,q‚Äô}\cdot(W_{q,q‚Äô}\setminus\lbrace\varepsilon\rbrace)^\omega$.</p></blockquote><p>For the word $\alpha$ from L.H.S, it reaches $q‚Äô\in F$ infinitely often. We can thus seperate into $r:q\xrightarrow{w_0}q‚Äô\xrightarrow{w_1}q‚Äô\xrightarrow{w_2}\dots$<br>The $w$ here refers the word to reach $q‚Äô$. We know that B√ºchi automata is non-empty so $|w_i|&gt;0$ when $i&gt;0$.<br>Therefore, $w_0$ will be a word from $W_{q,q‚Äô}$ and the rest will be words for $(W_{q‚Äô,q‚Äô}\setminus\lbrace\varepsilon\rbrace)^\omega$ because they reach the accepting state $q‚Äô\in F$.</p><p>For the word $w_0w_1w_2\dots$ from R.H.S, where $w_0$ refers to $W_{q,q‚Äô}$ and the rest refers to $(W_{q‚Äô,q‚Äô}\setminus\lbrace\varepsilon\rbrace)^\omega$.<br>This is accepted by $\mathcal{L}(\mathcal{A})$ because it reaches the accepting state $q‚Äô\in F$ infinitely often.</p><h3 id="Formal-Proof"><a href="#Formal-Proof" class="headerlink" title="Formal Proof"></a>Formal Proof</h3><p>$‚Äù\Leftarrow‚Äù$<br>Follows from the closure properties of the B√ºchi-recognizable languages established by Theorems <a href="../agv3-3/">3.2</a>, <a href="../agv3-4/">3.4</a>, <a href="../agv3-4/">3.5</a>.</p><p>$‚Äù\Rightarrow‚Äù$<br>Given a B√ºchi automaton $\mathcal{A}$, we consider for each pair $q,q‚Äô\in Q$ the regular language<br>$$<br>W_{q,q‚Äô} &#x3D; \lbrace w\in\Sigma^*\mid \text{finite-word automaton } (\Sigma,Q,\lbrace q\rbrace,T,{q‚Äô}) \text{ accepts }w\rbrace.<br>$$<br>We claim that $\mathcal{L}(\mathcal{A})&#x3D;\bigcup_{q\in I,q‚Äô\in F}W_{q,q‚Äô}\cdot(W_{q,q‚Äô}\setminus\lbrace\varepsilon\rbrace)^\omega$. The claim is proven as follows.</p><p>$\mathcal{L}(\mathcal{A})\subseteq\bigcup_{q\in I,q‚Äô\in F}W_{q,q‚Äô}\cdot(W_{q,q‚Äô}\setminus\lbrace\varepsilon\rbrace)^\omega$: Let $\alpha\in\mathcal{L}(\mathcal{A})$. Then there is an accpeting run $r$ of $\mathcal{A}$ on $\alpha$, which begins at some $q&#x3D;r(0)\in I$ and visits some $q‚Äô\in F$ infinitely often:</p><p>$$<br>r:q\xrightarrow{w_0}q‚Äô\xrightarrow{w_1}q‚Äô\xrightarrow{w_2}\dots<br>$$</p><p>where $w_i\in\Sigma^*$ for all $i\ge 0$, $|w_i|&gt;0$ for all $i&gt;0$ and $\alpha&#x3D;w_0w_1w_2\dots$ The notation $q_0\xrightarrow{w}q_{k+1}$ for some finite word $w&#x3D;w(0)w(1)\dots w(k)$ means that there exist states $q_1,\dots,q_k\in Q$ s.t. $(q_i,w(i),q_{i+1})\in T$ for all $0\leq i \leq k$. Since $w_0\in W_{q,q‚Äô}$ and $w_k\in W_{q‚Äô,q‚Äô}$ for $k&gt;0$, we have that $\alpha \in W_{q,q‚Äô}\cdot W_{q‚Äô,q‚Äô}^\omega$ for some $q\in I,q‚Äô\in F$.</p><p>$\mathcal{L}(\mathcal{A})\supseteq\bigcup_{q\in I,q‚Äô\in F}W_{q,q‚Äô}\cdot(W_{q,q‚Äô}\setminus\lbrace\varepsilon\rbrace)^\omega$: Let $\alpha&#x3D;w_0w_1w_2\dots$ with $w_0\in W_{q,q‚Äô}$ and $w_k\in W_{q‚Äô,q‚Äô}$ for some $q\in I,q‚Äô\in F$ and for all $k&gt;0$. Then the run:</p><p>$$<br>r:q\xrightarrow{w_0}q‚Äô\xrightarrow{w_1}q‚Äô\xrightarrow{w_2}\dots<br>$$</p><p>exists and is aceepting because $q‚Äô\in F$. It follows that $\alpha\in\mathcal{L}(\mathcal{A})$.</p><hr><p>Next chapter: <a href="../agv4-1/">Deterministic vs. Nondeterministic B√ºchi Automata</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/B%C3%BCchi_automaton">B√ºchi automaton</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 3.4 -- Closure Properties of the B√ºchi-recognizable languages (Concatenations)</title>
      <link href="/AGV/agv3-4/"/>
      <url>/AGV/agv3-4/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv3-3/">Closure Properties of the B√ºchi-recognizable languages (Intersection and Union)</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><p>In this section, we continue the proof of the <strong>closure properties</strong> of the B√ºchi-recognizable languages.</p><h2 id="Concatenation-of-regular-Langauge-and-Buchi-recognizable-Language"><a href="#Concatenation-of-regular-Langauge-and-Buchi-recognizable-Language" class="headerlink" title="Concatenation of regular Langauge and B√ºchi-recognizable Language"></a>Concatenation of regular Langauge and B√ºchi-recognizable Language</h2><blockquote><p>$\textbf{Construction 3.3. } \text{Let }\mathcal{A}_1&#x3D;(\Sigma,Q_1,I_1,T_1,F_1)\text{ be an automaton over finite words that}\newline\text{recognizes the languge }L_1\text{, and let }\mathcal{A}_2 &#x3D; (\Sigma,Q_2,I_2,T_2,\small\text{B√úCHI}\normalsize (F_2))\text{ be a B√ºchi automaton}\newline\text{over the same alphabet that recognizes }L_2.\text{ We construct a B√ºchi autotmaton }\newline\mathcal{A‚Äô}&#x3D;(\Sigma,Q‚Äô,I‚Äô,T‚Äô,\small\text{B√úCHI}\normalsize (F_2))\text{ with }\mathcal{L}(\mathcal{A‚Äô})&#x3D;L_1\cdot L_2\text{ as follows:}$<br>$\begin{array}{lrll}<br>\hspace{1cm} \cdot &amp;Q‚Äô&amp;&#x3D;&amp;Q_1\cup Q_2 \hspace{0.7cm}(\text{w.l.o.g we assume }Q_1\cap Q_2&#x3D;\varnothing)\newline<br>\hspace{1cm} \cdot &amp;I‚Äô&amp;&#x3D;&amp;\biggl\lbrace \begin{array}{ll}I_1 &amp; \ \text{if }I_1\cap F_1&#x3D;\varnothing\newline<br>I_1\cup I_2 &amp; \ \text{otherwise}\end{array} \newline<br>\hspace{1cm} \cdot &amp;T‚Äô&amp;&#x3D;&amp;T_1\cup T_2\cup\lbrace (q,\sigma,q‚Äô)\mid(q,\sigma,f)\in T_1,f\in F_1,q‚Äô\in I_2\rbrace \newline<br>\end{array}$</p></blockquote><table><thead><tr><th align="left">Notation</th><th align="left">Explaination</th></tr></thead><tbody><tr><td align="left">$Q‚Äô$</td><td align="left">Same as Union, we include both automata for concatenation</td></tr><tr><td align="left">$I‚Äô$</td><td align="left">We normaly start the the automaton from $I_1$ If $I_1$ is non-empty, otherwise we start at $I_2$</td></tr><tr><td align="left">$T‚Äô$</td><td align="left">For any states that can reach the accepting states of $T_1$ with one transition, we create a new transitions that reach the initial states of $T_2$ $(I_2)$</td></tr></tbody></table><p>The correctness of this construction is proven by the following theorem.</p><blockquote><p>$\textbf{Theorem 3.4. }\newline\textit{If $L_1$ is a regular language and $L_2$ is B√ºchi-recognizable, then $L_1\cdot L_2$ is B√ºchi-recognizable.}$</p></blockquote><h3 id="Explained-in-Human-language"><a href="#Explained-in-Human-language" class="headerlink" title="Explained in Human language"></a>Explained in Human language</h3><p>If $I_1$ is non-empty, then we can have a run that starts from $I_1$ to $r(n)$, that is one transition before $\mathcal{A_1}$‚Äôs accepting states of $f$. Then for next transition we either move to $f$, or we move on to $\mathcal{A_2}$ starting from $r(n+1)$.</p><p>If $I_1$ is empty, then any word accepted by $\mathcal{A‚Äò}$ is accepted by $\mathcal{A_2}$</p><p>On the other way, we can always construct a word $w\alpha$. If $w$ is accepted by $\mathcal{A_1}$ and $\alpha$ is accepted by $\mathcal{A_2}$, then $w\alpha$ is always accepted by $\mathcal{A‚Äô}$</p><h3 id="Formal-Proof"><a href="#Formal-Proof" class="headerlink" title="Formal Proof"></a>Formal Proof</h3><p>We prove that the B√ºchi automaton $\mathcal{A‚Äô}$ built from the automaton on finite words $\mathcal{A}_1$ and the B√ºchi automaton $\mathcal{A}_2$ indeed recognizes the concatenation of the languages of the two automata.</p><p>$\mathcal{L}(\mathcal{A‚Äô})\subseteq\mathcal{L}(\mathcal{A}_1)\cdot\mathcal{L}(\mathcal{A}_2):$</p><p>For $\alpha\in\mathcal{L}(\mathcal{A‚Äô})$, we have an accepting run $r&#x3D;r(0)r(1)r(2)\dots$ of $\mathcal{A‚Äô}$ on $\alpha$.<br>If $r(0)\in I_1$, then there is an $n\in\mathbb{N}$ such that $(r(n),\alpha(n),r(n+1))\in Q_1\times\Sigma\times I_2$ and therefore, there is a final state $f\in F_1$ such that $r(0)r(1)r(2)\dots r(n)f$ is an accepting run of $\mathcal{A_1}$ on $\alpha(0)\alpha(1)\alpha(2)\dots \alpha(n)$ and $r(n+1)r(n+2)\dots$ is an accepting run of $\mathcal{A_2}$ on $\alpha(n+1)\alpha(n+2)\dots$<br>If $r(0)\in I_2$ then $I_1\cup F_1 \neq\varnothing$ and therefore, $\varepsilon\in\mathcal{L}(\mathcal{A_1}),\alpha\in\mathcal{L}(\mathcal{A_2})$</p><p>$\mathcal{L}(\mathcal{A‚Äô})\supseteq\mathcal{L}(\mathcal{A}_1)\cdot\mathcal{L}(\mathcal{A}_2):$</p><p>For $w\in\mathcal{A_1}$, let $r&#x3D;r(0)r(1)\dots r(n)$ be an accepting run $\mathcal{A_1}$ on $w$.<br>For $\alpha\in\mathcal{A_2}$, let $s&#x3D;s(0)s(1)\dots$ be an accepting run of $\mathcal{A_2}$ on $\alpha$.<br>Then, $r(n)\in F_1$ and, by construction, $r(0)r(1)\dots r(n-1)s(0)s(1)\dots$ is an accepting run of $\mathcal{A‚Äô}$ on $w\alpha$.</p><h2 id="Infinite-concatenation-of-Regular-language"><a href="#Infinite-concatenation-of-Regular-language" class="headerlink" title="Infinite concatenation of Regular language"></a>Infinite concatenation of Regular language</h2><p>Finally, we show that the infinite concatenation of words of a regular language forms a B√ºchi-recognizable language. We construct a B√ºchi automaton for this language from an automaton over finite words in two steps.</p><h3 id="From-automaton-over-finite-words-to-a-single-initial-state"><a href="#From-automaton-over-finite-words-to-a-single-initial-state" class="headerlink" title="From automaton over finite words to a single initial state"></a>From automaton over finite words to a single initial state</h3><p>Firstly, we modify a given automaton over finite words into an equivalent automaton with one <strong>single initial state</strong> that has <strong>no incoming transitions</strong>.</p><p>We do this by create a new fresh state as the new initial state, with all transitions identical as the original. And the original initial state now has no incoming transitions.</p><blockquote><p>$\textbf{Construction 3.4. } \text{Let }\mathcal{A}_1&#x3D;(\Sigma,Q_1,I_1,T_1,F_1)\text{ be an automaton over finite words. We assume}\newline\text{that }\varepsilon\notin\mathcal{L}(\mathcal{A})\text{. We construct an automaton }\mathcal{A‚Äô} &#x3D; (\Sigma,Q‚Äô,I‚Äô,T‚Äô,F)\text{ over finite words such that }\newline\mathcal{L}(\mathcal{A})&#x3D;\mathcal{L}(\mathcal{A‚Äô})\text{ and }\mathcal{A‚Äô}\text{ has a single initial state that has no incoming transitions.}$<br>$\begin{array}{lrll}<br>\hspace{1cm} \cdot &amp;Q‚Äô&amp;&#x3D;&amp;Q_1\cup\lbrace q_f\rbrace \text{where }q_f\text{ is a fresh state}\newline<br>\hspace{1cm} \cdot &amp;I‚Äô&amp;&#x3D;&amp;\lbrace q_f\rbrace\newline<br>\hspace{1cm} \cdot &amp;T‚Äô&amp;&#x3D;&amp;T\cup\lbrace (q_f,\sigma,q‚Äô)\mid(q,\sigma,q‚Äô)\in T \text{ for some }q\in I\rbrace\newline<br>\end{array}$</p></blockquote><p>The second construction builds the B√ºchi automaton that recognizes the infinite concatenations of words from the regular language by <strong>adding a loop</strong> to the modified automaton.</p><blockquote><p>$\textbf{Construction 3.5. } \text{Let }\mathcal{A}\text{ be an automaton over finite words. We assume that }\varepsilon\notin\mathcal{L}(\mathcal{A}).\newline\text{We construct a B√ºchi automaton }\mathcal{A‚Äô‚Äô}&#x3D;(\Sigma,Q‚Äô‚Äô,I‚Äô‚Äô,T‚Äô‚Äô,\small\text{B√úCHI}\normalsize (F‚Äô‚Äô))\text{ such that }\mathcal{L}(\mathcal{A‚Äô‚Äô})&#x3D;\mathcal{L}(\mathcal{A})^\omega.\newline\text{Let }\mathcal{A‚Äô}&#x3D;(\Sigma,Q‚Äô,I‚Äô,T‚Äô,F‚Äô)\text{ be the automaton of Construction 3.4. Then }A‚Äô‚Äô\text{ is defined as follows:}$<br>$\begin{array}{l}<br>\hspace{1cm} \cdot \ Q‚Äô‚Äô&#x3D;Q‚Äô \hspace{1cm} \cdot \ I‚Äô‚Äô&#x3D;I‚Äô \hspace{1cm} \cdot \ F‚Äô‚Äô&#x3D;I‚Äô\newline<br>\hspace{1cm} \cdot \ T‚Äô‚Äô&#x3D;T‚Äô\cup\lbrace (q,\sigma,q_f)\mid(q,\sigma,q‚Äô)\in T‚Äô \text{ and }q‚Äô\in F‚Äô\rbrace\newline<br>\end{array}$</p></blockquote><p>This construction change the final state into the initial state, with adding new transition from final state to initial state. Therefore the automaton becomes a loop.</p><p>The correctness of this construction is proven by the following theorem.</p><blockquote><p>$\textbf{Theorem 3.5. }\textit{If $L$ is a regular language such that $\varepsilon\notin L$, then $L^\omega$ is B√ºchi-recognizable}$</p></blockquote><h3 id="Explained-in-Human-language-1"><a href="#Explained-in-Human-language-1" class="headerlink" title="Explained in Human language"></a>Explained in Human language</h3><p>If there is accepting run for $\mathcal{L}(\mathcal{A‚Äô‚Äô})$, it reaches the accepting state infinitely often.<br>We can split the word in every accepting states and it will be an accepting run for $\mathcal{L}(\mathcal{A‚Äô})$, since the transition to accepting state $F‚Äô‚Äô$ and $F‚Äô$ are identical.</p><p>If there is accepting run(s) for $\mathcal{L}(\mathcal{A‚Äô})$, we can infinitely repeat them so that is also accepted for $\mathcal{L}(\mathcal{A‚Äô‚Äô})$.</p><h3 id="Formal-Proof-1"><a href="#Formal-Proof-1" class="headerlink" title="Formal Proof"></a>Formal Proof</h3><p>Construction 3.4 does not affect the language of $\mathcal{A}$. We show that the B√ºchi automaton $\mathcal{A‚Äô‚Äô}$ built in Construction 3.5 from the resulting automaton $\mathcal{A‚Äô}$ on finite words indeed recognizes $\mathcal{L}(\mathcal{A‚Äô})^\omega$.</p><p>$\mathcal{L}(\mathcal{A‚Äô‚Äô})\subseteq\mathcal{L}(\mathcal{A‚Äô})^\omega:$</p><p>Assume that $\alpha\in\mathcal{L}(\mathcal{A‚Äô‚Äô})$ and that $r(0)r(1)r(2)\dots$ is an accpeting run of $\mathcal{A‚Äô‚Äô}$ on $\alpha$. Hence, we have that $r(i)&#x3D;q_f\in F‚Äô‚Äô&#x3D;I‚Äô$ for inifinitely many indices $i:i_0,i_1,i_2,\dots$. This provides a sequence of runs of $\mathcal{A‚Äô}$:</p><ul><li>run $r(0)r(1)\dots r(i_0-1)q$ on $w_0&#x3D; \alpha(0)\alpha(1)\dots\alpha(i_0-1)$ for some $q\in F‚Äô$</li><li>run $r(i_0)r(i_0+1)\dots r(i_i-1)q$ on $w_1&#x3D; \alpha(i_0)\alpha(i_1)\dots\alpha(i_1-1)$ for some $q\in F‚Äô$</li><li>and so forth.</li></ul><p>We thus have that $w_k\in\mathcal{L}(\mathcal{A‚Äô})$ for every $k\geq 0$. Hence, $\alpha\in\mathcal{L}(\mathcal{A‚Äô})^\omega$.</p><p>$\mathcal{L}(\mathcal{A‚Äô‚Äô})\supseteq\mathcal{L}(\mathcal{A‚Äô})^\omega:$</p><p>Assume that $\alpha &#x3D;w_0w_1w_2\dots\in\Sigma^\omega$ such that $w_k\in\mathcal{L}(\mathcal{A‚Äô})$ for all $k\geq 0$. For each $k$, we choose an accepting run $r_k(0)r_k(1)r_k(2)\dots r_k(n_k)$ of $\mathcal{A‚Äô}$ on $w_k$. Hence, $r_k(0)\in I‚Äô$ and $r_k(n_k)\in F‚Äô$ for all $k&gt;1$. Thus,</p><p>$$r_0(0)\dots r_0(n_0-1)r_1(0)\dots r_1(n_1-1)r_2(0)\dots r_2(n_2-1)\dots$$</p><p>is an accepting run of $\mathcal{A‚Äô‚Äô}$ on $\alpha$. Hence, $\alpha\in\mathcal{L}(\mathcal{A‚Äô‚Äô})$.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Now we proved the closure property holds for <strong>Union</strong> $(W_1\cup W_2)$, <strong>Intersection</strong> $(W_1\cap W_2)$, <strong>Concatenation of regular Langauge and B√ºchi-recognizable Language</strong> $(E+W)$, and <strong>Infinite concatenation of Regular language</strong> $(E^\omega)$.</p><p>In the next section we can start to prove <strong>B√ºchi‚Äôs Characterization Theorem</strong>.</p><hr><p>Next chapter: <a href="../agv3-5/">B√ºchi‚Äôs Characterization Theorem</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/Closure_(mathematics)">Closure (mathematics)</a>, <a href="https://en.wikipedia.org/wiki/Concatenation">Concatenation</a>, <a href="https://en.wikipedia.org/wiki/Absolute_infinite">Absolute infinite</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 3.3 -- Closure Properties of the B√ºchi-recognizable languages (Intersection and Union)</title>
      <link href="/AGV/agv3-3/"/>
      <url>/AGV/agv3-3/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv3-2/">$\omega$-regular language</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><p>In the following we refer the languages recognized by B√ºchi automata simply as <strong>B√ºchi-recognizable languages</strong>. <strong>B√ºchi‚Äôs characterization theorem</strong> states that the $\omega$-regular languages are exactly <strong>B√ºchi-recognizable languages</strong>. To prepare for the proof of B√ºchi‚Äôs theorem, we establish several <strong>closure properties</strong> of the B√ºchi-recognizable languages.</p><h2 id="Closure-Properties-of-Language-Union"><a href="#Closure-Properties-of-Language-Union" class="headerlink" title="Closure Properties of Language Union"></a>Closure Properties of Language Union</h2><blockquote><p>$\textbf{Construction 3.1. } \text{Let }L_1\text{ and }L_2\text{ be }\omega\text{-languages recognized by the B√ºchi automata}\newline\mathcal{A}_1&#x3D;(\Sigma,Q_1,I_1,T_1,\small\text{B√úCHI}\normalsize (F_1))\text{ and }\mathcal{A}_2 &#x3D; (\Sigma,Q_2,I_2,T_2,\small\text{B√úCHI}\normalsize (F_2))\text{, respectively.}\newline\text{We construct}\mathcal{A}_\cup&#x3D;(\Sigma,Q_\cup,I_\cup,T_\cup,\small\text{B√úCHI}\normalsize (F_\cup))\text{ with }\mathcal{L}(\mathcal{A}_\cup)&#x3D;L_1\cup L_2\text{ as follows:}$<br>$\begin{array}{l}<br>\hspace{1cm} \cdot \ Q_\cup&#x3D;Q_1\cup Q_2 \hspace{1cm}(\text{w.l.o.g we assume }Q_1\cap Q_2&#x3D;\varnothing)\newline<br>\hspace{1cm} \cdot \ I_\cup&#x3D;I_1\cup I_2 \ \hspace{1cm} \cdot \ T_\cup&#x3D;T_1\cup T_2 \ \hspace{1cm} \cdot \ F_\cup&#x3D;F_1\cup F_2 \newline<br>\end{array}$</p></blockquote><p>The correctness of this construction is proven by the following theorem.</p><blockquote><p>$\textbf{Theorem 3.2. } \textit{If $L_1$ and $L_2$ are B√ºchi-recognizable, then so is $L_1\cup L_2$.}$</p></blockquote><h3 id="Formal-Proof"><a href="#Formal-Proof" class="headerlink" title="Formal Proof"></a>Formal Proof</h3><p>We prove that the B√ºchi automaton $\mathcal{A}_\cup$ built by $\mathcal{A}_1$ and $\mathcal{A}_2$ indeed recognizes the union of the languages of the two automata.</p><p>$\mathcal{L}(\mathcal{A}_\cup)\subseteq\mathcal{L}(\mathcal{A}_1)\cup\mathcal{L}(\mathcal{A}_2):$</p><p>For $\alpha\in\mathcal{L}(\mathcal{A}_\cup)$, we have an accepting run $r&#x3D;r(0)r(1)r(2)\dots$ of $\mathcal{A}_\cup$ on $\alpha$.<br>If $r(0)\in I_1$, then $r$ is an accepting run of $\mathcal{A}_1$, otherwise $r(0)\in I_2$ and $r$ is an accepting run of $\mathcal{A}_2$.</p><p>$\mathcal{L}(\mathcal{A}_\cup)\supseteq\mathcal{L}(\mathcal{A}_1)\cup\mathcal{L}(\mathcal{A}_2):$</p><p>For $i\in\lbrace 1,2\rbrace$ and $\alpha\in\mathcal{L}(\mathcal{A}_i)$, there is an accepting run $r$ of $\mathcal{A}_i$. The run $r$ is also an accepting run of $\mathcal{A}_\cup$.</p><h2 id="Closure-Properties-of-Language-Intersection"><a href="#Closure-Properties-of-Language-Intersection" class="headerlink" title="Closure Properties of Language Intersection"></a>Closure Properties of Language Intersection</h2><p>As we will see later, the B√ºchi-recognizable languages are closed under <code>complement</code>.<br>The closure under <code>complement</code> and <code>union</code> implies the closure under <code>intersection</code> $(\mathcal{A}_\cap &#x3D; (\mathcal{A‚Äô_1}\cup \mathcal{A‚Äô_2})‚Äô)$</p><p>Below, the automaton for the intersection is essentially the product of the two automata.</p><blockquote><p>$\textbf{Construction 3.2. } \text{Let }L_1\text{ and }L_2\text{ be }\omega\text{-languages recognized by the B√ºchi automata}\newline\mathcal{A}_1&#x3D;(\Sigma,Q_1,I_1,T_1,\small\text{B√úCHI}\normalsize(F_1))\text{ and }\mathcal{A}_2 &#x3D; (\Sigma,Q_2,I_2,T_2,\small\text{B√úCHI}\normalsize (F_2))\text{, respectively.}\newline\text{We construct}\mathcal{A}_\cap&#x3D;(\Sigma,Q_\cap,I_\cap,T_\cap,\small\text{B√úCHI}\normalsize (F_\cap))\text{ with }\mathcal{L}(\mathcal{A}_\cap)&#x3D;L_1\cap L_2\text{ as follows:}$<br>$\begin{array}{rll}<br>\hspace{1cm} \cdot \ Q_\cap&amp;&#x3D;&amp;Q_1\times Q_2\times\lbrace 1,2\rbrace\newline<br>\hspace{1cm} \cdot \ I_\cap&amp;&#x3D;&amp;I_1\times I_2\times\lbrace 1\rbrace\newline<br>\hspace{1cm} \cdot \ T_\cap&amp;&#x3D;&amp;\lbrace (q_1,q_2,i),\sigma ,(q‚Äô_1,q‚Äô_2,j)\mid (q_1,\sigma,q‚Äô_1)\in T_1,(q_2,\sigma,q‚Äô_2)\in T_2,i,j\in\lbrace 1,2\rbrace,\newline<br>\hspace{1cm} \ &amp;&amp;\hspace{5.3cm}q_i \notin F_i\rightarrow i&#x3D;j \wedge q_i\in F_i\wedge i\neq j\rbrace\newline<br>\hspace{1cm} \cdot \ F_\cap&amp;&#x3D;&amp;\lbrace (q_1,q_2,2)\mid q_1\in F_1, q_2\in F_2\rbrace\newline<br>\end{array}$</p></blockquote><table><thead><tr><th align="left"></th><th align="left">Explaination</th></tr></thead><tbody><tr><td align="left">$Q_\cap$</td><td align="left">States in the new automaton is <strong>tuples</strong> that contain the states of two automata plus the third component that used to <strong>combine acceptance conditions</strong>, e.g. $(q_1,q_2,1)$ is a state.</td></tr><tr><td align="left">$I_\cap$</td><td align="left">New automaton is constructed with only <strong>one initial state</strong>, so we assign the value to the acceptance condition <code>&#123;1&#125;</code> for simplicity</td></tr><tr><td align="left">$T_\cap$</td><td align="left">The switch from $\lbrace 0\rbrace$ and $\lbrace 1\rbrace$ happens nondeterministically. And once you enter the second copy $\lbrace 1\rbrace$, it stays forever.</td></tr><tr><td align="left">$F_\cap$</td><td align="left">For each transition, it has to be possible by both automata and if such transition reach the one of the automata‚Äôs accepting state, the acceptance condition changed. This creates an alternation between the accepting state of the 1st and 2nd automaton.</td></tr></tbody></table><p>Since we start our acceptance condition as <code>&#123;1&#125;</code>, our accepting states of the new automaton will be the <strong>accepting states of the 2nd automaton when acceptance condition becomes <code>&#123;2&#125;</code></strong>. i.e. Whenever the run reach to the accepting states of the 2nd automaton, it always has to first reach the accepting states of the 1st automaton.</p><blockquote><p>$\textbf{Theorem 3.3. } \textit{If $L_1$ and $L_2$ are B√ºchi-recognizable, then so is $L_1\cap L_2$.}$</p></blockquote><h3 id="Formal-Proof-1"><a href="#Formal-Proof-1" class="headerlink" title="Formal Proof"></a>Formal Proof</h3><p>The run $r‚Äô$ is accepting iff $r_1$ is accepting and $r_2$ is accepting.</p><p>i.e. $r‚Äô&#x3D;(q_1^0,q_2^0,t^0)(q_1^1,q_2^1,t^1)\dots$ is a run of $\mathcal{A}_\cap$ on an input word $\alpha$,<br>iff $r_1 &#x3D; q^0_1 q^1_1\dots$ is a run of $\mathcal{A}_1$ on $\alpha$ and $r_1 &#x3D; q^0_2 q^1_2\dots$ is a run of $\mathcal{A}_2$ on $\alpha$</p><p>Therefore, an accepting run will be: <strong>(1)</strong> go to states with <code>&#123;1&#125;</code> ‚Üí <strong>(2)</strong> reach accepting state of 1st automaton ‚Üí <strong>(3)</strong> go to states with <code>&#123;2&#125;</code> ‚Üí <strong>(4)</strong> reach accepting state of 2nd automaton ‚Üí goes back to <strong>(1)</strong>‚Ä¶</p><hr><p>Next chapter: <a href="../agv3-4/">Closure Properties of the B√ºchi-recognizable languages (Concatenations)</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/Closure_(mathematics)">Closure (mathematics)</a>, <a href="https://en.wikipedia.org/wiki/Intersection_(set_theory)">Intersection (set theory)</a>, <a href="https://en.wikipedia.org/wiki/Union_(set_theory)">Union (set theory)</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 3.2 -- $&#92;omega$-regular language</title>
      <link href="/AGV/agv3-2/"/>
      <url>/AGV/agv3-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv/">Kleene‚Äôs Theorem</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><em>$\omega$-regular expression</em> denotes languages over <strong>infinite</strong> words.<br>In addition to language union on languages over infinite words, we have 2 operations that convert languages over finite words into languages over infinite words.</p><h2 id="omega-regular-expression"><a href="#omega-regular-expression" class="headerlink" title="$\omega$-regular expression"></a>$\omega$-regular expression</h2><p>The collection of $\omega$-regular languages over an alphabet $\Sigma^\omega$ is $\mathcal{L}(W)$, where $W$ is a $\omega$-regular expression.<br>$\omega$-regular expression can be defined as $W :&#x3D; E^\omega \mid E\cdot W\mid W_1+W_2 $, where:</p><ul><li><strong>infinite concatenation</strong> of a <strong>non-empty</strong> regular language $E^\omega$,</li><li><strong>union</strong> of $\omega$-regular languages, $W_1+W_2$, and</li><li><strong>concatenation</strong> of regular languages and $\omega$-regular language $E\cdot W$</li></ul><blockquote><p>$\textbf{Definition 3.3. } \textit{$\omega$-Regular expressions } \text{are defined as follows:}$<br>$\begin{array}{l}<br>\hspace{1cm} \cdot \ \text{If $E$ is a regular expression where $\varepsilon\notin\mathcal{L}(E)$, then $E^\omega$ is an $\omega$-regular expression.}\newline<br>\hspace{1cm} \ \ \mathcal{L}(E^\omega) &#x3D; \mathcal{L}(E)^\omega\newline<br>\hspace{1cm} \ \ \text{where } L^\omega &#x3D;\lbrace \omega_0\omega_1\dots\mid\omega_i\in L,|\omega_i|&gt;0\rbrace \text{ for } L\subseteq\Sigma^* \newline<br>\hspace{1cm} \cdot \ \text{If $E$ is a regular expression and $W$ is an $\omega$-regular expression,}\newline<br>\hspace{1cm} \ \ \text{then $E\cdot W$ is an $\omega$-regular expression:}\newline<br>\hspace{1cm} \ \ \mathcal{L}(E\cdot W) &#x3D; \mathcal{L}(E)\cdot\mathcal{L}(W)\newline<br>\hspace{1cm} \ \ \text{where } L_1 \cdot L_2&#x3D;\lbrace \omega\alpha\mid\omega\in L_1,\alpha\in L_2\rbrace \text{ for } L_1 \subseteq\Sigma^*, L_2 \subseteq\Sigma^\omega\newline<br>\hspace{1cm} \cdot \ \text{If $W_1$ and $W_2$ are $\omega$-regular expressions, then $W_1+W_2$ is an $\omega$-regular expression:}\newline<br>\hspace{1cm} \ \ \mathcal{L}(W_1+W_2) &#x3D; \mathcal{L}(W_1)\cup\mathcal{L}(W_2) .\newline<br>\end{array}$</p></blockquote><p>A language over infinite words is $\omega$-regular if it is definable by a $\omega$-regular expression.</p><hr><p>Next chapter: <a href="../agv3-3/">Closure Properties of the B√ºchi-recognizable languages (Intersection and Union)</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/Omega_language">Omega language</a>, <a href="https://en.wikipedia.org/wiki/Omega-regular_language">Omega Regular language</a>, <a href="https://en.wikipedia.org/wiki/B%C3%BCchi_automaton">B√ºchi automaton</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 3.1 -- Kleene&#39;s Theorem</title>
      <link href="/AGV/agv3-1/"/>
      <url>/AGV/agv3-1/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv2-3/">The B√ºchi Acceptance Condition</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><em>Kleene‚Äôs theorem</em> states that the <em>set of languages over finite words</em> that can be defined by <strong>regular expressions</strong> is exactly the set of languages that can be recognized by <strong>automata over finite words</strong>.</p><p>Based on this, we define $\omega$-regular expressions, and finally prove the corresponding theorem for $\omega$-regular languages: <strong>B√ºchi‚Äôs characterization theorem</strong>.</p><h2 id="Regular-Expression"><a href="#Regular-Expression" class="headerlink" title="Regular Expression"></a>Regular Expression</h2><p>Regular expression consist of <strong>constants</strong> that denote languages of <em>finite words</em>, and<br>consist of <strong>operator symbols</strong> that denote <em>operations over these languages</em>.</p><p>The collection of regular languages over an alphabet $\Sigma$ is $\mathcal{L}(E)$, where $E$ is a regular expression.<br>Regular expression can be defined as $E :&#x3D; \varepsilon\mid\varnothing\mid a\in\Sigma\mid E+F\mid E\cdot F\mid E^* $, where:</p><ul><li><strong>empty language</strong>: $\varepsilon$,</li><li><strong>empty string language</strong>: $\varnothing$,</li><li><strong>singleton language</strong>: (single letter from alphabet) $a\in\Sigma$,</li><li><strong>union</strong> of regular languages: $E+F$,</li><li><strong>concatenation</strong> of regular languages: $E\cdot F$, and</li><li>language with <strong>kleene star</strong>: $E^*$.</li></ul><blockquote><p>$\textbf{Definition 3.1. } \textit{Regular expressions } \text{are defined as follows:}$<br>$\begin{array}{l}\hspace{1cm} \cdot \ \text{The constants }\varepsilon\text{ and }\varnothing\text{ are regular expressions.}\newline<br>\hspace{1cm} \ \ \mathcal{L}(\varepsilon) &#x3D; \lbrace\varepsilon\rbrace ,\mathcal{L}(\varnothing)&#x3D;\varnothing.\newline<br>\hspace{1cm} \cdot \ \text{If }a\in\Sigma\text{ is a symbol, then }a\text{ is a regular expressions.}\newline<br>\hspace{1cm} \ \ \mathcal{L}(a) &#x3D; \lbrace a\rbrace .\newline<br>\hspace{1cm} \cdot \ \text{If }E\text{ and }F\text{ are regular expressions, then }E+F\text{ is a regular expression:}\newline<br>\hspace{1cm} \ \ \mathcal{L}(E+F) &#x3D; \mathcal{L}(E)\cup\mathcal{L}(F) .\newline<br>\hspace{1cm} \cdot \ \text{If }E\text{ and }F\text{ are regular expressions, then }E\cdot F\text{ is a regular expression:}\newline<br>\hspace{1cm} \ \ \mathcal{L}(E\cdot F) &#x3D; \lbrace uv\mid u\in\mathcal{L}(E),v\in\mathcal{L}(F)\rbrace.\newline<br>\hspace{1cm} \cdot \ \text{If }E\text{ is a regular expression, then }E^*\text{ is a regular expression.}\newline<br>\hspace{1cm} \ \ \mathcal{L}(E^{\ast}) &#x3D; \lbrace u_1u_2\dots u_n\mid n\in\mathbb{N},u_i\in\mathcal{L}(E)\text{ for all }0\leq i\leq n\rbrace.\end{array}$</p></blockquote><h2 id="Kleene‚Äôs-Theorem"><a href="#Kleene‚Äôs-Theorem" class="headerlink" title="Kleene‚Äôs Theorem"></a>Kleene‚Äôs Theorem</h2><p><em>A language over finite words</em> is <strong>regular</strong> if it is definable by a <em>regular expression</em>, or<br>if it is recognized by <em>automata over finite words</em>.</p><blockquote><p>$\textbf{Definition 3.2. } \text{An }\textit{automaton on finite words } \mathcal{A}\text{ is a tuple } (\Sigma,Q,I,T,F), \text{ where }\Sigma\text{ is an input} \newline \text{alphabet, }Q\text{ is a nonempty finite set of states, }I\in Q\text{ is a set of initial states, }\Delta\subseteq Q\times\Sigma\times Q\text{ is}\newline\text{a set of transitions, and }F\subseteq Q\text{ are a set of finite states.}$</p></blockquote><h3 id="Mathematical-Definition"><a href="#Mathematical-Definition" class="headerlink" title="Mathematical Definition"></a>Mathematical Definition</h3><p>An automaton $\mathcal{A}$ accepts a finite word $w \in\Sigma^*$ if there is a finite sequence of states $q(0)q(1) . . . q(|w|)$ such that $q(0)\in I$ and $(q(i),w(i), q(i + 1))\in\Delta$ for all $i &lt; |w|$ and with $q(|w|)\in F$</p><h3 id="Explained-in-Human-language"><a href="#Explained-in-Human-language" class="headerlink" title="Explained in Human language"></a>Explained in Human language</h3><p>In a nutshell, a finite word $w$ is <strong>accepted</strong> by an automaton $\mathcal{A} &#x3D; (\Sigma,Q,I,T,F)$ if:</p><table><thead><tr><th align="left">Notation</th><th align="left">Explaination</th></tr></thead><tbody><tr><td align="left">$\Sigma$</td><td align="left">$w$ is a finite word in $\Sigma$</td></tr><tr><td align="left">$Q$</td><td align="left">There exists a finite sequence of states $q(0)q(1) . . . q(|w|)$</td></tr><tr><td align="left">$I$</td><td align="left">In such sequence, $q(0)$ is one of the initial state $I$</td></tr><tr><td align="left">$T$</td><td align="left">In such sequence, there is transition from $q(i)$ to $q(i+1)$ for each letter $w(i)$, where $i&lt;|w|$</td></tr><tr><td align="left">$F$</td><td align="left">In such sequence, $q(|w|)$ is one of the final state $F$, and it will be the last state of the run since there is no more letters</td></tr></tbody></table><h3 id="From-accepted-word-to-accepted-language"><a href="#From-accepted-word-to-accepted-language" class="headerlink" title="From accepted word to accepted language"></a>From accepted word to accepted language</h3><p>The set of all words accepted by $\mathcal{A}$ is called the <strong>language</strong> of $\mathcal{A}$, denoted by $\mathcal{L}(\mathcal{A})$.</p><blockquote><p>$\textbf{Theorem 3.1. } \text{(Kleene‚Äôs Theorem)}\newline\textit{A language is regular iff it is recognized by some finite word automaton.}$</p></blockquote><hr><p>Next post: <a href="../agv3-2/">$\omega$-regular language</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/Regular_expression">Regular expression</a>,<a href="https://en.wikipedia.org/wiki/Regular_language">Regular language</a> <a href="https://en.wikipedia.org/wiki/Kleene_star#:~:text=The%20Kleene%20star%20is%20defined,x%E2%8B%85y%20%E2%88%88%20S*.">Kleene star</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 2.3 -- The B√ºchi Acceptance Condition</title>
      <link href="/AGV/agv2-3/"/>
      <url>/AGV/agv2-3/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv2-2/">Automata over Infinite Words</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="2-3-The-Buchi-Acceptance-Condition"><a href="#2-3-The-Buchi-Acceptance-Condition" class="headerlink" title="2.3 The B√ºchi Acceptance Condition"></a>2.3 The B√ºchi Acceptance Condition</h2><p>The B√ºchi Acceptance Condition is given as a set of <strong>accepting states</strong> $F$.<br>A run of a B√ºchi automaton is accepting if <strong>some state from this set occurs infinitely often</strong>.</p><p><a name="inf"></a></p><h3 id="Infinite-word"><a href="#Infinite-word" class="headerlink" title="Infinite word"></a>Infinite word</h3><p>For an infinite word $\alpha$ over $\Sigma$, an <strong>Infinity Set</strong> of $\alpha$ is denoted as:<br>$$\text{Inf}(\alpha) &#x3D; \lbrace\sigma\in\Sigma\mid\forall m\in\mathbb{N}.\exists n\in\mathbb{N}.n\geq m \text{ and } \alpha(n)&#x3D;\sigma\rbrace$$</p><p>Meaning that $\text{Inf}(\alpha)$ is a set of all letters $\sigma$ from the alphabet $\Sigma$, so that<br>for all $m$, you can always find $\sigma$ as the n-th letter of $\alpha$ when there exists an $n$ where $n\geq m$.</p><p>This denotes the set of all letters of $\Sigma$ that occur <strong>infinitely often</strong> in $\alpha$.</p><h3 id="Buchi-Condition"><a href="#Buchi-Condition" class="headerlink" title="B√ºchi Condition"></a>B√ºchi Condition</h3><p>To express the meaning of ‚Äúsome state from the set of <em>accepting states</em> is reached <strong>infinitely often</strong>‚Äú, we can rewrite our accpeing condition $Acc$ into B√ºchi Condition $\small\text{B√úCHI} \normalsize(F)$. Here, $\small\text{B√úCHI} \normalsize(F)$ is a set of <em>infinite word</em>:</p><blockquote><p>$\textbf{Definition 2.4. } \text{ The } \textit{B√ºchi Condition } \small\text{B√úCHI} \normalsize(F)\text{ on a set of states }F\subseteq Q\text{ is the set}$</p><p>$$\small\text{B√úCHI} \normalsize(F) &#x3D; \lbrace\alpha\in Q^\omega \mid \text{Inf}(\alpha) \cap F \neq \varnothing\rbrace$$</p><p>$\text{An automaton }\mathcal{A}&#x3D;(\Sigma,Q,I,T,Acc)\text{ with }Acc&#x3D;\small\text{B√úCHI} \normalsize(F)\text{ is called a }\textit{B√ºchi automaton.}\newline \text{The set }F\text{ is called the }\textit{set of accepting states.}$</p></blockquote><h2 id="Constrcution-of-Complete-Buchi-Automaton"><a href="#Constrcution-of-Complete-Buchi-Automaton" class="headerlink" title="Constrcution of Complete B√ºchi Automaton"></a>Constrcution of Complete B√ºchi Automaton</h2><blockquote><p>$\textbf{Theorem 2.1. } \textit{For every B√ºchi Automaton }\mathcal{A},\text{ there is a complete B√ºchi Automaton }\mathcal{A}‚Äô \newline \textit{such that }\mathcal{L}(\mathcal{A}) &#x3D; \mathcal{L}(\mathcal{A}‚Äô)$</p></blockquote><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Let $\mathcal{A}$ be the automaton from <a href="../agv2-2/#eg1">Example 2.1</a> with B√ºchi acceptance condition $\small\text{B√úCHI}\normalsize (\lbrace D\rbrace)$. The language of the automaton consists of a single word:<br>$$\mathcal{L}(\mathcal{A})&#x3D;\lbrace aabbaabbaabb\dots\rbrace$$</p><p>For a B√ºchi Automaton $\mathcal{A} &#x3D; (\Sigma,Q,I,T,\small\text{B√úCHI} \normalsize(F))$,<br>we define the <strong>complete</strong> B√ºchi Automaton $\mathcal{A‚Äô} &#x3D; (\Sigma,Q‚Äô,I‚Äô,T‚Äô,\small\text{B√úCHI} \normalsize (F‚Äô))$ using:</p><ul><li>$Q‚Äô$ &#x3D; $Q \cup \lbrace q_f\rbrace$ where $q_f$ is a fresh state</li><li>$I‚Äô$ &#x3D; $I$</li><li>$T‚Äô$ &#x3D; $T \cup \lbrace (q,\sigma,q_f) \mid \nexists q‚Äô . (q,\sigma,q‚Äô)\in T\rbrace\cup\lbrace (q_f,\sigma,q_f)\mid\sigma\in\Sigma\rbrace$</li><li>$F‚Äô$ &#x3D; $F$</li></ul><p><img src="/images/notes/uds/agv/2_3_eg.png"></p><h3 id="Explained-in-Human-language"><a href="#Explained-in-Human-language" class="headerlink" title="Explained in Human language"></a>Explained in Human language</h3><p>First, we add a <strong>fresh state</strong> $q_f$ the <em>set of state</em> $Q$ without changing the <em>initial</em> and <em>accepting</em> states.</p><p>A <em>complete B√ºchi Automaton</em> requires every states must have transitions for every letters in the alphabet.<br>So for each states orginally in $Q$, we construct new transitions that the letters are not yet used by the state.<br>(which is $\nexists q‚Äô . (q,\sigma,q‚Äô)\in T$)</p><p>Finally, for all transitions from the fresh state are self transitioning, and they include all letters.<br>(which is $(q_f,\sigma,q_f)\mid\sigma\in\Sigma$)</p><h3 id="Formal-Proof"><a href="#Formal-Proof" class="headerlink" title="Formal Proof"></a>Formal Proof</h3><ul><li><p>The runs of $\mathcal{A‚Äô}$ are a <strong>superset</strong> of those of $\mathcal{A}$.</p><ul><li>During the construction of $\mathcal{A‚Äô}$, we have not removed any original transitions, but adding new fresh states.</li></ul></li><li><p>Furthermore, on <strong>any infinite input word</strong>, the accepting runs of $\mathcal{A}$ and $\mathcal{A‚Äô}$ are the same.</p><ul><li>If $\mathcal{A}$ accepts, $\mathcal{A‚Äô}$ also accepts because $\mathcal{A‚Äô}$ is a superset.</li><li>If a run reaches new fresh states $q_f$ stays in $q_f$ forever, and</li><li>since $q_f\notin F‚Äô$, such a run is not accepting.</li></ul></li></ul><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>A <em>complete deterministic automaton</em> may be viewed as a <strong>total function</strong> from $\Sigma^\omega$ to $Q^\omega$.<br>A <em>complete (possibly nondeterministic) automaton</em> produces <strong>at least one run for every input word</strong>.</p><hr><p>Next chapter: <a href="../agv3-1/">Kleene‚Äôs Theorem</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/B%C3%BCchi_automaton">B√ºchi automaton</a>, <a href="https://en.wikipedia.org/wiki/Omega_language">Omega language</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 2.2 -- Automata over Infinite Words</title>
      <link href="/AGV/agv2-2/"/>
      <url>/AGV/agv2-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv2-1/">B√ºchi automata (Preliminaries)</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="2-2-Automata-over-Infinite-Words"><a href="#2-2-Automata-over-Infinite-Words" class="headerlink" title="2.2 Automata over Infinite Words"></a>2.2 Automata over Infinite Words</h2><p>The operational behavior of an automaton over infinite words is very similar to automaton over finite words:</p><ol><li>Start with an <em>initial state</em></li><li>Automaton constructs a <strong>run</strong> by reading one letter of the input alphabet at a time, and<br>transitioning to a successor <em>state</em> permitted by its <em>transitions</em>.</li></ol><p>The major difference between automata over finite and infinite words is the <strong>acceptance condition</strong>.</p><blockquote><p>$\textbf{Definition 2.1. } \text{ An } \textit{automaton over infinite words } \text{is a tuple }\mathcal{A} &#x3D; (\Sigma,Q,I,T,Acc)\text{, where}$<br>$\begin{array}{l}<br>\hspace{1cm} \cdot \ \Sigma \text{ is a finite } \textit{alphabet} \newline<br>\hspace{1cm} \cdot \ Q \text{ is a finite set of } \textit{states} \newline<br>\hspace{1cm} \cdot \ I \subseteq Q \text{ is a subset of } \textit{initial states} \newline<br>\hspace{1cm} \cdot \ T \subseteq Q \times \Sigma \times Q \text{ is a set of } \textit{transitions} \text{, and} \newline<br>\hspace{1cm} \cdot \ Acc \subseteq Q^\omega \text{ is the } \textit{accepting condition}<br>\end{array}$</p></blockquote><p>In the following, we refer an automaton over infinite words simply as an automaton.</p><h3 id="Runs-of-Buchi-automata"><a href="#Runs-of-Buchi-automata" class="headerlink" title="Runs of B√ºchi automata"></a>Runs of B√ºchi automata</h3><p>A run in a B√ºchi automaton has to transition infinitely many times, and starts with the initial state.</p><blockquote><p>$\textbf{Definition 2.2. }\text{ An }\textit{run }\text{of an automaton }\mathcal{A}\text{ on an infinite input word }\alpha\text{ is an }\newline\text{infinite sequence of states }r&#x3D;r(0)r(1)r(2)\dots\text{ such that the following hold:}\newline\begin{array}{l}\hspace{1cm} \cdot \ r(0)\in I\newline\hspace{1cm} \cdot \ \text{for all }i\in\mathbb{N},(r(i),\alpha(i),r(i+1))\in T\end{array}$</p></blockquote><p><a name="eg1"></a></p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Below is a graphical representation of an automation over:</p><ul><li>alphabet $\Sigma &#x3D; \lbrace a,b\rbrace$, and with</li><li>set of states $Q &#x3D;\lbrace A,B,C,D\rbrace$,</li><li>initial set of states $I &#x3D;\lbrace A\rbrace$, and</li><li>set of transitions $T &#x3D;\lbrace (A,a,B),(B,a,C),(C,b,D),(D,b,A)\rbrace$</li></ul><p><img src="/images/notes/uds/agv/2_1_eg.png"></p><p>On the infinite input word $aabbaabb\dots$, the (only) run of the automaton is $ABCDABCDABCD\dots$</p><h2 id="Deterministic-and-Complete-Automaton"><a href="#Deterministic-and-Complete-Automaton" class="headerlink" title="Deterministic and Complete Automaton"></a>Deterministic and Complete Automaton</h2><p>An automaton is <strong>deterministic</strong> if $|I|\leq 1$ and $\mid\lbrace (q,\sigma,q‚Äô)\in T \mid q‚Äô\in Q\rbrace|\leq 1$ for every $q\in Q$ and $\sigma\in\Sigma$.<br>Meaning that the automaton has <strong>exactly 1</strong> <em>initial state</em>, and <strong>exactly 1</strong> <em>transition</em> from $q$ to $q‚Äô$</p><p>An automaton is <strong>complete</strong> if $\mid\lbrace (q,\sigma,q‚Äô)\in T \mid q‚Äô\in Q\rbrace|\geq 1$ for every $q\in Q$.<br>Meaning that any two states $(q,q‚Äô)$ in the automaton should have <strong>at least 1</strong> transitions from $q$ to $q‚Äô$.</p><p>Therefore, the automaton in the example above is deterministic but not complete.</p><p>The transitions of an <em>deterministic and complete automata</em> are usually given as a function $\delta:Q \times\Sigma\rightarrow Q$.<br>Meaning that the set of all transitions $\delta$ contains <strong>any states</strong> with <strong>any letter</strong>.</p><h2 id="Accepted-Run"><a href="#Accepted-Run" class="headerlink" title="Accepted Run"></a>Accepted Run</h2><blockquote><p>$\textbf{Definition 2.3. } \text{ An automaton } \mathcal{A} \textit{ accepts}\text{ an infinite word }\alpha\text{ if: }$<br>$\begin{array}{l}<br>\hspace{1cm} \cdot \ \text{there is a run }r\text{ of }\mathcal{A}\text{ on }\alpha\text{, and}\newline<br>\hspace{1cm} \cdot \ r \text{ is } \textit{accepting}:r\in Acc\end{array}\newline<br>\text{The } \textit{language recognized }\text{by }\mathcal{A}\text{ is defined as follows: }<br>\mathcal{L}(\mathcal{A}) &#x3D; \lbrace \alpha\in\Sigma^\omega\mid\mathcal{A}\text{ accepts }\alpha\rbrace$</p></blockquote><p>We say two automata are <strong>equivalent</strong> if they have the same language.</p><hr><p>Next chapter: <a href="../agv2-3/"></a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/B%C3%BCchi_automaton">B√ºchi automaton</a>, <a href="https://en.wikipedia.org/wiki/Omega_language">Omega language</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 2.1 -- B√ºchi automata (Preliminaries)</title>
      <link href="/AGV/agv2-1/"/>
      <url>/AGV/agv2-1/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv1-3/">The Logic-Automata Connection</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="2-1-Preliminaries"><a href="#2-1-Preliminaries" class="headerlink" title="2.1 Preliminaries"></a>2.1 Preliminaries</h2><table><thead><tr><th align="left">Basic math notations</th><th align="left">Example</th></tr></thead><tbody><tr><td align="left">Natural numbers</td><td align="left">$\mathbb{N} &#x3D; \lbrace 0,1,2,3\dots\rbrace$</td></tr><tr><td align="left">Positive Natural numbers</td><td align="left">$\mathbb{N}^+ &#x3D; \lbrace 1,2,3\dots\rbrace$</td></tr><tr><td align="left">Numbers from $n$ to $m$</td><td align="left">$[n,m] &#x3D; \lbrace n,n+1,\dots,m\rbrace$ For $n,m\in \mathbb{N}$ with $n\leq m$</td></tr><tr><td align="left">Numbers from $0$ to $m$</td><td align="left">$[m] &#x3D; \lbrace 0,1,\dots,m\rbrace$</td></tr></tbody></table><p>$$$$</p><table><thead><tr><th align="left">Alphabet and Letter</th><th align="left">Example</th></tr></thead><tbody><tr><td align="left"><strong>Alphabet</strong></td><td align="left">a nonempty, finite set of symbols, usually denoted by $\Sigma$</td></tr><tr><td align="left"><strong>Letter</strong></td><td align="left">elements of an <em>alphabets</em>, denoted by $\sigma$</td></tr></tbody></table><p>$$$$</p><table><thead><tr><th align="left">Finite and Infinite Word</th><th align="left">Example</th></tr></thead><tbody><tr><td align="left"><strong>Finite Words</strong></td><td align="left">concatenation $w&#x3D;w(0)w(1)\dots w(n-1)$ of <br/> <em>finitely many letters</em> of $\Sigma$</td></tr><tr><td align="left"><strong>Infinite Words</strong></td><td align="left">$\alpha$ (will be explained in <a href="../agv2-3/#inf">chapter 2.3</a></td></tr><tr><td align="left"><strong>$n$-th letter</strong> of word $w$</td><td align="left">$w(n)$ for each $n\in [|w| - 1]$</td></tr><tr><td align="left"><strong>Length</strong> of words $w$</td><td align="left">$|w|$</td></tr><tr><td align="left">set of all <strong>finite words</strong></td><td align="left">\Sigma^*$</td></tr><tr><td align="left"><strong>Infinite Words</strong></td><td align="left">$\alpha$ (will be explained in <a href="../agv2-3/#inf">chapter 2.3</a></td></tr><tr><td align="left">set of all <strong>non-empty finite words</strong></td><td align="left">$\Sigma^+ &#x3D; \Sigma^* \backslash \lbrace \epsilon \rbrace$</td></tr><tr><td align="left">set of all <strong>infinite words</strong></td><td align="left">$\Sigma^\omega$</td></tr></tbody></table><p>$$$$</p><table><thead><tr><th align="left">Language</th><th align="left">Example</th></tr></thead><tbody><tr><td align="left">language over <strong>finite words</strong> ($\omega$<strong>-language</strong>)</td><td align="left">each subset of $\Sigma^*$</td></tr><tr><td align="left">language over <strong>infinite words</strong> ($\omega$<strong>-language</strong>)</td><td align="left">each subset of $\Sigma^\omega$</td></tr></tbody></table><hr><p>Next chapter: <a href="../agv2-2/">Automata over Infinite Words</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/B%C3%BCchi_automaton">B√ºchi automaton</a>, <a href="https://en.wikipedia.org/wiki/Omega_language">Omega language</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 1.3 -- The Logic-Automata Connection</title>
      <link href="/AGV/agv1-3/"/>
      <url>/AGV/agv1-3/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv1-2/">Synthesis</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Verification-or-Synthesis"><a href="#Verification-or-Synthesis" class="headerlink" title="Verification or Synthesis"></a>Verification or Synthesis</h2><p>In applications like <a href="../agv1-1/">verification</a> and <a href="../agv1-2/">synthesis</a>, the automata- and game-theoretic machinery is usually ‚Äúhidden‚Äù behind a logical formulation of the problem.</p><p><img src="/images/notes/uds/agv/1_3_logic.png"></p><h3 id="Logics-with-corresponding-Automata"><a href="#Logics-with-corresponding-Automata" class="headerlink" title="Logics with corresponding Automata"></a>Logics with corresponding Automata</h3><blockquote><p><strong>S1S</strong>‚Äòs expressiveness exceeds that of <strong>LTL</strong>, and<br><strong>S2S</strong>‚Äòs expressiveness exceeds that of <strong>CTL*</strong> (on binary trees)</p></blockquote><table><thead><tr><th align="left">Logic</th><th align="left">Usage</th><th align="left">Example</th></tr></thead><tbody><tr><td align="left"><strong>Linear-time temporal logic (LTL)</strong></td><td align="left">sets of infinite <strong>words</strong></td><td align="left">$\square \Diamond \ell_1$</td></tr><tr><td align="left"><strong>Computation-tree logic (CTL &#x2F; CTL*)</strong></td><td align="left">sets of infinite <strong>trees</strong></td><td align="left">$\textsf{EF}\ell_1 \wedge \textsf{EF}m_1$</td></tr><tr><td align="left"><strong>Monadic second-order logic with one successor (S1S)</strong></td><td align="left">logic over infinite <strong>words</strong></td><td align="left">$\forall x . x \in P \rightarrow S(x) \in P$</td></tr><tr><td align="left"><strong>Monadic second-order logic with two successors (S2S)</strong></td><td align="left">logic over infinite <strong>binary trees</strong></td><td align="left">$\forall x . x \in P \rightarrow S_1(x) \in P \vee S_2(x) \in P$</td></tr></tbody></table><h3 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h3><ul><li>$\square \Diamond \ell_1$<br>$P_0$ is infinitely often at location $\ell_1$.</li><li>$\textsf{EF}\ell_1 \wedge \textsf{EF}m_1$<br>There exists a computation path in which $P_0$ reaches location $\ell_1$, and<br>there is a (possibly different) computation path in which $P_1$ reaches location $m_1$.</li><li>$\forall x . x \in P \rightarrow S(x) \in P$<br>A (given) set of natural numbers $P$ is either empty, or<br>consists of all positions starting from some position of the word.</li><li>$\forall x . x \in P \rightarrow S_1(x) \in P \vee S_2(x) \in P$<br>A (given) set of nodes $P$ contains from each node $n \in P$ an entire path starting in $n$.</li></ul><p>For example, <strong>mutual exclusion</strong> property can be expressed using <strong>linear-time temporal logic (LTL)</strong>:<br>$$\square \neg (\ell_1 \wedge m_1)$$</p><h2 id="Satisfiability-problem"><a href="#Satisfiability-problem" class="headerlink" title="Satisfiability problem"></a>Satisfiability problem</h2><p>Other than verification and synthesis, another important application of the connection between logic and automata is to decide the <em>satisfiability</em> problem of the various logics.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>We want to know if there exist two natural numbers $x$ and $y$ such that $x&#x3D;y+1$ and $y&#x3D;x+1$.<br>This can be expressed as the <strong>S1S</strong> formula $x&#x3D;S(y) \wedge y&#x3D;S(x)$, translate each conjunct into an automaton:</p><p><img src="/images/notes/uds/agv/1_3_automaton.png"></p><p><strong>Alphabet</strong>: subsets of $\lbrace x,y\rbrace$.</p><p>There does not exist a word that is accepted by both automaton. Hence, the formula is unsatisfiable.</p><hr><p>Next chapter: <a href="../agv2-1/">B√ºchi automata (Preliminaries)</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 1.2 -- Synthesis</title>
      <link href="/AGV/agv1-2/"/>
      <url>/AGV/agv1-2/</url>
      
        <content type="html"><![CDATA[<p>Previous chapter: <a href="../agv1-1/">Model Checking</a></p><blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Synthesis"><a href="#Synthesis" class="headerlink" title="Synthesis"></a>Synthesis</h2><p>In synthesis, we check automatically if there <em>exists</em> a program that satisfies a given specification.</p><p>If the answer is yes, we construct such a program.</p><p>We solve it by determine the winner of a <strong>two-player game</strong> between a <em>system player</em> and an <em>environment player</em>.</p><table><thead><tr><th align="left"></th><th align="left">Task</th><th align="left">Goal</th></tr></thead><tbody><tr><td align="left"><strong>System player</strong></td><td align="left">choose the <strong>outputs</strong> of the system</td><td align="left"><strong>meet</strong> the specification</td></tr><tr><td align="left"><strong>Environment player</strong></td><td align="left">choose the <strong>inputs</strong> of the system</td><td align="left"><strong>falsify</strong> the specification</td></tr></tbody></table><p>Therefore, the specification is satisfied if the <strong>System player</strong> wins.<br>Such <strong>winning strategy</strong> can be translated into a program that is guaranteed to satisfy the specification.</p><h3 id="Example-coffee-machine"><a href="#Example-coffee-machine" class="headerlink" title="Example: coffee machine"></a>Example: coffee machine</h3><p>In this example, we assume there‚Äôs a machine that ‚Äúoutputs coffee‚Äù whenever users press a button.</p><p><strong>Set of</strong> $AP &#x3D; \lbrace bu, co\rbrace$, where input $AP_I &#x3D; \lbrace bu\rbrace$ and output $AP_O &#x3D; \lbrace co\rbrace$.</p><p><strong>Specification</strong>: $co$ should hold iff. $bu$ holds in every step.</p><p><img src="/images/notes/uds/agv/1_2_coffee.png"></p><p>From this automaton, we construct a <em><strong>game arena</strong></em> where in each round,</p><ol><li>Environment player chooses the input ($bu$ or $\neg bu$)</li><li>System player chooses the output ($co$ or $\neg co$)</li></ol><p>States of the game keep track of the corresponding state of the automaton,<br>then we can determine who is the winner for each possible play.</p><p><img src="/images/notes/uds/agv/1_2_game.png"></p><p>Here, system player gets to choose the next move with circles, and environment player choose with squares.</p><p>System player has a simple winning strategy from starting position $t_0$:</p><blockquote><p>react input $bu$ with output $co$, and react input $\neg bu$ with output $\neg co$</p></blockquote><p>In this way, the play visits $t_0$ infinitely often, which proves that it satisfies the specification.</p><hr><p>Next chapter: <a href="../agv1-3/">The Logic-Automata Connection</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/Program_synthesis">Program synthesis</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AGV 1.1 -- Model Checking</title>
      <link href="/AGV/agv1-1/"/>
      <url>/AGV/agv1-1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Bernd Finkbeiner</p></blockquote><h2 id="Model-Checking"><a href="#Model-Checking" class="headerlink" title="Model Checking"></a>Model Checking</h2><p>Given a <strong>system model</strong>, we try to check whether it meets its <strong>specification</strong> <em>automatically</em> and <em>exhaustively</em>.<br>To describe&#x2F;represent the <strong>system</strong> and <strong>specification</strong>, we use <strong>Automata over infinite objects</strong>.</p><h3 id="Verification-Problem"><a href="#Verification-Problem" class="headerlink" title="Verification Problem"></a>Verification Problem</h3><p>The verification problem can be solved by:</p><blockquote><p>Constructing the <strong>intersection</strong> of system, with an automaton for the <strong>negation of the specification</strong>,<br>then checking whether the language of the resulting automaton is <strong>empty</strong>.</p></blockquote><p>$\textbf{Example 1.1. } \text{Consider the concurrent program }\small{\text{TURN}}:$<br>$$\text{local $t$: boolean where initially $t$ &#x3D; $false$}\newline<br>P_0::\left[ \begin{array}{l}\text{loop forever do}\newline<br>\hspace{1cm}\left[ \begin{array}{l}<br>\ell_0: \text{await }\neg t; \newline<br>\ell_1: \text{critical;} \newline<br>\ell_2: t :&#x3D; true; \newline<br>\end{array} \right]\end{array} \right]<br>\mid\mid P_1::\left[ \begin{array}{l}<br>\text{loop forever do}\newline<br>\hspace{1cm}\left[ \begin{array}{l}<br>m_0: \text{await } t; \newline<br>m_1: \text{critical;} \newline<br>m_2: t :&#x3D; false; \newline<br>\end{array} \right]\end{array} \right]$$</p><p>The example above is a simple solution to the <strong>mutual exclusion problem</strong>:<br>it ensures that at any given point of time, <strong>at most one</strong> process is in the critical region.</p><h3 id="From-Program-to-automaton"><a href="#From-Program-to-automaton" class="headerlink" title="From Program to automaton"></a>From Program to automaton</h3><p>To represent the above program using automaton, we need to define an <strong>alphabet $\Sigma$</strong>.</p><p>Firstly, we fix a set of <strong>atomic propositions (AP)</strong>, that is (potentially) relevant to the program states.<br>For the program in $\small{\text{Example 1.1}}$, $AP &#x3D; \lbrace\ell_0,\ell_1,\ell_2,m_0,m_1,m_2,t\rbrace$.<br>i.e. The present program location and the current value of $t$.</p><p>Then, we define the <strong>alphabet</strong> as $\Sigma &#x3D; 2^{AP}$, the set of subsets of $AP$.<br>An $AP$ is included in the subset if it is currently $true$.</p><p><img src="/images/notes/uds/agv/1_1_turn.png"></p><p>This automaton is a <em><strong>safety automaton</strong></em>, it accepts all <strong>infinite repetitons</strong> of the sequence<br>$\lbrace\ell_0,m_0\rbrace \lbrace\ell_1,m_0\rbrace \lbrace\ell_2,m_0\rbrace \lbrace\ell_0,m_0,t\rbrace \lbrace\ell_0,m_2,t\rbrace$</p><h2 id="Automata-Verification"><a href="#Automata-Verification" class="headerlink" title="Automata Verification"></a>Automata Verification</h2><p>To verify $\small{\text{TURN}}$ satisfies the <strong>mutual exclusion</strong> property ($P_0$ and $P_1$ are never in $\ell_1$ and $m_1$ at the same time),<br>we build an automaton that <strong>represents the negation</strong> (eventually $P_0$ and $P_1$ are simultaneously in location 01):</p><p><img src="/images/notes/uds/agv/1_1_neg.png"></p><p>This automaton is a <em><strong>B√ºchi automaton</strong></em> with accepting state $t_1$.</p><p>A <strong>word</strong> is accepted if $t_1$ is visited <strong>infinitely often</strong>.</p><p>For every word accepted by the <em>system automaton</em>, this <em>property automaton</em> stays in $t_0$ forever and therefore does not accept the word.<br>This means there does not exist an infinite sequence that <strong>generated by the program</strong>, and<br><strong>accepted by the negation automaton</strong> of the specification. In other words, $\small{\text{TURN}}$ is <strong>correct</strong>.</p><hr><p>Next post: <a href="../agv1-2/">Synthesis</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/B%C3%BCchi_automaton">B√ºchi automaton</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AGV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 197. Rising Temperature</title>
      <link href="/LeetCode/sql50-197/"/>
      <url>/LeetCode/sql50-197/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Weather"><a href="#Table-name-Weather" class="headerlink" title="Table name: Weather"></a>Table name: <code>Weather</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">id</td><td align="left">int</td></tr><tr><td align="left">recordDate</td><td align="left">date</td></tr><tr><td align="left">temperature</td><td align="left">int</td></tr></tbody></table><p>There are no different rows with the same <code>recordDate</code>.<br>This table contains information about the <code>temperature</code> on a certain day.</p><blockquote><p>Write a solution to find all <code>dates&#39; id</code> with higher temperatures compared to its <strong>previous dates</strong> (yesterday).<br>Return the result table in any order.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>Here, we need to learn how to handle the datatype <code>date</code>.<br>To modify the date, we can use <code>INTERVAL</code> keyword, or <code>DATEADD()</code> function.</p><h3 id="INTERVAL"><a href="#INTERVAL" class="headerlink" title="INTERVAL &lt;value&gt; &lt;unit&gt;"></a><code>INTERVAL &lt;value&gt; &lt;unit&gt;</code></h3><p>Interval is a special datatype, that can interact with <code>time</code> and <code>date</code>.</p><p>Interval unit includes<br><strong>microsecond</strong>, <strong>millisecond</strong>, <strong>second</strong>, <strong>minute</strong>, <strong>hour</strong>, <strong>day</strong>, <strong>week</strong>, <strong>month</strong>, <strong>year</strong>, <strong>decade</strong>, <strong>century</strong>, <strong>millennium</strong></p><p>For example, <code>&#39;2001-09-28&#39; + INTERVAL 1 DAY</code> ‚Üí <code>2002-09-28</code></p><h3 id="DATEADD"><a href="#DATEADD" class="headerlink" title="DATEADD(&lt;interval&gt;, &lt;number&gt;, &lt;date&gt;)"></a><code>DATEADD(&lt;interval&gt;, &lt;number&gt;, &lt;date&gt;)</code></h3><p>Similarly, we can use DATEADD() to modify data with datatype <code>date</code>.</p><p><code>DATEADD(year, 1, &#39;2001-09-28&#39;)</code> ‚Üí <code>2002-09-28</code></p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT w1.id FROM Weather w1 JOIN Weather w2ON w1.recordDate = w2.recordDate + INTERVAL 1 DAYWHERE w1.temperature &gt; w2.temperature;  </code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 1581. Customer Who Visited but Did Not Make Any Transactions</title>
      <link href="/LeetCode/sql50-1581/"/>
      <url>/LeetCode/sql50-1581/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Visits"><a href="#Table-name-Visits" class="headerlink" title="Table name: Visits"></a>Table name: <code>Visits</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">visit_id</td><td align="left">int</td></tr><tr><td align="left">customer_id</td><td align="left">int</td></tr></tbody></table><p>This table contains information about the <code>customers</code> who visited the mall.</p><h3 id="Table-name-Transactions"><a href="#Table-name-Transactions" class="headerlink" title="Table name: Transactions"></a>Table name: <code>Transactions</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">transaction_id</td><td align="left">int</td></tr><tr><td align="left">visit_id</td><td align="left">int</td></tr><tr><td align="left">amount</td><td align="left">int</td></tr></tbody></table><p>This table contains information about the <code>transactions</code> made during the visit_id.</p><blockquote><p>Write a solution to find the <code>IDs of the users</code> who visited <strong>without making any transactions</strong>, and<br>the <strong>number of times</strong> they made these types of visits.<br>Return the result table sorted in any order.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>This is another typical <code>JOIN</code> query question.<br>The tricky part is the column we join on doesn‚Äôt necessarily be selected.</p><p>Moreover, we can control which rows to be joined using <code>WHERE</code>, as simple <code>SELECT</code>.</p><p>Lasting to remember is to use <code>GROUP BY</code> for your <code>COUNT()</code> function,<br>to make sure they counted separately based on <code>customer_id</code>.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT customer_id, count(*) AS count_no_transFROM VisitsLEFT JOIN Transactions ON Visits.visit_id=Transactions.visit_idWHERE transaction_id IS NULLGROUP BY customer_id</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 1068. Product Sales Analysis I</title>
      <link href="/LeetCode/sql50-1068/"/>
      <url>/LeetCode/sql50-1068/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Sales"><a href="#Table-name-Sales" class="headerlink" title="Table name: Sales"></a>Table name: <code>Sales</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">sale_id</td><td align="left">int</td></tr><tr><td align="left">product_id</td><td align="left">int</td></tr><tr><td align="left">year</td><td align="left">int</td></tr><tr><td align="left">quantity</td><td align="left">int</td></tr><tr><td align="left">price</td><td align="left">int</td></tr></tbody></table><p>Each row of this table shows a sale on the product <code>product_id</code> in a certain year.<br>Note that the <code>price</code> is per unit.</p><h3 id="Table-name-Product"><a href="#Table-name-Product" class="headerlink" title="Table name: Product"></a>Table name: <code>Product</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">product_id</td><td align="left">int</td></tr><tr><td align="left">product_name</td><td align="left">varchar</td></tr></tbody></table><p>Each row of this table indicates the <code>product name</code> of each product.</p><blockquote><p>Write a solution to report the <code>product_name</code>, <code>year</code>, and <code>price</code> for each <code>sale_id</code> in the <code>Sales</code> table.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>This question is a basic usage of <code>JOIN</code> query.</p><p>Just be careful on which table you are referring when you select the columns.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT Product.product_name, Sales.year, Sales.price FROM Sales INNER JOIN Product ON Sales.product_id = Product.product_id;</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 1517. Find Users With Valid E-Mails</title>
      <link href="/LeetCode/sql50-1517/"/>
      <url>/LeetCode/sql50-1517/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name"><a href="#Table-name" class="headerlink" title="Table name: &#96;&#96;"></a>Table name: &#96;&#96;</h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">user_id</td><td align="left">int</td></tr><tr><td align="left">name</td><td align="left">varchar</td></tr><tr><td align="left">mail</td><td align="left">varchar</td></tr></tbody></table><p>This table contains information of the <code>users</code> signed up in a website. Some <code>e-mails</code> are invalid.</p><p>A valid <code>e-mail</code> has a <strong>prefix name</strong> and a <strong>domain</strong>.</p><p><strong>domain</strong>: <code>@leetcode.com</code>.<br><strong>prefix name</strong> is a string that may contain:</p><ul><li>letters (upper or lower case)</li><li>digits</li><li>underscore <code>_</code></li><li>period <code>.</code></li><li>dash <code>-</code></li></ul><p>(The prefix name <strong>must start with a letter.</strong>)</p><blockquote><p>Write a solution to find the users who have <strong>valid emails</strong>.<br>Return the result table in any order.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>For string validation, there is a powerful tool for pattern matching called <a href="https://evermap.com/RegularExpressions.asp">RegEx</a>.</p><p>In SQL, it provides the keyword <code>REGEXP</code> to enter your pattern for validation.<br>Here, we simply explain the patterns we used to match the requirement.</p><table><thead><tr><th align="left">Pattern</th><th align="left">Meaning</th></tr></thead><tbody><tr><td align="left"><code>^</code></td><td align="left">Match Beginning of string</td></tr><tr><td align="left"><code>$</code></td><td align="left">Match The End of string</td></tr><tr><td align="left"><code>[a-zA-Z]</code></td><td align="left">Match any upper and lower case letter</td></tr><tr><td align="left"><code>[a-zA-Z0-9_.-]</code></td><td align="left">Match any upper and lower case letter, digits, underscore, period, dash</td></tr><tr><td align="left"><code>*</code></td><td align="left">Zero or more instances of string preceding it</td></tr></tbody></table><p>Therefore, <code>^[a-zA-Z][a-zA-Z0-9_.-]*</code> means:</p><blockquote><p>Begins the string with any upper or lower case letter,<br>follows by zero or more upper and lower case letter, digits, underscore, period, and&#x2F;or dash.</p></blockquote><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT * FROM UsersWHERE mail REGEXP &#39;^[a-zA-Z][a-zA-Z0-9_.-]*@leetcode\\.com$&#39;</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 1327. List the Products Ordered in a Period</title>
      <link href="/LeetCode/sql50-1327/"/>
      <url>/LeetCode/sql50-1327/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Products"><a href="#Table-name-Products" class="headerlink" title="Table name: Products"></a>Table name: <code>Products</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">product_id</td><td align="left">int</td></tr><tr><td align="left">product_name</td><td align="left">varchar</td></tr><tr><td align="left">product_category</td><td align="left">varchar</td></tr></tbody></table><p>This table contains data about the company‚Äôs products.</p><h3 id="Table-name-Orders"><a href="#Table-name-Orders" class="headerlink" title="Table name: Orders"></a>Table name: <code>Orders</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">product_id</td><td align="left">int</td></tr><tr><td align="left">order_date</td><td align="left">date</td></tr><tr><td align="left">unit</td><td align="left">int</td></tr></tbody></table><p>unit is the number of products ordered in order_date.</p><blockquote><p>Write a solution to get the <code>names</code> of products,<br>that have <strong>at least 100 units</strong> ordered <strong>in February 2020</strong> and their <code>amount</code>.<br>Return the result table in any order.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><h3 id="Retrieve-the-amount-of-products"><a href="#Retrieve-the-amount-of-products" class="headerlink" title="Retrieve the amount of products"></a>Retrieve the amount of products</h3><p>Here, we can use <code>SUM()</code> function. Similar to <code>COUNT()</code>,<br>we can use <code>GROUP BY</code> so that multiple rows that contain the same <code>product_name</code> will sum up into one row.</p><h3 id="SELECT-based-on-Time-Range"><a href="#SELECT-based-on-Time-Range" class="headerlink" title="SELECT based on Time Range"></a>SELECT based on Time Range</h3><p>To validate the date, we can use <code>EXTRACT()</code> function.</p><pre><code class="sql">EXTRACT(part FROM date)</code></pre><p><code>&lt;part&gt;</code> in this function refers to specific piece of information about the time.</p><p>Here, we can use <code>YEAR_MONTH</code> to check whether the date in within <strong>February 2020</strong>.</p><p>For all possible parts defined by SQL, you may check the list <a href="#list">below</a>.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT p.product_name, SUM(o.unit) AS unitFROM Products p JOIN Orders o ON p.product_id = o.product_id     AND EXTRACT(YEAR_MONTH FROM order_date) = 202002GROUP BY product_nameHAVING unit &gt;= 100</code></pre><p><a name="list"></a></p><h2 id="List-of-part-in-EXTRACT-function"><a href="#List-of-part-in-EXTRACT-function" class="headerlink" title="List of part in EXTRACT() function"></a>List of <code>part</code> in <code>EXTRACT()</code> function</h2><p>Here‚Äôs the list of all possible component you can extract from date:</p><table><thead><tr><th align="left">Parts</th><th align="left"></th><th align="left"></th><th align="left"></th></tr></thead><tbody><tr><td align="left">MICROSECOND</td><td align="left">WEEK</td><td align="left">MINUTE_MICROSECOND</td><td align="left">DAY_MICROSECOND</td></tr><tr><td align="left">SECOND</td><td align="left">MONTH</td><td align="left">MINUTE_SECOND</td><td align="left">DAY_SECOND</td></tr><tr><td align="left">MINUTE</td><td align="left">QUARTER</td><td align="left">HOUR_MICROSECOND</td><td align="left">DAY_MINUTE</td></tr><tr><td align="left">HOUR</td><td align="left">YEAR</td><td align="left">HOUR_SECOND</td><td align="left">DAY_HOUR</td></tr><tr><td align="left">DAY</td><td align="left">SECOND_MICROSECOND</td><td align="left">HOUR_MINUTE</td><td align="left">YEAR_MONTH</td></tr></tbody></table><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 1484. Group Sold Products By The Date</title>
      <link href="/LeetCode/sql50-1484/"/>
      <url>/LeetCode/sql50-1484/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Activities"><a href="#Table-name-Activities" class="headerlink" title="Table name: Activities"></a>Table name: <code>Activities</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">sell_date</td><td align="left">date</td></tr><tr><td align="left">product</td><td align="left">varchar</td></tr></tbody></table><p>Each row of this table contains the product name and the date it was sold in a market.</p><blockquote><p>Write a solution to find for each <code>date</code> the number of different products sold and their <code>names</code>.<br>The sold products names for each date should be <strong>sorted lexicographically</strong>.<br>Return the result table <strong>ordered by sell_date</strong>.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>Again, there are two tasks we need to solve:</p><ol><li>Count how many types of products are sold in one day</li><li>List all types of items into a single column</li></ol><h3 id="Type-of-Items"><a href="#Type-of-Items" class="headerlink" title="Type of Items"></a>Type of Items</h3><p>We can simply count how many products are sold using <code>COUNT</code>, groupped by the date they belong to:</p><pre><code class="sql">SELECT COUNT(*) AS num_sold, FROM ActivitiesGROUP BY sell_date</code></pre><p>However, if a product is sold twice in one day, they will be counted twice as well.<br>Since the question asked for <strong>the number of different products sold</strong>,<br>we need to specify the column we are counting, and use the keyword <code>DINSTINCT</code> to remove duplicates:</p><pre><code class="sql">SELECT COUNT(DISTINCT product) AS num_sold, FROM ActivitiesGROUP BY sell_date</code></pre><h3 id="GROUP-CONCAT-Rolling-up-multiple-rows-in-single-row"><a href="#GROUP-CONCAT-Rolling-up-multiple-rows-in-single-row" class="headerlink" title="GROUP_CONCAT(): Rolling up multiple rows in single row"></a>GROUP_CONCAT(): Rolling up multiple rows in single row</h3><p>To roll data from multiple rows in single row, we may use the <code>GROUP_CONCAT()</code> function,<br>and below is the syntax:</p><pre><code class="sql">GROUP_CONCAT(expr   [ORDER BY &#123;unsigned_integer | col_name | expr&#125; ASC | DESC]    [SEPARATOR str_val])</code></pre><ul><li>It can be sorted with respect to other column by using <code>ORDER BY</code> inside the function</li><li>You may define custom string as the <code>separator</code> of the output (default is comma)</li></ul><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT sell_date, COUNT(DISTINCT product) AS num_sold,     GROUP_CONCAT(DISTINCT product) AS productsFROM ActivitiesGROUP BY sell_date</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 176. Second Highest Salary</title>
      <link href="/LeetCode/sql50-176/"/>
      <url>/LeetCode/sql50-176/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name"><a href="#Table-name" class="headerlink" title="Table name: &#96;&#96;"></a>Table name: &#96;&#96;</h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">id</td><td align="left">int</td></tr><tr><td align="left">salary</td><td align="left">int</td></tr></tbody></table><p>Each row of this table contains information about the <code>salary</code> of an <code>employee</code>.</p><blockquote><p>Write a solution to find the <strong>second highest distinct</strong> <code>salary</code> from the Employee table.<br>If there is no second highest salary, return <code>null</code>.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>The key idea of this question is to get the <strong>second</strong> value. Here I have two ideas that come to my mind immediately</p><ol><li>First, order the list according to salary, then fetch the second row.</li><li>First, find the highest salary, then do another <code>SELECT</code> query based on the highest salary.</li></ol><h3 id="1-Using-LIMIT-and-OFFSET"><a href="#1-Using-LIMIT-and-OFFSET" class="headerlink" title="1. Using LIMIT and OFFSET"></a>1. Using LIMIT and OFFSET</h3><p>Using <code>LIMIT</code> and <code>OFFSET</code>, we can simply retrieve the second row of a database:</p><pre><code class="sql">SELECT DISTINCT Salary     FROM Employee     ORDER BY salary DESC     LIMIT 1 OFFSET 1</code></pre><p>Here, we used <code>ORDER BY salary DESC</code> and <code>DISTINCT</code> to make sure the second row contains the second highest salary.<br>Then <code>LIMIT 1</code> constraints there will be only one row returned, <code>OFFSET 1</code> means to skip 1 row before fetching.</p><p>However, this query won‚Äôt return <code>null</code> if there isn‚Äôt a second row.</p><p>To solve the problem, we can wrap this query by another <code>SELECT</code> query.</p><h3 id="2-Recursive-SELECT"><a href="#2-Recursive-SELECT" class="headerlink" title="2. Recursive SELECT"></a>2. Recursive SELECT</h3><p>There will be two <code>SELECT</code> function, the <code>SELECT</code> in <code>WHERE</code> clause returns the highest salary:</p><pre><code class="sql">WHERE salary &lt; (SELECT MAX(salary) FROM Employee)</code></pre><p>So that the <code>SELECT</code> query outside can directly compare with this and thus it returns the second highest salary.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><h3 id="Using-LIMIT-and-OFFSET"><a href="#Using-LIMIT-and-OFFSET" class="headerlink" title="Using LIMIT and OFFSET"></a>Using LIMIT and OFFSET</h3><pre><code class="sql">SELECT(    SELECT DISTINCT Salary     FROM Employee     ORDER BY salary DESC     LIMIT 1 OFFSET 1 )AS SecondHighestSalary;</code></pre><h3 id="Recursive-SELECT"><a href="#Recursive-SELECT" class="headerlink" title="Recursive SELECT"></a>Recursive SELECT</h3><pre><code class="sql">SELECT MAX(salary) AS SecondHighestSalary FROM EmployeeWHERE salary &lt; (SELECT MAX(salary) FROM Employee);</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 196. Delete Duplicate Emails</title>
      <link href="/LeetCode/sql50-196/"/>
      <url>/LeetCode/sql50-196/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Person"><a href="#Table-name-Person" class="headerlink" title="Table name: Person"></a>Table name: <code>Person</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">id</td><td align="left">int</td></tr><tr><td align="left">email</td><td align="left">varchar</td></tr></tbody></table><p>Each row of this table contains an <code>email</code>. The emails will <strong>not contain uppercase letters</strong>.</p><blockquote><p>Write a solution to <strong>delete all duplicate emails</strong>, keeping only one unique email with the <strong>smallest id</strong>.<br>For SQL users, please note that you are supposed to write a <code>DELETE</code> statement and not a <code>SELECT</code> one.<br>The final order of the table does not matter.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>Usually, people will simply replace the old table with the new table using <code>SELECT</code> to remove the duplicates.<br>The tricky part of this question is that you cannot create a new table, as the system only checks the original table <code>Person</code>.</p><p>Since we cannot use <code>SELECT</code>, the only way to filter out unwanted rows is to use <code>WHERE</code> or <code>HAVING</code>.</p><p>First of all, we can call the same table twice by giving them different name temporarily, so that we can compare between rows,</p><p>We need to keep the same email which has smaller id, so <code>p.Id &gt; q_Id</code>, then we also need to nake sure that there are acutally duplicate email, so <code>p.Email=q.Email</code></p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">DELETE p from Person p, Person q where p.Id&gt;q.Id AND q.Email=p.Email</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 1527. Patients With a Condition</title>
      <link href="/LeetCode/sql50-1527/"/>
      <url>/LeetCode/sql50-1527/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Patients"><a href="#Table-name-Patients" class="headerlink" title="Table name: Patients"></a>Table name: <code>Patients</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">patient_id</td><td align="left">int</td></tr><tr><td align="left">patient_name</td><td align="left">varchar</td></tr><tr><td align="left">conditions</td><td align="left">varchar</td></tr></tbody></table><p><code>conditions</code> contains <strong>zero or more</strong> code separated by spaces.<br>This table contains information of the <code>patients</code> in the hospital.</p><blockquote><p>Write a solution to find the <code>patient_id</code>, <code>patient_name</code>, and <code>conditions</code> of the patients who have <strong>Type I Diabetes</strong>.<br>Type I Diabetes always starts with <code>DIAB1</code> prefix. Return the result table in any order.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><h3 id="SQL-LIKE-Operator"><a href="#SQL-LIKE-Operator" class="headerlink" title="SQL LIKE Operator"></a>SQL LIKE Operator</h3><p>In SQL, to extract data that contain certain specified pattern, we can use <code>LIKE</code> in the <code>WHERE</code> clause.<br>For example, we can use </p><pre><code class="sql">SELECT * FROM Patients WHERE conditions LIKE &#39;DIAB1%&#39;</code></pre><p>In here, <code>%</code> is a wildcard, refers to any number of characters can exist after the string <code>DIAB1</code>.<br><code>DIAB1</code>, <code>DIAB1234</code>, <code>DIAB1eg</code> are valid outputs.</p><p>There is another wildcard <code>_</code>, refers to exactly one single character.<br><code>aDIAB12</code>, <code>2DIAB1</code> are valid outputs of <code>_DIAB1</code></p><h3 id="Valid-outputs"><a href="#Valid-outputs" class="headerlink" title="Valid outputs"></a>Valid outputs</h3><p>In this question, <code>conditions</code> which contain valid <code>DIAB1</code> are either:</p><ul><li><code>DIAB1</code> is after some conditions, for exmaple <code>ACNE DIAB100</code>, or</li><li>the list of conditions begins with <code>DIAB1</code>, for example <code>DIAB100 MYOP</code>.</li></ul><p>Therefore, we have to include both cases with two separate <code>LIKE</code> operator.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT * FROM PatientsWHERE conditions LIKE &#39;% DIAB1%&#39; OR conditions LIKE &#39;DIAB1%&#39;</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 1667. Fix Names in a Table</title>
      <link href="/LeetCode/sql50-1667/"/>
      <url>/LeetCode/sql50-1667/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Users"><a href="#Table-name-Users" class="headerlink" title="Table name: Users"></a>Table name: <code>Users</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">user_id</td><td align="left">int</td></tr><tr><td align="left">name</td><td align="left">varchar</td></tr></tbody></table><p>This table contains the <code>user_id</code> and the <code>name</code> of the user. The <code>name</code> consists of <strong>only lowercase and uppercase</strong> characters.</p><blockquote><p>Write a solution to fix the names so that <strong>only the first character is uppercase</strong> and the <strong>rest are lowercase</strong>.<br>Return the result table <strong>ordered</strong> by <code>user_id</code>.<br>The result format is in the following example.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>We can split the tasks into three part.</p><ol><li>Split the name into <strong>first character</strong> and the <strong>remaining characters</strong> ‚Üí <code>SUBSTRING()</code></li><li>Modify them into <strong>upper case</strong> and <strong>lower case</strong> respectively ‚Üí <code>UPPER()</code> and <code>LOWER()</code></li><li>Order the result by <code>user_id</code> ‚Üí <code>ORDER BY</code></li></ol><h3 id="SQL-SUBSTRING-Function"><a href="#SQL-SUBSTRING-Function" class="headerlink" title="SQL SUBSTRING() Function"></a>SQL SUBSTRING() Function</h3><p>For extracting characters from a string, we can use the function <code>SUBSTRING(&lt;string&gt;, start, end)</code>.<br>For example,</p><pre><code class="sql">SUBSTRING(name, 1, 1)</code></pre><p>returns the first character from string <code>name</code>,<br>and <code>name</code> without the first letter.</p><pre><code class="sql">SUBSTRING(name, 2, LENGTH(name))</code></pre><h3 id="SQL-UPPER-LOWER-and-CONCAT"><a href="#SQL-UPPER-LOWER-and-CONCAT" class="headerlink" title="SQL UPPER(), LOWER(), and CONCAT()"></a>SQL UPPER(), LOWER(), and CONCAT()</h3><p>For text converting, we can simply use <code>UPPER(&lt;text&gt;)</code> and <code>LOWER(&lt;text&gt;)</code>.<br>Then we can combine two substring together by using</p><pre><code class="sql">CONCAT(&lt;string1&gt;, &lt;string2&gt;, ... , &lt;string_n&gt;)</code></pre><p>and finally, use <code>ORDER BY user_id</code>.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT user_id,   CONCAT(    UPPER(SUBSTRING(name, 1, 1)),     LOWER(SUBSTRING(name, 2, LENGTH(name)))  ) AS nameFROM UsersORDER BY user_id</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 1378. Replace Employee ID With The Unique Identifier</title>
      <link href="/LeetCode/sql50-1378/"/>
      <url>/LeetCode/sql50-1378/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Employees"><a href="#Table-name-Employees" class="headerlink" title="Table name: Employees"></a>Table name: <code>Employees</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">id</td><td align="left">int</td></tr><tr><td align="left">name</td><td align="left">varchar</td></tr></tbody></table><p>id is the primary key (column with unique values) for this table.<br>Each row of this table contains the id and the name of an employee in a company.</p><h3 id="Table-name-EmployeeUNI"><a href="#Table-name-EmployeeUNI" class="headerlink" title="Table name: EmployeeUNI"></a>Table name: <code>EmployeeUNI</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">id</td><td align="left">int</td></tr><tr><td align="left">unique_id</td><td align="left">int</td></tr></tbody></table><p>(<code>id</code>, <code>unique_id</code>) is the primary key (combination of columns with unique values) for this table.<br>Each row of this table contains the id and the corresponding unique id of an employee in the company.</p><blockquote><p>Write a solution to show the <code>unique ID</code> of each user,<br>If a user does not have a unique ID replace just show <strong>null</strong>.<br>Return the result table in any order.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>In this question, we need to use <code>JOIN</code>:</p><pre><code class="sql">FROM &lt;table1&gt;JOIN &lt;table2&gt; ON &lt;table1.column_n&gt; = &lt;table2.column_m&gt;</code></pre><p><code>JOIN</code> always comes with <code>ON</code>, which indicates the column used as a reference for joining.<br>Also, there are different types referring to different usage.</p><p><img src="/images/leetcode/sql50/sql_join.png"></p><p>We are trying to include <code>unique_id</code> to the table <code>Employees</code><br>Since we need to include every users even if they don‚Äôt have a unique ID, we need to use <code>LEFT JOIN</code>.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT EmployeeUNI.unique_id, Employees.name FROM Employees LEFT JOIN EmployeeUNI ON EmployeeUNI.id = Employees.id;</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 1683. Invalid Tweets</title>
      <link href="/LeetCode/sql50-1683/"/>
      <url>/LeetCode/sql50-1683/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Tweets"><a href="#Table-name-Tweets" class="headerlink" title="Table name: Tweets"></a>Table name: <code>Tweets</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">tweet_id</td><td align="left">int</td></tr><tr><td align="left">content</td><td align="left">varchar</td></tr></tbody></table><p><code>tweet_id</code> is the primary key (column with unique values) for this table.<br>This table contains all the tweets in a social media app.</p><blockquote><p>Write a solution to find the <code>IDs</code> of the <strong>invalid tweets</strong>.<br>The tweet is invalid if the <strong>number of characters</strong> used in the <code>content</code> of the tweet is <strong>strictly greater than 15</strong>.<br>Return the result table in any order.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>To check the number of character, we can use the <code>LENGTH(&lt;string&gt;)</code> function.</p><p>If you use this function on numbers (e.g. int), it will turn it into string and return <strong>number of digits</strong>.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT tweet_id FROM Tweets WHERE LENGTH(content)&gt;15;</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 1148. Article Views I</title>
      <link href="/LeetCode/sql50-1148/"/>
      <url>/LeetCode/sql50-1148/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Views"><a href="#Table-name-Views" class="headerlink" title="Table name: Views"></a>Table name: <code>Views</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">article_id</td><td align="left">int</td></tr><tr><td align="left">author_id</td><td align="left">int</td></tr><tr><td align="left">viewer_id</td><td align="left">int</td></tr><tr><td align="left">view_date</td><td align="left">date</td></tr></tbody></table><p>There is <strong>no primary key</strong> (column with unique values) for this table, the table may have duplicate rows.</p><p>Each row of this table indicates that some <code>viewer</code> viewed an article (written by some <code>author</code>) on some <code>date</code>.</p><p>Note that equal <code>author_id</code> and <code>viewer_id</code> indicate the same person.</p><blockquote><p>Write a solution to find all the <strong>authors</strong> that viewed <strong>at least one of their own articles</strong>.<br>Return the result table sorted by id in <strong>ascending order</strong>.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>We have two tasks:</p><ol><li>Authors viewed their own articles ‚Üí <code>WHERE author_id = viewer_id</code></li><li>Sort table by id in ascending order ‚Üí <code>ORDER BY author_id ASC</code></li></ol><h3 id="SQL-ORDER-BY"><a href="#SQL-ORDER-BY" class="headerlink" title="SQL ORDER BY"></a>SQL ORDER BY</h3><pre><code class="sql">ORDER BY &lt;column1&gt;, &lt;column2&gt;, ... ASC|DESC;</code></pre><p>By default, <code>ORDER BY</code> sort rows in <strong>ascending order</strong>.</p><p>And if there are multiple columns, sort the rows according to the first column, and then the second column when the rows contain same values in the first column and so on.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT distinct author_id AS id FROM Views WHERE author_id = viewer_id ORDER BY author_id ASC</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 595. Big Countries</title>
      <link href="/LeetCode/sql50-595/"/>
      <url>/LeetCode/sql50-595/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-World"><a href="#Table-name-World" class="headerlink" title="Table name: World"></a>Table name: <code>World</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">name</td><td align="left">varchar</td></tr><tr><td align="left">continent</td><td align="left">varchar</td></tr><tr><td align="left">area</td><td align="left">int</td></tr><tr><td align="left">population</td><td align="left">int</td></tr><tr><td align="left">gdp</td><td align="left">bigint</td></tr></tbody></table><p><code>name</code> is the primary key (column with unique values) for this table.</p><p>Each row of this table gives information about the name of a country,<br>the <code>continent</code> to which it belongs, its <code>area</code>, the <code>population</code>, and its <code>GDP value</code>.</p><h3 id="Big-Country"><a href="#Big-Country" class="headerlink" title="Big Country"></a>Big Country</h3><p>A country is <strong>big</strong> if:</p><ul><li>it has an <code>area</code> of <strong>at least three million</strong> (i.e., 3000000 km2), <strong>or</strong></li><li>it has a <code>population</code> of <strong>at least twenty-five million</strong> (i.e., 25000000).</li></ul><blockquote><p>Write a solution to find the <code>name</code>, <code>population</code>, and <code>area</code> of the <strong>big countries</strong>.<br>Return the result table in any order.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>Again we use <code>SELECT &lt;column_name&gt; FROM &lt;table_name&gt; WHERE &lt;conditions&gt;</code> to get the solution.</p><p>As question mention we should use <code>OR</code> and <strong>at least</strong> refers to <code>&gt;=</code>.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT name, population, area FROM World WHERE area &gt;= 3000000 OR population &gt;= 25000000;</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 584. Find Customer Referee</title>
      <link href="/LeetCode/sql50-584/"/>
      <url>/LeetCode/sql50-584/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Customer"><a href="#Table-name-Customer" class="headerlink" title="Table name: Customer"></a>Table name: <code>Customer</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">id</td><td align="left">int</td></tr><tr><td align="left">name</td><td align="left">varchar</td></tr><tr><td align="left">referee_id</td><td align="left">int</td></tr></tbody></table><p><code>id</code> is the <code>primary key column</code> for this table.<br>Each row of this table indicates the <code>id</code> of a customer, their <code>name</code>, and the <code>id of the customer who referred them</code>.</p><blockquote><p>Find the <strong>names</strong> of the customer that are <strong>not referred by the customer with id &#x3D; 2</strong>.<br>Return the result table in any order.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>Again we use <code>SELECT &lt;column_name&gt; FROM &lt;table_name&gt; WHERE &lt;conditions&gt;</code> to get the solution.</p><p>The tricky part is some of the <code>referee_id</code> may contain <code>NULL</code> value.</p><h3 id="NULL-handling"><a href="#NULL-handling" class="headerlink" title="NULL handling"></a>NULL handling</h3><p>We may simply think that the solution is</p><pre><code class="sql">WHERE referee_id !=2</code></pre><p>However, <code>NULL</code> <strong>always</strong> return <code>false</code> in any comparison. For example:</p><pre><code class="sql">SELECT *FROM CustomerWHERE referee_id != 2 OR referee_id = 2</code></pre><p>This query will return all rows that their <code>referee_id</code> is not <code>NULL</code>. Because <code>NULL</code> returns <code>false</code> in both cases.</p><p>In order to retrieve rows that contain <code>NULL</code>, we have to use the keyword <code>IS NULL</code>.</p><p>For further explaination of NULL Handling in SQL, you may check the <a href="https://www.sqlite.org/nulls.html">sqlite documentation</a></p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT &quot;name&quot; FROM Customer WHERE referee_id != 2 OR referee_id IS NULL;</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 -- 1757. Recyclable and Low Fat Products</title>
      <link href="/LeetCode/sql50-1757/"/>
      <url>/LeetCode/sql50-1757/</url>
      
        <content type="html"><![CDATA[<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Table-name-Products"><a href="#Table-name-Products" class="headerlink" title="Table name: Products"></a>Table name: <code>Products</code></h3><table><thead><tr><th align="left">Column Name</th><th align="left">Type</th></tr></thead><tbody><tr><td align="left">product_id</td><td align="left">int</td></tr><tr><td align="left">low_fats</td><td align="left">enum</td></tr><tr><td align="left">recyclable</td><td align="left">enum</td></tr></tbody></table><p><code>product_id</code> is the primary key (column with unique values) for this table.</p><p><code>low_fats</code> is an <code>ENUM</code> of type (<code>Y</code>, <code>N</code>) where <code>Y</code> means this product is low fat and <code>N</code> means it is not.</p><p><code>recyclable</code> is an <code>ENUM</code> of types (<code>Y</code>, <code>N</code>) where <code>Y</code> means this product is recyclable and <code>N</code> means it is not.</p><blockquote><p>Write a solution to <strong>find the ids</strong> of products that are <strong>both low fat and recyclable</strong>.<br>Return the result table in any order.</p></blockquote><h2 id="Explaination"><a href="#Explaination" class="headerlink" title="Explaination"></a>Explaination</h2><p>This is one the most basic SQL <code>SELECT</code> query scenario,<br>by using <code>SELECT &lt;column_name&gt; FROM &lt;table_name&gt; WHERE &lt;conditions&gt;</code> you may get the solution easily.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><pre><code class="sql">SELECT product_id FROM Products WHERE low_fats = &quot;Y&quot; AND recyclable = &quot;Y&quot;;</code></pre><hr><p>More SQL 50 questions: <a href="../sql50/">here</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode Walkthrough (Portal üö™)</title>
      <link href="/LeetCode/index/"/>
      <url>/LeetCode/index/</url>
      
        <content type="html"><![CDATA[<blockquote><p>This is a portal for my walkthroughs of Leetcode Questions</p></blockquote><h2 id="SQL-50"><a href="#SQL-50" class="headerlink" title="SQL 50"></a><a href="../sql50/">SQL 50</a></h2><p><a href="https://leetcode.com/studyplan/top-sql-50/">Question List on Leetcode</a></p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode SQL 50 (Portal üö™)</title>
      <link href="/LeetCode/sql50/"/>
      <url>/LeetCode/sql50/</url>
      
        <content type="html"><![CDATA[<blockquote><p>This is a portal for my walkthroughs of SQL 50 on Leetcode</p></blockquote><p><a href="https://leetcode.com/studyplan/top-sql-50/">Link of Leetcode SQL 50</a></p><table><thead><tr><th align="left">Select</th></tr></thead><tbody><tr><td align="left"><a href="../sql50-1757/">1757. Recyclable and Low Fat Products</a></td></tr><tr><td align="left"><a href="../sql50-584/">584. Find Customer Referee</a></td></tr><tr><td align="left"><a href="../sql50-595/">595. Big Countries</a></td></tr><tr><td align="left"><a href="../sql50-1148/">1148. Article Views I</a></td></tr><tr><td align="left"><a href="../sql50-1683/">1683. Invalid Tweets</a></td></tr></tbody></table><table><thead><tr><th align="left">Basic Joins</th></tr></thead><tbody><tr><td align="left"><a href="../sql50-1378/">1378. Replace Employee ID With The Unique Identifier</a></td></tr><tr><td align="left"><a href="../sql50-1068/">1068. Product Sales Analysis I</a></td></tr><tr><td align="left"><a href="../sql50-1581/">1581. Customer Who Visited but Did Not Make Any Transactions</a></td></tr><tr><td align="left"><a href="../sql50-197/">197. Rising Temperature</a></td></tr></tbody></table><table><thead><tr><th align="left">Advanced String Functions &#x2F; Regex &#x2F; Clause</th></tr></thead><tbody><tr><td align="left"><a href="../sql50-1667/">1667. Fix Names in a Table</a></td></tr><tr><td align="left"><a href="../sql50-1683/">1527. Patients With a Condition</a></td></tr><tr><td align="left"><a href="../sql50-196/">196. Delete Duplicate Emails</a></td></tr><tr><td align="left"><a href="../sql50-176/">176. Second Highest Salary</a></td></tr><tr><td align="left"><a href="../sql50-1484/">1484. Group Sold Products By The Date</a></td></tr><tr><td align="left"><a href="../sql50-1327/">1327. List the Products Ordered in a Period</a></td></tr><tr><td align="left"><a href="../sql50-1517/">1517. Find Users With Valid E-Mails</a></td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
          <category> SQL_50 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cantonese Ch.1-5 -- Rimes with u &amp; yu (Phonology)</title>
      <link href="/Canto/canto1-5/"/>
      <url>/Canto/canto1-5/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Golden Rule of becoming a native Cantonese speaker: <strong>Tones</strong> &gt; Everything!</p></blockquote><p>In this blog, we use <a href="https://jyutping.org/en/docs/english/">Jyutping</a> to indicate the pronunciation of Cantonese characters.</p><p>Previous lesson: <a href="../canto1-3/">Rimes with e</a></p><hr><p>In this lesson, we talk about Rimes with <code>u</code>, <code>yu</code>. Here we use <code>u</code> similar to languages like German or Italian.</p><p>And <code>yu</code> is equivalent to ‚Äú√º‚Äù in German. Let‚Äôs take a look.</p><h2 id="Rimes-with-u"><a href="#Rimes-with-u" class="headerlink" title="Rimes with u"></a>Rimes with <code>u</code></h2><p>For <code>u</code>, <code>ui</code>, <code>un</code>, <code>ut</code>, u sounds like ‚Äúoo‚Äù in ‚Äúfoo‚Äù.</p><p>For <code>ung</code> and <code>uk</code>, u sound like ‚Äúone‚Äù in ‚Äútone‚Äù.</p><table><thead><tr><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th></tr></thead><tbody><tr><td align="left">u</td><td align="left">oo in foo</td><td align="left"><ruby>Â§´<rp>(</rp><rt>fu1</rt><rp>)</rp></ruby></td><td align="left">ut</td><td align="left">oot in boot</td><td align="left"><ruby>Èóä<rp>(</rp><rt>fut3</rt><rp>)</rp></ruby></td></tr><tr><td align="left">ui</td><td align="left">ewy in chewy<sup>1</sup></td><td align="left"><ruby>ÁÅ∞<rp>(</rp><rt>fui1</rt><rp>)</rp></ruby></td><td align="left">ung</td><td align="left">one in tone</td><td align="left"><ruby>È¢®<rp>(</rp><rt>fung1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">un</td><td align="left">oon in cartoon</td><td align="left"><ruby>Ê≠°<rp>(</rp><rt>fun1</rt><rp>)</rp></ruby></td><td align="left">uk</td><td align="left">ook in cook</td><td align="left"><ruby>Á¶è<rp>(</rp><rt>fuk1</rt><rp>)</rp></ruby></td></tr></tbody></table><p><sup>1</sup>‚ÄúChewy‚Äù is two syllables, but in Cantonese this is a diphthong. So try to blend it into one sound, treat the ‚Äúew‚Äù as the major sound and the ‚Äúj‚Äù as a small tip at the end of the syllable.</p><h2 id="Rimes-with-yu"><a href="#Rimes-with-yu" class="headerlink" title="Rimes with yu"></a>Rimes with <code>yu</code></h2><p>Unfortunately, in English there is no word sound exactly as <code>yu</code>.</p><p>But you can imitate it by positioning your tongue more forward, closer to your front teeth (not touching them!), and try to say the word ‚Äúfoo‚Äù.</p><p>In some accents, when people say the word ‚Äúo<strong>ccu</strong>py‚Äù or ‚Äúe<strong>du</strong>cation‚Äù, they may use the <code>yu</code> sound as well.</p><table><thead><tr><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th></tr></thead><tbody><tr><td align="left">yu</td><td align="left">u in occupy</td><td align="left"><ruby>Êõ∏<rp>(</rp><rt>syu1</rt><rp>)</rp></ruby></td><td align="left">yut</td><td align="left">uned in tuned</td><td align="left"><ruby>Èõ™<rp>(</rp><rt>syut3</rt><rp>)</rp></ruby></td></tr><tr><td align="left">yun</td><td align="left">une in tune</td><td align="left"><ruby>ÈÖ∏<rp>(</rp><rt>syun1</rt><rp>)</rp></ruby></td><td align="left"></td><td align="left"></td><td align="left"></td></tr></tbody></table><h2 id="Learn-a-new-word-before-you-move-on"><a href="#Learn-a-new-word-before-you-move-on" class="headerlink" title="Learn a new word before you move on"></a>Learn a new word before you move on</h2><p>You may already know that <ruby>Â§öË¨ù<rp>(</rp><rt>do1 ze6</rt><rp>)</rp></ruby> means <strong>Thank you</strong>, but you can take one step further!</p><p>Try to use <ruby>ÊÑüÊøÄ‰∏çÊ∫ñ<rp>(</rp><rt>gam2 gik1 bat1 zeon2</rt><rp>)</rp></ruby> or simply <ruby>Â§öË¨ùÊõ¨<rp>(</rp><rt>do1 ze6 saai3</rt><rp>)</rp></ruby> to show your appreciation.</p><p>You can use it in many scenario, and politeness is always the key to success.</p><p>So again‚Ä¶ <ruby>‰∏ãÊ¨°Ë¶ã<rp>(</rp><rt>haa6 ci3 gin3</rt><rp>)</rp></ruby>!</p><p>Next lesson: <a href="../canto1-6/">Tones</a></p><hr><p>Further reading: <a href="https://jyutping.org/en/">Jyutping</a>, <a href="https://lshk.org/">The linguistic Society of Hong Kong</a></p>]]></content>
      
      
      <categories>
          
          <category> Cantonese </category>
          
          <category> Full_Course </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cantonese </tag>
            
            <tag> Language Learning </tag>
            
            <tag> Phonology </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cantonese Ch.1-4 -- Rimes with i &amp; o (Phonology)</title>
      <link href="/Canto/canto1-4/"/>
      <url>/Canto/canto1-4/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Golden Rule of becoming a native Cantonese speaker: <strong>Tones</strong> &gt; Everything!</p></blockquote><p>In this blog, we use <a href="https://jyutping.org/en/docs/english/">Jyutping</a> to indicate the pronunciation of Cantonese characters.</p><p>Previous lesson: <a href="../canto1-3/">Rimes with e</a></p><hr><p>In this lesson, we talk about Rimes with <code>i</code> and <code>o</code>. Both are pretty intuitive for English speakers.</p><h2 id="Rimes-with-i"><a href="#Rimes-with-i" class="headerlink" title="Rimes with i"></a>Rimes with <code>i</code></h2><p>For <code>i</code>, <code>iu</code>, <code>im</code>, <code>in</code>, <code>ip</code>, <code>it</code>, i sounds like ‚Äúyee‚Äù. For example, ‚Äúee‚Äù in ‚Äúsee‚Äù or ‚Äúkeen‚Äù.</p><p>For <code>ing</code> and <code>ik</code>, i sound like ‚Äúegg‚Äù. For example, ‚Äúi‚Äù in ‚Äúignore‚Äù or ‚Äúsing‚Äù.</p><table><thead><tr><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th></tr></thead><tbody><tr><td align="left">i</td><td align="left">ee in see</td><td align="left"><ruby>ÊÄù<rp>(</rp><rt>si1</rt><rp>)</rp></ruby></td><td align="left">ip</td><td align="left">eep in weep</td><td align="left"><ruby>Êîù<rp>(</rp><rt>sip3</rt><rp>)</rp></ruby></td></tr><tr><td align="left">iu</td><td align="left">eal in seal</td><td align="left"><ruby>Ááí<rp>(</rp><rt>siu1</rt><rp>)</rp></ruby></td><td align="left">it</td><td align="left">eet in meet</td><td align="left"><ruby>Ëàå<rp>(</rp><rt>sit3</rt><rp>)</rp></ruby></td></tr><tr><td align="left">im</td><td align="left">eam in beam</td><td align="left"><ruby>ÈñÉ<rp>(</rp><rt>sim2</rt><rp>)</rp></ruby></td><td align="left">ing</td><td align="left">ing in sing</td><td align="left"><ruby>Âçá<rp>(</rp><rt>sing1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">in</td><td align="left">een in seen</td><td align="left"><ruby>ÂÖà<rp>(</rp><rt>sin1</rt><rp>)</rp></ruby></td><td align="left">ik</td><td align="left">ic in acidic</td><td align="left"><ruby>Ë≠ò<rp>(</rp><rt>sik1</rt><rp>)</rp></ruby></td></tr></tbody></table><h2 id="Rimes-with-o"><a href="#Rimes-with-o" class="headerlink" title="Rimes with o"></a>Rimes with <code>o</code></h2><p>Every Rime with <code>o</code> sounds like ‚Äúoy‚Äù in ‚Äújoy‚Äù or ‚Äúahoy‚Äù.</p><p>Except for <code>ou</code>, it sounds more like ‚Äúoh‚Äù. For example, ‚Äúou‚Äù in ‚Äúsoul‚Äù.</p><table><thead><tr><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th></tr></thead><tbody><tr><td align="left">o</td><td align="left">ee in see</td><td align="left"><ruby>ÂèØ<rp>(</rp><rt>ho2</rt><rp>)</rp></ruby></td><td align="left">ot</td><td align="left">ought in thought</td><td align="left"><ruby>Ê∏¥<rp>(</rp><rt>hot3</rt><rp>)</rp></ruby></td></tr><tr><td align="left">oi</td><td align="left">oy in joy</td><td align="left"><ruby>Èñã<rp>(</rp><rt>hoi1</rt><rp>)</rp></ruby></td><td align="left">ok</td><td align="left">orch in orchestra</td><td align="left"><ruby>Â≠∏<rp>(</rp><rt>hok6</rt><rp>)</rp></ruby></td></tr><tr><td align="left">on</td><td align="left">on in gone</td><td align="left"><ruby>Áúã<rp>(</rp><rt>hon3</rt><rp>)</rp></ruby></td><td align="left">ou</td><td align="left">ou in soul</td><td align="left"><ruby>Â•Ω<rp>(</rp><rt>hou2</rt><rp>)</rp></ruby></td></tr><tr><td align="left">ong</td><td align="left">ong in long</td><td align="left"><ruby>Â∫∑<rp>(</rp><rt>hong1</rt><rp>)</rp></ruby></td><td align="left"></td><td align="left"></td><td align="left"></td></tr></tbody></table><h2 id="Learn-a-new-word-before-you-move-on"><a href="#Learn-a-new-word-before-you-move-on" class="headerlink" title="Learn a new word before you move on"></a>Learn a new word before you move on</h2><p>Excuse me, it‚Äôs time for your daily dose of Cantonese vocab!</p><ruby>ÂîîÂ•ΩÊÑèÊÄù<rp>(</rp><rt>m4 hou2 ji3 si1</rt><rp>)</rp></ruby>, which means **Excuse me**!<p>You can use it in many scenario, and politeness is always the key to success.</p><p>So again‚Ä¶ <ruby>‰∏ãÊ¨°Ë¶ã<rp>(</rp><rt>haa6 ci3 gin3</rt><rp>)</rp></ruby>!</p><p>Next lesson: <a href="../canto1-5/">Rimes with u</a></p><hr><p>Further reading: <a href="https://jyutping.org/en/">Jyutping</a>, <a href="https://lshk.org/">The linguistic Society of Hong Kong</a></p>]]></content>
      
      
      <categories>
          
          <category> Cantonese </category>
          
          <category> Full_Course </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cantonese </tag>
            
            <tag> Language Learning </tag>
            
            <tag> Phonology </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cantonese Ch.1-3 -- Rimes with e (Phonology)</title>
      <link href="/Canto/canto1-3/"/>
      <url>/Canto/canto1-3/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Golden Rule of becoming a native Cantonese speaker: <strong>Tones</strong> &gt; Everything!</p></blockquote><p>In this blog, we use <a href="https://jyutping.org/en/docs/english/">Jyutping</a> to indicate the pronunciation of Cantonese characters.</p><p>Previous lesson: <a href="../canto1-2/">Rimes with a &amp; aa</a></p><h2 id="All-Rimes-with-e"><a href="#All-Rimes-with-e" class="headerlink" title="All Rimes with e"></a>All Rimes with <code>e</code></h2><p>In this lesson, we talk about Rimes with <code>e</code>. e is a very naughty sound because it has multiple sounds based on how you spell it.</p><p>Also, e can combine with o to create <code>oe</code> and <code>eo</code> sounds.</p><h3 id="Rimes-with-e"><a href="#Rimes-with-e" class="headerlink" title="Rimes with e"></a>Rimes with <code>e</code></h3><table><thead><tr><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th></tr></thead><tbody><tr><td align="left">e</td><td align="left">ai in pair</td><td align="left"><ruby>‰∫õ<rp>(</rp><rt>se1</rt><rp>)</rp></ruby></td><td align="left">eng</td><td align="left">eng in leng<sup>2</sup></td><td align="left"><ruby>ÈÑ≠<rp>(</rp><rt>zeng6</rt><rp>)</rp></ruby></td></tr><tr><td align="left">ei</td><td align="left">ey in prey</td><td align="left"><ruby>Âõõ<rp>(</rp><rt>sei3</rt><rp>)</rp></ruby></td><td align="left">ep</td><td align="left">ep in bicep</td><td align="left"><ruby>Â§æ<rp>(</rp><rt>gaap3</rt><rp>)</rp></ruby></td></tr><tr><td align="left">eu</td><td align="left">eil in veil</td><td align="left"><ruby>Êéâ<rp>(</rp><rt>diu6</rt><rp>)</rp></ruby></td><td align="left">et</td><td align="left">et in pet</td><td align="left"><ruby>Âù∫<rp>(</rp><rt>paat6</rt><rp>)</rp></ruby></td></tr><tr><td align="left">em</td><td align="left">em in gem</td><td align="left"><ruby>Ëàî<rp>(</rp><rt>tim2</rt><rp>)</rp></ruby></td><td align="left">ek</td><td align="left">ek in trek</td><td align="left"><ruby>Áü≥<rp>(</rp><rt>sek6</rt><rp>)</rp></ruby></td></tr></tbody></table><p>We can see most of them are the same as e pronounced in English.</p><h3 id="Rimes-with-oe-and-eo"><a href="#Rimes-with-oe-and-eo" class="headerlink" title="Rimes with oe and eo"></a>Rimes with <code>oe</code> and <code>eo</code></h3><p><code>oe</code> and <code>eo</code> sound very similar. They were considered the same sound before, but soon linguists found that this sound behaved differently and had different consonances.<br>Therefore, they are split for specific use cases. For example, if there‚Äôs an <code>eoi</code> sound, there won‚Äôt be a <code>oei</code> sound.</p><table><thead><tr><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th></tr></thead><tbody><tr><td align="left">oe</td><td align="left">ur in fur</td><td align="left"><ruby>Èã∏<rp>(</rp><rt>goe3</rt><rp>)</rp></ruby></td><td align="left">eoi</td><td align="left">an in France but ends with ng not n</td><td align="left"><ruby>Ë°∞<rp>(</rp><rt>seoi1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">oeng</td><td align="left">ern in cern<sup>2</sup></td><td align="left"><ruby>Ëñë<rp>(</rp><rt>goeng1</rt><rp>)</rp></ruby></td><td align="left">eon</td><td align="left">alm in calm with p instead</td><td align="left"><ruby>Ë©¢<rp>(</rp><rt>seon1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">oek</td><td align="left">erk in berserk</td><td align="left"><ruby>ËÖ≥<rp>(</rp><rt>goek3</rt><rp>)</rp></ruby></td><td align="left">eot</td><td align="left">alm in calm with t instead</td><td align="left"><ruby>Êëî<rp>(</rp><rt>seot1</rt><rp>)</rp></ruby></td></tr></tbody></table><p><sup>1</sup><a href="https://www.google.com/search?q=leng+meaning">meaning of ‚Äúleng‚Äù</a></p><p><sup>2</sup> Obviously, the <code>oeng</code> sound should have a ‚Äúg‚Äù sound, so precisely, it should sound like ‚Äúcaring.‚Äù Here, the ‚Äúng‚Äù is similar to the ‚Äúng‚Äù in ‚Äúsing.‚Äù</p><h2 id="Learn-a-new-word-before-you-move-on"><a href="#Learn-a-new-word-before-you-move-on" class="headerlink" title="Learn a new word before you move on"></a>Learn a new word before you move on</h2><p>Let‚Äôs continue with greetings, how to impress your Hong Kong friend that you haven‚Äôt seen for so long, by showing your Cantonese skills?</p><p>You may say <ruby>Â•ΩËÄêÁÑ°Ë¶ã<rp>(</rp><rt>hou2 noi6 mou4 gin3</rt><rp>)</rp></ruby>, which means <strong>Long time no see</strong>!</p><p>Fun fact is, long time no see may acutally come from Cantonese users, who try to do direct translate from cantonese to english.</p><p>So again‚Ä¶ <ruby>‰∏ãÊ¨°Ë¶ã<rp>(</rp><rt>haa6 ci3 gin3</rt><rp>)</rp></ruby>!</p><p>Next lesson: <a href="../canto1-4/">Rimes with i &amp; o</a></p><hr><p>Further reading: <a href="https://jyutping.org/en/">Jyutping</a>, <a href="https://lshk.org/">The linguistic Society of Hong Kong</a></p>]]></content>
      
      
      <categories>
          
          <category> Cantonese </category>
          
          <category> Full_Course </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cantonese </tag>
            
            <tag> Language Learning </tag>
            
            <tag> Phonology </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cantonese Ch.1-2 -- Rimes with a &amp; aa (Phonology)</title>
      <link href="/Canto/canto1-2/"/>
      <url>/Canto/canto1-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Golden Rule of becoming a native Cantonese speaker: <strong>Tones</strong> &gt; Everything!</p></blockquote><p>In this blog, we use <a href="https://jyutping.org/en/docs/english/">Jyutping</a> to indicate the pronunciation of Cantonese characters.</p><p>Previous lesson: <a href="../canto1-1/">Introduction</a></p><h2 id="Recap-of-Rimes"><a href="#Recap-of-Rimes" class="headerlink" title="Recap of Rimes"></a>Recap of Rimes</h2><p>Rimes is a syllable of vowels with consonants that you can <strong>rhyme</strong>!</p><p>For example, in English, the Rime of ‚ÄúCow‚Äù is ‚Äúow‚Äù; in Cantonese, cow is <ruby>Áâõ<rp>(</rp><rt>ngau4</rt><rp>)</rp></ruby>, and the Rime is ‚Äúau‚Äù.</p><h2 id="Difference-of-a-and-aa"><a href="#Difference-of-a-and-aa" class="headerlink" title="Difference of a and aa"></a>Difference of <code>a</code> and <code>aa</code></h2><p>Two vowels in Cantonese start with a. <code>a</code> sounds like ‚Äúuh‚Äù in English, and <code>aa</code> ‚Äúahhh‚Äù in English.</p><p>And all their combinations as well. For example, <ruby>ÂàÜ<rp>(</rp><rt>fan1</rt><rp>)</rp></ruby> sounds like ‚Äúfun‚Äù, and <ruby>È£Ø<rp>(</rp><rt>faan6</rt><rp>)</rp></ruby> sounds like ‚Äúfran‚Äù in France without ‚Äúr‚Äù sound.</p><p>Still, it may be difficult to distinguish their difference when they form rimes with other sounds.</p><p>A trick to pronounce any combinations of the <code>aa</code> sound is to try to add the ‚Äúahhh‚Äù sound before <code>a</code>.<br>For example, <code>ap</code> sounds like ‚Äúup‚Äù in English, and <code>aap</code> sounds like ‚Äúahh-up‚Äù in one syllable.</p><p>Let‚Äôs see all the rimes combinations with <code>a</code> and <code>aa</code>!</p><h3 id="Rimes-with-a"><a href="#Rimes-with-a" class="headerlink" title="Rimes with a"></a>Rimes with <code>a</code></h3><table><thead><tr><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th></tr></thead><tbody><tr><td align="left">a</td><td align="left">uh in bruh</td><td align="left"><ruby>Âòû<rp>(</rp><rt>laa3</rt><rp>)</rp></ruby></td><td align="left">ang</td><td align="left">ung in sung</td><td align="left"><ruby>Â¢û<rp>(</rp><rt>zang1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">ai</td><td align="left">i in night</td><td align="left"><ruby>Êì†<rp>(</rp><rt>zai1</rt><rp>)</rp></ruby></td><td align="left">ap</td><td align="left">up in cup</td><td align="left"><ruby>Ê±Å<rp>(</rp><rt>zap1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">au</td><td align="left">ull in dull</td><td align="left"><ruby>Âë®<rp>(</rp><rt>zau1</rt><rp>)</rp></ruby></td><td align="left">at</td><td align="left">utt in butt</td><td align="left"><ruby>Ë≥™<rp>(</rp><rt>zat1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">am</td><td align="left">um in sum</td><td align="left"><ruby>Èáù<rp>(</rp><rt>zam1</rt><rp>)</rp></ruby></td><td align="left">ak</td><td align="left">uck in duck</td><td align="left"><ruby>Ââá<rp>(</rp><rt>zak1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">an</td><td align="left">un in fun</td><td align="left"><ruby>Áèç<rp>(</rp><rt>zan1</rt><rp>)</rp></ruby></td><td align="left"></td><td align="left"></td><td align="left"></td></tr></tbody></table><h3 id="Rimes-with-aa"><a href="#Rimes-with-aa" class="headerlink" title="Rimes with aa"></a>Rimes with <code>aa</code></h3><table><thead><tr><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th></tr></thead><tbody><tr><td align="left">aa</td><td align="left">a in far</td><td align="left"><ruby>Ê∏£<rp>(</rp><rt>zaa1</rt><rp>)</rp></ruby></td><td align="left">aang</td><td align="left">an in France but ends with ng not n</td><td align="left"><ruby>Áà≠<rp>(</rp><rt>zang1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">aai</td><td align="left">i in high</td><td align="left"><ruby>ÈΩã<rp>(</rp><rt>zaai1</rt><rp>)</rp></ruby></td><td align="left">aap</td><td align="left">alm in calm with p instead</td><td align="left"><ruby>ÈõÜ<rp>(</rp><rt>zaap6</rt><rp>)</rp></ruby></td></tr><tr><td align="left">aau</td><td align="left">ow in wow</td><td align="left"><ruby>Âò≤<rp>(</rp><rt>zaau1</rt><rp>)</rp></ruby></td><td align="left">aat</td><td align="left">alm in calm with t instead</td><td align="left"><ruby>Á¥Æ<rp>(</rp><rt>zaat3</rt><rp>)</rp></ruby></td></tr><tr><td align="left">aam</td><td align="left">alm in calm</td><td align="left"><ruby>Á´ô<rp>(</rp><rt>zaam6</rt><rp>)</rp></ruby></td><td align="left">aak</td><td align="left">alm in calm with k instead</td><td align="left"><ruby>Á™Ñ<rp>(</rp><rt>zaak3</rt><rp>)</rp></ruby></td></tr><tr><td align="left">aan</td><td align="left">an in France</td><td align="left"><ruby>ËÆö<rp>(</rp><rt>zaan3</rt><rp>)</rp></ruby></td><td align="left"></td><td align="left"></td><td align="left"></td></tr></tbody></table><h2 id="Learn-a-new-word-before-you-move-on"><a href="#Learn-a-new-word-before-you-move-on" class="headerlink" title="Learn a new word before you move on"></a>Learn a new word before you move on</h2><p>In Cantonese, <ruby>Êó©Êäñ<rp>(</rp><rt>zou2 tau2</rt><rp>)</rp></ruby> will be another most common thrase you may hear, which means <strong>good night</strong>.</p><p>Its literally meaning is sleep early, it is a good wish because nowadays people sleep quite late right?</p><p>So again‚Ä¶ <ruby>‰∏ãÊ¨°Ë¶ã<rp>(</rp><rt>haa6 ci3 gin3</rt><rp>)</rp></ruby>!</p><p>Next lesson: <a href="../canto1-3/">Rimes with e</a></p><hr><p>Further reading: <a href="https://jyutping.org/en/">Jyutping</a>, <a href="https://lshk.org/">The linguistic Society of Hong Kong</a></p>]]></content>
      
      
      <categories>
          
          <category> Cantonese </category>
          
          <category> Full_Course </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cantonese </tag>
            
            <tag> Language Learning </tag>
            
            <tag> Phonology </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cantonese Ch.1-1 -- Onset (Phonology)</title>
      <link href="/Canto/canto1-1/"/>
      <url>/Canto/canto1-1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Golden Rule of becoming a native Cantonese speaker: <strong>Tones</strong> &gt; Everything!</p></blockquote><p>In this blog, we use <a href="https://jyutping.org/en/docs/english/">Jyutping</a> to indicate the pronunciation of Cantonese characters.</p><p>Previous lesson: <a href="../canto1-0/">Introduction</a></p><h2 id="Introduction-of-Onset"><a href="#Introduction-of-Onset" class="headerlink" title="Introduction of Onset"></a>Introduction of Onset</h2><p>In this lesson, We start with <code>Onset</code>. They are all <code>consonants</code> that are used before vowels.</p><p>For example, ‚Äúgood morning‚Äù in Cantonese is <ruby>Êó©Êô®<rp>(</rp><rt>zou2 san4</rt><rp>)</rp></ruby>, where ‚Äúz‚Äù and ‚Äús‚Äù are Onset here.</p><h2 id="Onset"><a href="#Onset" class="headerlink" title="Onset"></a>Onset</h2><p>Basically, these consonant looks identical, or you may find alternative spelling in English, except<br><code>kw</code>, <code>z</code>, and <code>c</code> might be a little unique.</p><table><thead><tr><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th><th align="left">Jyutping</th><th align="left">Sounds in English</th><th align="left">Cantonese Example</th></tr></thead><tbody><tr><td align="left">-</td><td align="left">character that have no starting consonant (Null initial)</td><td align="left"><ruby>ÂëÄ<rp>(</rp><rt>aa3</rt><rp>)</rp></ruby></td><td align="left">k</td><td align="left">k in king</td><td align="left"><ruby>Âç°<rp>(</rp><rt>kaa1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">b</td><td align="left">b in bar</td><td align="left"><ruby>Â∑¥<rp>(</rp><rt>baa1</rt><rp>)</rp></ruby></td><td align="left">ng</td><td align="left">ng in sing</td><td align="left"><ruby>Áâô<rp>(</rp><rt>ngaa4</rt><rp>)</rp></ruby></td></tr><tr><td align="left">p</td><td align="left">p in palm</td><td align="left"><ruby>ÊÄï<rp>(</rp><rt>paa3</rt><rp>)</rp></ruby></td><td align="left">h</td><td align="left">h in harp</td><td align="left"><ruby>Ëù¶<rp>(</rp><rt>haa1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">m</td><td align="left">m in mat</td><td align="left"><ruby>Â™Ω<rp>(</rp><rt>maa1</rt><rp>)</rp></ruby></td><td align="left">gw</td><td align="left">gu in guava</td><td align="left"><ruby>Áìú<rp>(</rp><rt>gwaa1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">f</td><td align="left">f in foul</td><td align="left"><ruby>Ëä±<rp>(</rp><rt>faa1</rt><rp>)</rp></ruby></td><td align="left">kw</td><td align="left">qu in aqua</td><td align="left"><ruby>Ë™á<rp>(</rp><rt>kwaa1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">d</td><td align="left">d in dip<sup>1</sup></td><td align="left"><ruby>Êâì<rp>(</rp><rt>daa2</rt><rp>)</rp></ruby></td><td align="left">w</td><td align="left">w in wow</td><td align="left"><ruby>Ëõô<rp>(</rp><rt>waa1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">t</td><td align="left">t in tip<sup>1</sup></td><td align="left"><ruby>‰ªñ<rp>(</rp><rt>taa1</rt><rp>)</rp></ruby></td><td align="left">z</td><td align="left"><strong>j</strong> in job but with a ‚Äòt‚Äô sound in front of it<sup>2</sup></td><td align="left"><ruby>Êè∏<rp>(</rp><rt>zaa1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">n</td><td align="left">n in nap</td><td align="left"><ruby>ÈÇ£<rp>(</rp><rt>naa5</rt><rp>)</rp></ruby></td><td align="left">c</td><td align="left">c in chat<sup>2</sup> without ‚Äòh‚Äô sound</td><td align="left"><ruby>Âèâ<rp>(</rp><rt>caa1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">l</td><td align="left">l in lap</td><td align="left"><ruby>Âï¶<rp>(</rp><rt>laa1</rt><rp>)</rp></ruby></td><td align="left">s</td><td align="left">s in soup</td><td align="left"><ruby>Ê≤ô<rp>(</rp><rt>saa1</rt><rp>)</rp></ruby></td></tr><tr><td align="left">g</td><td align="left">g in gum</td><td align="left"><ruby>ÂÆ∂<rp>(</rp><rt>gaa1</rt><rp>)</rp></ruby></td><td align="left">j</td><td align="left"><strong>y</strong> in yes<sup>3</sup></td><td align="left"><ruby>‰πü<rp>(</rp><rt>jaa5</rt><rp>)</rp></ruby></td></tr></tbody></table><p><sup>1</sup>If you are a native English speaker, you may notice that the Cantonese ‚Äúd‚Äù sound is softer than in English, but the ‚Äút‚Äù sound is more challenging (the difference is negligible here). But if you have a problem pronouncing this pair, try to make your tongue touch the upper front teeth when creating the ‚Äúd‚Äù and ‚Äút‚Äù sounds.</p><p><sup>2</sup>In Cantonese, ‚Äúc‚Äù and ‚Äúz‚Äù are clear sounds without aspirated. You can try to not stress your lip and open your mouth wider.</p><p><sup>3</sup>In most European languages, ‚Äúj‚Äù sounds like ‚Äúy‚Äù in English. For example, ‚Äúja‚Äù in German. Therefore, Jyutping chose ‚Äúj‚Äù to represent this sound.</p><h2 id="Learn-a-new-word-before-you-move-on"><a href="#Learn-a-new-word-before-you-move-on" class="headerlink" title="Learn a new word before you move on"></a>Learn a new word before you move on</h2><p>In Cantonese, <strong>bye bye</strong> will be the most common way to say goodbye.</p><p>But you may also say <ruby>ÂÜçË¶ã<rp>(</rp><rt>zoi3 gin3</rt><rp>)</rp></ruby>Ôºå which means <strong>see you</strong>.</p><p>or you may say <ruby>‰∏ãÊ¨°Ë¶ã<rp>(</rp><rt>haa6 ci3 gin3</rt><rp>)</rp></ruby> which means <strong>see you next time</strong>!</p><p>So‚Ä¶ <ruby>‰∏ãÊ¨°Ë¶ã<rp>(</rp><rt>haa6 ci3 gin3</rt><rp>)</rp></ruby>!</p><p>Next lesson: <a href="../canto1-2/">Rimes with a &amp; aa</a></p><hr><p>Further reading: <a href="https://jyutping.org/en/">Jyutping</a>, <a href="https://lshk.org/">The linguistic Society of Hong Kong</a></p>]]></content>
      
      
      <categories>
          
          <category> Cantonese </category>
          
          <category> Full_Course </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cantonese </tag>
            
            <tag> Language Learning </tag>
            
            <tag> Phonology </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cantonese Ch.1-0 -- Introduction to Phonology &amp; Tones</title>
      <link href="/Canto/canto1-0/"/>
      <url>/Canto/canto1-0/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Golden Rule of becoming a native Cantonese speaker: <strong>Tones</strong> &gt; Everything!</p></blockquote><p>In this blog, we use <a href="https://jyutping.org/en/docs/english/">Jyutping</a> to indicate the pronunciation of Cantonese characters.</p><h2 id="Overview-of-Cantonese-Phonology"><a href="#Overview-of-Cantonese-Phonology" class="headerlink" title="Overview of Cantonese Phonology"></a>Overview of Cantonese Phonology</h2><p>Maybe you already know that we use one syllable for each character in Cantonese,<br>just like all other Chinese languages. It contains 3 crucial parts in order to pronounce the word.<br>That is the <code>consonances</code>, <code>vowels</code>, and <code>tones</code>.</p><p>In Cantonese, there are <strong>19</strong> consonances, <strong>9</strong> vowels and <strong>6</strong> tones.<br>That creates <strong>1,760</strong> different sounds to cover over 10,000 Chinese Characters.</p><p>Every Cantonese consonance and vowel pair can always be described as an <code>Onset-Rime</code>.</p><h3 id="Phonology-Structure"><a href="#Phonology-Structure" class="headerlink" title="Phonology Structure"></a>Phonology Structure</h3><p>So what is actually an <code>Onset-Rimes</code>?<br>An <code>Onset-Rimes</code> is either a <code>consonant-vowel</code> or a <code>consonant-vowel-consonant</code> structure, For example:</p><ul><li><p><code>consonant-vowel</code>: the word ‚Äúrich‚Äù &#x3D; <ruby>ÂØå<rp>(</rp><rt>fu3</rt><rp>)</rp></ruby> (sounds like ‚Äúfoo‚Äù in English).</p></li><li><p><code>consonant-vowel-consonant</code>: the word ‚Äúbamboo‚Äù &#x3D; <ruby>Á´π<rp>(</rp><rt>zuk1</rt><rp>)</rp></ruby> (sounds like ‚Äújoke‚Äù in English).</p></li></ul><h3 id="Tones"><a href="#Tones" class="headerlink" title="Tones"></a>Tones</h3><p>Tones are a unique feature of the Chinese language; in Cantonese, it is slightly more fancy than in Mandarin.<br>But don‚Äôt worry, in this Chapter, we will break it down and make it easy for you!</p><p><img src="/images/canto/canto-tone.png"></p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>So today, we‚Äôve learned the structure of Cantonese, and know that it contains Onsets, Rimes, and Tones.<br>It‚Äôs time to learn your first Cantonese phrase!</p><p>In Cantonese, the most common greeting we use is <strong>Good Morning</strong>, that is <ruby>Êó©Êô®<rp>(</rp><rt>zou2 san4</rt><rp>)</rp></ruby>!</p><p>zou2 san4‚Ä¶ How do we pronounce the ‚Äúz‚Äù sound? Now, let‚Äôs move on to the next lesson for <code>Onset</code>!</p><p>Portal:</p><ul><li><a href="../canto1-1/">Chapter 0-1: Onset</a></li><li><a href="../canto1-2/">Chapter 0-2: Rimes with a &amp; aa</a></li><li><a href="../canto1-3/">Chapter 0-3: Rimes with e</a></li><li><a href="../canto1-4/">Chapter 0-4: Rimes with i &amp; o</a></li><li><a href="../canto1-5/">Chapter 0-5: Rimes with u &amp; yu</a></li><li><a href="../canto1-6/">Chapter 0-6: Tones</a></li><li><a href="../canto1-7/">Chapter 0-7: Onset, Rimes and Tones (Summary)</a></li></ul><hr><p>Further reading: <a href="https://jyutping.org/en/">Jyutping</a>, <a href="https://lshk.org/">The linguistic Society of Hong Kong</a></p>]]></content>
      
      
      <categories>
          
          <category> Cantonese </category>
          
          <category> Full_Course </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cantonese </tag>
            
            <tag> Language Learning </tag>
            
            <tag> Phonology </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo-zhruby -- Implementing HTML Ruby tag in Hexo</title>
      <link href="/hexo-zhruby/"/>
      <url>/hexo-zhruby/</url>
      
        <content type="html"><![CDATA[<p>Implement the HTML tag <code>&lt;ruby&gt;</code> for Hexo using <a href="https://hexo.io/docs/tag-plugins">Tag Plugin</a> feature. Provide auto pronounciation indication for Jyutping (Cantonese), Zhuyin (Taiwanese Mandarin), and Pinyin (Chinese Mandarin), and the default setting for general usage. Support Traditonal and Simplified Chinese characters. </p><p>Inspired by the <a href="https://github.com/jamespan/hexo-ruby-character">hexo-ruby-character</a> by <a href="https://github.com/jamespan">jamespan</a>.</p><h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><pre><code>npm install hexo-zhruby --save</code></pre><h2 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h2><p>Ruby („É´„Éì) is also known as <a href="https://en.wikipedia.org/wiki/Furigana">Furigana</a> (ÊåØ„Çä‰ªÆÂêç).  It contains two basic use cases:</p><ol><li>To clarify or indicate the pronunciation for readers</li><li><a href="https://en.wikipedia.org/wiki/Kanji#Special_readings">Gikun</a>, in which the characters have different pronunciations than they seem due to convention or for a specific context. For example, the pronunciation of ÁÖôËçâ in Japanese is <em>tabako (tobacco)</em>.</li></ol><h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p><strong>TLDR</strong>: Usage: <code>&#123;% tag rb|rt %&#125;</code>; Tag options: <code>ruby_def</code>, <code>ruby_jy</code>, <code>ruby_py</code>, <code>ruby_zy</code>.</p><hr><h3 id="For-the-1st-use-case-pronunciation-indication"><a href="#For-the-1st-use-case-pronunciation-indication" class="headerlink" title="For the 1st use case (pronunciation indication):"></a>For the 1st use case (pronunciation indication):</h3><p><code>ruby_def</code> allows any language, and the spacing in <code>rp</code> will expand evenly with respect to the word length in <code>rt</code>.</p><ul><li><code>&#123;% ruby_def Âü∫Êú¨|„Åç„Åª„Çì %&#125;</code> ‚Üí <ruby>Âü∫Êú¨<rp> (</rp><rt>„Åç„Åª„Çì</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_def Âü∫Êú¨|Í∏∞Î≥∏ %&#125;</code> ‚Üí <ruby>Âü∫Êú¨<rp> (</rp><rt>Í∏∞Î≥∏</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_def Âü∫Êú¨|fundamental %&#125;</code> ‚Üí <ruby>Âü∫Êú¨<rp> (</rp><rt>fundamental</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_def Âü∫Êú¨|Œ∏ŒµŒºŒµŒªŒπœéŒ¥ŒµœÇ %&#125;</code> ‚Üí <ruby>Âü∫Êú¨<rp> (</rp><rt>Œ∏ŒµŒºŒµŒªŒπœéŒ¥ŒµœÇ</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_def Âü∫Êú¨|–±–∞–∑–æ–≤—ã–π %&#125;</code> ‚Üí <ruby>Âü∫Êú¨<rp> (</rp><rt>–±–∞–∑–æ–≤—ã–π</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_def Âü∫Êú¨|z√°kladn√≠ %&#125;</code> ‚Üí <ruby>Âü∫Êú¨<rp> (</rp><rt>z√°kladn√≠</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_def fundamental|Âü∫Êú¨ %&#125;</code> ‚Üí <ruby>fundamental<rp> (</rp><rt>Âü∫Êú¨</rt><rp>)</li></ul><p><code>ruby_jy</code>, <code>ruby_py</code>, <code>ruby_zy</code> refers to <strong>Jyutping</strong>, <strong>Pinyin</strong>, <strong>Zhuyin</strong> respectively. </p><p>No need to enter the pronunciation manually in <code>rt</code>; the value will automatically be returned.</p><ul><li><code>&#123;% ruby_zy Âü∫Êú¨ %&#125;</code> ‚Üí <ruby>Âü∫Êú¨<rp> (</rp><rt>„Ñê„Ñß „ÑÖ„Ñ£Àá</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_py Âü∫Êú¨ %&#125;</code> ‚Üí <ruby>Âü∫Êú¨<rp> (</rp><rt>jƒ´ bƒõn</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_jy Âü∫Êú¨ %&#125;</code> ‚Üí <ruby>Âü∫Êú¨<rp> (</rp><rt>gei1 bun2</rt><rp>) </rp></ruby></li></ul><hr><h3 id="For-the-2nd-use-case-Gikun"><a href="#For-the-2nd-use-case-Gikun" class="headerlink" title="For the 2nd use case (Gikun):"></a>For the 2nd use case (Gikun):</h3><p>Same usage for <code>ruby_def</code>.</p><ul><li><code>&#123;% ruby_def special|basic %&#125;</code> ‚Üí <ruby>special<rp> (</rp><rt>basic</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_def ÁâπÂà•|Âü∫Êú¨ %&#125;</code> ‚Üí <ruby>ÁâπÂà•<rp> (</rp><rt>Âü∫Êú¨</rt><rp>)</li></ul><p>In <code>ruby_jy</code>, <code>ruby_py</code>, <code>ruby_zy</code>, you can also add <code>|rt</code> just like <code>ruby_def</code>.</p><ul><li><code>&#123;% ruby_zy ÁâπÂà•|special %&#125;</code> ‚Üí <ruby>ÁâπÂà•<rp> (</rp><rt>special</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_py ÁâπÂà•|special %&#125;</code> ‚Üí <ruby>ÁâπÂà•<rp> (</rp><rt>special</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_jy ÁâπÂà•|special %&#125;</code> ‚Üí <ruby>ÁâπÂà•<rp> (</rp><rt>special</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_zy ÁâπÂà•|Âü∫Êú¨ %&#125;</code> ‚Üí <ruby>ÁâπÂà•<rp> (</rp><rt>„Ñê„Ñß „ÑÖ„Ñ£Àá</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_py ÁâπÂà•|Âü∫Êú¨ %&#125;</code> ‚Üí <ruby>ÁâπÂà•<rp> (</rp><rt>jƒ´ bƒõn</rt><rp>) </rp></ruby></li><li><code>&#123;% ruby_jy ÁâπÂà•|Âü∫Êú¨ %&#125;</code> ‚Üí <ruby>ÁâπÂà•<rp> (</rp><rt>gei1 bun2</rt><rp>) </rp></ruby></li></ul><p>Notice that the <code>rt</code> output depends on the pronunciation in <code>rt,</code> but <strong>not</strong> <code>rp.</code> This feature is only available when <code>rt</code> is a <strong>Chinese Character</strong> in <a href="https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)">CJK Unified Ideographs</a> (\U4E00-\U9FFF).</p><p>If the input of <code>rt</code> is not in CJK Unified Ideographs, it is considered as <code>ruby_def</code>.</p><h2 id="Known-issues"><a href="#Known-issues" class="headerlink" title="Known issues"></a>Known issues</h2><p>The Chinese language contains a lot of <strong>Homophones</strong>, which can be resolved by context most of the time. However, for long sentences (&gt;&#x3D; 15 characters), or very specific names and terms, the auto-generation from 1st use case may not be very sensitive.</p><p>Please use <code>ruby_def</code> if it happens or contribute to this project by providing a more sensitive or advanced Chinese vocabulary library.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://en.wikipedia.org/wiki/CJK_characters">CJK Unified Ideographs (Unicode block)</a></li><li><a href="https://en.wikipedia.org/wiki/Homophone">Homophone</a></li><li><a href="https://en.wiktionary.org/wiki/%E7%BE%A9%E8%A8%93#Japanese">Gikun (japanese only)</a></li><li><a href="https://en.wikipedia.org/wiki/Kanji#Special_readings">Gikun (English version under the article Kanji)</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/ruby">&lt;ruby&gt;: The Ruby Annotation element</a></li><li><a href="https://en.wikibooks.org/wiki/Unicode/Character_reference">Unicode&#x2F;Character reference</a></li><li><a href="https://en.wikipedia.org/wiki/Universal_Character_Set_characters">Universal Character Set characters (Unicode)</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Node.js </tag>
            
            <tag> HTML </tag>
            
            <tag> Cantonese </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Using Hexo Plugin functions to create a custom Tag Plugin</title>
      <link href="/hexo-tagplugin-2/"/>
      <url>/hexo-tagplugin-2/</url>
      
        <content type="html"><![CDATA[<p><strong>Disclaimer</strong>: For explaination on <code>Tag Plugin</code> and <code>Scripts</code> in Hexo, you may take a look of <a href="../hexo-tagplugin-1">this post</a>.</p><h2 id="Plugin"><a href="#Plugin" class="headerlink" title="Plugin"></a>Plugin</h2><blockquote><p>Be Careful! Don‚Äôt mix <code>Plugin</code>, <code>Tag</code>, and <code>Tag Plugin</code> in Hexo, even though they look extremely similar.</p></blockquote><p>Usually, <code>Plugin</code> are for complicated functions. Yet if you want to publish your custom <code>Tag Plugin</code> to the NPM registry or even shown on the Hexo Community Page, <code>Plugin</code> would be a very good choice.</p><h3 id="From-Script-to-Plugin"><a href="#From-Script-to-Plugin" class="headerlink" title="From Script to Plugin"></a>From Script to Plugin</h3><p>Assume you already have a script call <code>index.js</code>, and you want to turn it into package, you may do the following:</p><ol><li><p>Navigate <code>node_modules</code> folder in your project folder. This is the folder where Hexo stored all the packages for your blog. Create a folder inside and the name must begin with <code>hexo-</code> or Hexo will ignore it.</p></li><li><p>Your folder must contain at least two files: the actual JavaScript code and <code>package.json</code> file that describes the purpose of the plugin and sets its dependencies.</p><pre><code class="directory">.‚îú‚îÄ‚îÄ index.js‚îî‚îÄ‚îÄ package.json</code></pre></li><li><p>In <code>package.json</code>, it should at least have the <code>name</code>, <code>version</code> and <code>main</code> entries set.</p><pre><code class="json">&#123;    &quot;name&quot;: &quot;hexo-my-plugin&quot;,    &quot;version&quot;: &quot;0.0.1&quot;,    &quot;main&quot;: &quot;index&quot;&#125;</code></pre></li><li><p>In the root <code>package.json</code> of your hexo project, you also need to list your <code>plugin</code> as a <code>dependency</code>, for Hexo to detect and load it.<br> Please remember that if your package contain other dependencies, also install and list them for testing and dubugging.</p><pre><code class="json">&#123;    &quot;name&quot;: &quot;hexo-site&quot;,    &quot;version&quot;: &quot;0.0.0&quot;,    &quot;private&quot;: true,    &quot;scripts&quot;: &#123;        &quot;build&quot;: &quot;hexo generate&quot;,        &quot;clean&quot;: &quot;hexo clean&quot;,        &quot;deploy&quot;: &quot;hexo deploy&quot;,        &quot;server&quot;: &quot;hexo server&quot;    &#125;,    &quot;hexo&quot;: &#123;        &quot;version&quot;: &quot;&quot;    &#125;,    &quot;dependencies&quot;: &#123;        &quot;hexo&quot;: &quot;^7.3.0&quot;,        ...        &quot;hexo-my-plugin&quot;: &quot;0.0.1&quot;,        &quot;my-plugin-dependency1&quot;: &quot;2.0.0&quot;,        &quot;my-plugin-dependency2&quot;: &quot;2.0.0&quot;    &#125;&#125;</code></pre></li></ol><blockquote><p>If you run command that check all the package after step 4, for exmaple <code>hexo clean</code>, it will check all the packages in <code>node_modules</code> and remove packages that are not publish on npm.</p></blockquote><h2 id="Publish-Plugin-to-npm"><a href="#Publish-Plugin-to-npm" class="headerlink" title="Publish Plugin to npm"></a>Publish Plugin to npm</h2><p>To publish your package on the NPM registry, don‚Äôt forget you have to setup your account on <a href="https://www.npmjs.com/">npm</a> first.</p><p>After creating the account, open your terminal and run <code>npm login</code> in the root of your package. </p><p>Enter your <code>username</code> and <code>password</code>, then you should see a message like this if login is successful,</p><pre><code class="cmd">Logged in as &lt;your-username&gt; on https://registry.npmjs.org/.</code></pre><p>Once you logged-in, you may simply publish your folder with <code>npm publish</code> command.</p><h2 id="Publish-Plugin-to-Hexo"><a href="#Publish-Plugin-to-Hexo" class="headerlink" title="Publish Plugin to Hexo"></a>Publish Plugin to Hexo</h2><p>After publish your plugin package in npm, you can also publish it to Hexo official.</p><h3 id="Fork-and-Clone"><a href="#Fork-and-Clone" class="headerlink" title="Fork and Clone"></a>Fork and Clone</h3><p>First of all, <code>Fork</code> <a href="https://github.com/hexojs/site">hexojs&#x2F;site</a> from Github</p><p><img src="/images/coding/hexo_plugin/fork.png"></p><p>Then <code>Clone</code> the repository to your computer and install dependencies.</p><pre><code class="cmd">$ git clone https://github.com/&lt;username&gt;/site.git$ cd site$ npm install</code></pre><h3 id="Add-your-Plugin-to-the-list"><a href="#Add-your-Plugin-to-the-list" class="headerlink" title="Add your Plugin to the list"></a>Add your Plugin to the list</h3><p>Create a new yaml file in <code>source/_data/plugins/</code>, use your plugin name as the file name</p><p>Edit <code>source/_data/plugins/&lt;your-plugin-name&gt;.yml</code> and add your plugin. For example:</p><p><img src="/images/coding/hexo_plugin/plugin_yml.png"></p><h3 id="Push-the-branch"><a href="#Push-the-branch" class="headerlink" title="Push the branch"></a>Push the branch</h3><p>Create a pull request and describe the change. Hexo official create a nice form to make sure you have included everything needed.</p><p><img src="/images/coding/hexo_plugin/pull_form.png"></p><p><img src="/images/coding/hexo_plugin/pull_req.png"></p><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>You may check the progress on the pull requests history.<br>Once it is closed you can see your plugin on the Hexo Plugins Community.</p><p><img src="/images/coding/hexo_plugin/pull_closed.png"></p><p><img src="/images/coding/hexo_plugin/hexo_list.png"></p><h2 id="Example-work"><a href="#Example-work" class="headerlink" title="Example work"></a>Example work</h2><p>As you may see, I also made my Plugin ‚ÄúHexo-zhruby‚Äù for Hexo and you can now see it on the community.<br>For more details and see how it works, you may check <a href="../hexo-zhruby/">here</a>.</p><hr><p>Further Reading:</p><ul><li><a href="https://hexo.io/docs/plugins">Hexo Plugins and Scripts</a></li><li><a href="https://hexo.io/docs/tag-plugins">Hexo Tag Plugins</a></li><li><a href="https://hexo.io/plugins/">Hexo Plugins Community</a></li><li><a href="https://docs.npmjs.com/cli/v8/commands/npm-publish">npm-publish</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Coding </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Node.js </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Using Hexo Scripts functions to create a custom Tag Plugin</title>
      <link href="/hexo-tagplugin-1/"/>
      <url>/hexo-tagplugin-1/</url>
      
        <content type="html"><![CDATA[<p>To color your personal Hexo Blog with more features, scripts and plugins are your powerful tools to use. Below we are trying to create our own <code>tag plugin</code> for the Hexo blog.</p><h2 id="Tag-Plugin"><a href="#Tag-Plugin" class="headerlink" title="Tag Plugin"></a>Tag Plugin</h2><blockquote><p>Be careful! Tag plugins are different from <a href="https://hexo.io/docs/front-matter">post tags</a>.</p></blockquote><p>Tag plugins are special type of syntax that you may use in your Markdown file. </p><p>Hexo has already provided some default Tag plugins like <code>Block Quote</code> and <code>iframe</code>.</p><h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><p>For example, the syntax of <code>iframe</code> tag is:</p><pre><code class="Markdown">&#123;% iframe url [width] [height] %&#125;</code></pre><p>Let say I want to embed a video from me and my friends‚Äô YouTube video:</p><pre><code class="Markdown">&#123;% iframe https://www.youtube.com/embed/XIOl6BU7s9I?si=yTYsHIXNM6o-Zl9Z 820 461%&#125;</code></pre><p>And that‚Äôs how it looks like:</p><iframe src="https://www.youtube.com/embed/XIOl6BU7s9I?si=yTYsHIXNM6o-Zl9Z" width="820" height="461" frameborder="0" loading="lazy" allowfullscreen></iframe><h2 id="Script"><a href="#Script" class="headerlink" title="Script"></a>Script</h2><p>Let say we want to create our own tag plugin, we can use the Hexo <code>script</code> function. Here‚Äôre the steps.</p><ol><li><p>Create a JavaScript file with function <code>hexo.extend.tag.register(&quot;tag_name&quot;, args)</code>. You may also put your own function inside so that the second argument can also be <code>function (args)&#123;&#125;</code></p><p> Here is an example of a function that create a tag named <code>youtube</code>, with embedding video function:</p><pre><code class="JavaScript">hexo.extend.tag.register(&quot;youtube&quot;, function (args) &#123;    var id = args[0];    return (        &#39;&lt;div class=&quot;video-container&quot;&gt;&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;http://www.youtube.com/embed/&#39; +        id +        &#39;&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&#39;    );&#125;);</code></pre></li><li><p>Put your JavaScript files in the <code>scripts</code> folder. If your project folder is new, you may not be able to find it. This is because <code>scripts</code> folder is actually under the <code>Themes</code> folder.</p><p> You may check <a href="https://hexo.io/docs/themes">here</a> to see the structure of <code>themes</code> and create your own one. Or you may be simply find a template on the <a href="https://hexo.io/themes/">Hexo themes community</a> then put your <code>.js</code> file into the theme.</p></li><li><p>It is done! Hexo will load them during initialization and you may use them in your blog post designs.</p></li></ol><h3 id="Beyond-Scripts"><a href="#Beyond-Scripts" class="headerlink" title="Beyond Scripts"></a>Beyond Scripts</h3><p>If you are not satisfied with creating a local tag plugin, but a public one that will be seen by the community, you should consider using Hexo <code>plugin</code> function instead.</p><p>check <a href="../hexo-tagplugin-2">here</a> to continue the journey.</p><hr><p>Further Reading:</p><ul><li><a href="https://hexo.io/docs/plugins">Hexo Plugins and Scripts</a></li><li><a href="https://hexo.io/docs/tag-plugins">Hexo Tag Plugins</a></li><li><a href="https://hexo.io/api/tag">Hexo Tag Api</a></li><li><a href="https://hexo.io/plugins/">Hexo Plugins Community</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Coding </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Node.js </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Railroad Diagram of version range operators</title>
      <link href="/json-dependencies-diagram/"/>
      <url>/json-dependencies-diagram/</url>
      
        <content type="html"><![CDATA[<blockquote><p>This is a image version of the post <a href="../json-dependencies/">here</a></p></blockquote><p><a name="range-set"></a></p><p><strong>range-set:</strong><br><img src="/images/coding/json_dep_diagram/range-set.png" alt="range-set"></p><pre><code class="EBNF">range-set   ::= range ( logical-or range )*</code></pre><p><strong>logical-or:</strong></p><p><img src="/images/coding/json_dep_diagram/logical-or.png" alt="logical-or"></p><pre><code class="EBNF">logical-or  ::= &#39; &#39;* &#39;||&#39; &#39; &#39;*</code></pre><p>referenced by: <a href="#range-set">range-set</a></p><p><a name="range"></a></p><p><strong>range:</strong></p><p><img src="/images/coding/json_dep_diagram/range.png" alt="range"></p><pre><code class="EBNF">range   ::= hyphen           | simple ( &#39; &#39; simple )*           | &#39;&#39;</code></pre><p>referenced by: <a href="#range-set">range-set</a></p><p><a name="hyphen"></a></p><p><strong>hyphen:</strong></p><p><img src="/images/coding/json_dep_diagram/hyphen.png" alt="hyphen"></p><pre><code class="EBNF">hyphen   ::= partial &#39; - &#39; partial</code></pre><p>referenced by: <a href="#range">range</a></p><p><a name="simple"></a></p><p><strong>simple:</strong></p><p><img src="/images/coding/json_dep_diagram/simple.png" alt="simple"></p><pre><code class="EBNF">simple   ::= primitive           | partial           | tilde           | caret</code></pre><p>referenced by: <a href="#range">range</a></p><p><a name="primitive"></a></p><p><strong>primitive:</strong></p><p><img src="/images/coding/json_dep_diagram/primitive.png" alt="primitive"></p><pre><code class="EBNF">primitive   ::= ( &#39;&lt;&#39; | &#39;&gt;&#39; | &#39;&gt;=&#39; | &#39;&lt;=&#39; | &#39;=&#39; ) partial</code></pre><p>referenced by: <a href="#simple">simple</a></p><p><a name="partial"></a></p><p><strong>partial:</strong></p><p><img src="/images/coding/json_dep_diagram/partial.png" alt="partial"></p><pre><code class="EBNF">partial  ::= xr ( &#39;.&#39; xr ( &#39;.&#39; xr qualifier? )? )?</code></pre><p>referenced by:</p><ul><li><a href="#caret">caret</a></li><li><a href="#hyphen">hyphen</a></li><li><a href="#primitive">primitive</a></li><li><a href="#simple">simple</a></li><li><a href="#tilde">tilde</a></li></ul><p><a name="xr"></a></p><p><strong>xr:</strong></p><p><img src="/images/coding/json_dep_diagram/xr.png" alt="xr"></p><pre><code class="EBNF">xr    ::= &#39;x&#39;        | &#39;X&#39;        | &#39;*&#39;        | nr</code></pre><p>referenced by: <a href="#partial">partial</a></p><p><a name="nr"></a></p><p><strong>nr:</strong></p><p><img src="/images/coding/json_dep_diagram/nr.png" alt="nr"></p><pre><code class="EBNF">nr    ::= &#39;0&#39;        | [&#39;1&#39;-&#39;9] [&#39;0&#39;-&#39;9]*</code></pre><p>referenced by:</p><ul><li><a href="#part">part</a></li><li><a href="#xr">xr</a></li></ul><p><a name="tilde"></a></p><p><strong>tilde:</strong></p><p><img src="/images/coding/json_dep_diagram/tilde.png" alt="tilde"></p><pre><code class="EBNF">tilde    ::= &#39;~&#39; partial</code></pre><p>referenced by: <a href="#simple">simple</a></p><p><a name="caret"></a></p><p><strong>caret:</strong></p><p><img src="/images/coding/json_dep_diagram/caret.png" alt="caret"></p><pre><code class="EBNF">caret    ::= &#39;^&#39; partial</code></pre><p>referenced by: <a href="#simple">simple</a></p><p><a name="qualifier"></a></p><p><strong>qualifier:</strong></p><p><img src="/images/coding/json_dep_diagram/qualifier.png" alt="qualifier"></p><pre><code class="EBNF">qualifier   ::= ( &#39;-&#39; pre )? ( &#39;+&#39; build )?</code></pre><p>referenced by: <a href="#partial">partial</a></p><p><a name="pre"></a></p><p><strong>pre:</strong></p><p><img src="/images/coding/json_dep_diagram/pre.png" alt="pre"></p><pre><code class="EBNF">pre     ::= parts</code></pre><p>referenced by: <a href="#qualifier">qualifier</a></p><p><a name="build"></a></p><p><strong>build:</strong></p><p><img src="/images/coding/json_dep_diagram/build.png" alt="build"></p><pre><code class="EBNF">build   ::= parts</code></pre><p>referenced by: <a href="#qualifier">qualifier</a></p><p><a name="parts"></a></p><p><strong>parts:</strong></p><p><img src="/images/coding/json_dep_diagram/parts.png" alt="parts"></p><pre><code class="EBNF">parts   ::= part ( &#39;.&#39; part )*</code></pre><p>referenced by:</p><ul><li><a href="#build">build</a></li><li><a href="#pre">pre</a></li></ul><p><a name="part"></a></p><p><strong>part:</strong></p><pre><code class="EBNF">part    ::= nr | [-0-9A-Za-z]+</code></pre><p><img src="/images/coding/json_dep_diagram/part.png" alt="part"></p><hr><p>generated by <a href="https://www.bottlecaps.de/rr/ui">RR - Railroad Diagram Generator</a></p>]]></content>
      
      
      <categories>
          
          <category> Coding </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Node.js </tag>
            
            <tag> json </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Explaination of version range operators in package.json for package dependencies</title>
      <link href="/json-dependencies/"/>
      <url>/json-dependencies/</url>
      
        <content type="html"><![CDATA[<blockquote><p>To see the syntax and Railroad diagram version, goto <a href="../json-dependencies-diagram/">here</a></p></blockquote><h2 id="Basic-Structure"><a href="#Basic-Structure" class="headerlink" title="Basic Structure"></a>Basic Structure</h2><p>Package dependecies are a tuple of <code>[major, minor, patch]</code> with numeric values.</p><pre><code class="json">&#123;    &quot;name&quot;: &quot;project name&quot;,    &quot;version&quot;: &quot;0.0.1&quot;,    &quot;description&quot;: &quot;description of the project&quot;,    &quot;keywords&quot;: [        &quot;keyword 1&quot;,        &quot;keyword 2&quot;    ],    &quot;author&quot;: &quot;John Doe&quot;,    &quot;dependencies&quot;: &#123;      &quot;package-1&quot;: &quot;~0.6.2&quot;,      &quot;package-2&quot;: &quot;&gt;=2.6.2&quot;    &#125;&#125;</code></pre><h2 id="Version-Range-operator"><a href="#Version-Range-operator" class="headerlink" title="Version Range operator"></a>Version Range operator</h2><h3 id="Basic-Range"><a href="#Basic-Range" class="headerlink" title="Basic Range"></a>Basic Range</h3><p>For <code>x</code> in exmaple, see <strong>Advanced Range</strong> below.</p><table><thead><tr><th align="left">Operator</th><th align="left">Explaination</th><th align="left">Example</th></tr></thead><tbody><tr><td align="left"><code>=</code></td><td align="left">package version must be exactly matched</td><td align="left"><code>1.0.0</code> :&#x3D; <code>=1.0.0</code><br>(They are equivalent)</td></tr><tr><td align="left"><code>&lt;</code></td><td align="left">package version must be less than indicated</td><td align="left"><code>&lt;2.0.0</code> <br>:&#x3D;version from <code>0.0.1</code> to <code>1.x.x</code></td></tr><tr><td align="left"><code>&lt;=</code></td><td align="left">package version must be less than or euqal to indicated</td><td align="left"><code>&lt;=2.0.0</code> <br>:&#x3D;version from <code>0.0.1</code> to <code>2.0.0</code></td></tr><tr><td align="left"><code>&gt;</code></td><td align="left">package version must be greater than indicated</td><td align="left"><code>&gt;2.0.0</code>:&#x3D; <br>version from <code>2.0.1</code> to <code>x</code> (x &gt;&#x3D; 2)</td></tr><tr><td align="left"><code>&gt;=</code></td><td align="left">package version must be greater than or euqal to indicated</td><td align="left"><code>&gt;=2.0.0</code> <br>:&#x3D;version from <code>2.0.0</code> to <code>x</code> (x &gt;&#x3D; 2)</td></tr><tr><td align="left"><code>||</code></td><td align="left">joined one or more operator</td><td align="left"><code>&gt;2.0.1 || &lt;1.7.3</code> <br>:&#x3D;version greater than <code>2.0.1</code> or less than <code>1.7.3</code></td></tr><tr><td align="left"><code>space</code></td><td align="left">Intersected one or more operator</td><td align="left"><code>&gt;=2.0.1  &lt;=1.7.3</code> <br>:&#x3D;version from <code>2.0.1</code> to <code>1.7.3</code> (inclusive)</td></tr></tbody></table><h3 id="Advanced-Range"><a href="#Advanced-Range" class="headerlink" title="Advanced Range"></a>Advanced Range</h3><p>Advanced ranges may be combined in the same way as primitive comparators using <code>space</code> or <code>||</code>.</p><table><thead><tr><th align="left">Operator</th><th align="left">Explaination</th><th align="left">Example</th></tr></thead><tbody><tr><td align="left"><code>X</code>, <code>x</code>, <code>*</code></td><td align="left">A Wildcard may be used for any values in the <code>[major, minor, patch]</code> tuple (missing value are consider using Wildcard <code>x</code>)</td><td align="left"><code>*</code> :&#x3D; <code> </code><em>(empty string)</em> :&#x3D; <code>&gt;=0.0.0</code><br><code>1.x.x</code> :&#x3D; <code>1.x</code> :&#x3D; <code>1</code> :&#x3D; <code>&gt;=1.0.0 &lt;2.0.0</code></td></tr><tr><td align="left"><code>-</code></td><td align="left">Specifies an inclusive set of package version</td><td align="left"><code>1.2 - 2.3.4</code> :&#x3D; <code>&gt;=1.2.0 &lt;=2.3.4</code> <br>(missing pieces of first version are replaced with zeroes)<br><code>1.2.3 - 2.3</code> :&#x3D; <code>&gt;=1.2.3 &lt;2.4.x</code><br>(missing pieces of second version replace with <code>X-range</code>)</td></tr><tr><td align="left"><code>~</code></td><td align="left">Allows <code>patch</code> or <code>minor</code> level version changes, depends on specification</td><td align="left"><code>~1.2.3</code> :&#x3D; any version starts with <code>1.2</code> and greater than <code>1.2.3</code><br><code>~1.2</code> :&#x3D; any version starts with <code>1.2</code> (same as <code>1.2.x</code>)</td></tr><tr><td align="left"><code>^</code></td><td align="left">Allows version changes in the <code>[major, minor, patch]</code> tuple without modify the <strong>left-most non-zero</strong> element.</td><td align="left"><code>^1.2.3</code> :&#x3D; <code>&gt;=1.2.3 &lt;2.0.0</code><br>(minor update)<br><code>^0.2.3</code> :&#x3D; <code>&gt;=0.2.3 &lt;0.3.0</code> <br>(patch update)<br><code>^0.0.3</code> :&#x3D; <code>&gt;=0.0.3 &lt;0.0.4</code><br>(no updates)</td></tr></tbody></table><h2 id="Further-Explaination-on-Caret-Ranges"><a href="#Further-Explaination-on-Caret-Ranges" class="headerlink" title="Further Explaination on Caret Ranges ^"></a>Further Explaination on Caret Ranges <code>^</code></h2><h3 id="Special-interaction-with-Wildcard-operator-x"><a href="#Special-interaction-with-Wildcard-operator-x" class="headerlink" title="Special interaction with Wildcard operator x"></a>Special interaction with Wildcard operator <code>x</code></h3><p>When parsing caret ranges, minor and patch values with wildcard <code>x</code> desugars to the number <code>0</code> (missing values are consider as <code>x</code>):</p><p>Example:</p><ul><li><code>^1.2.x</code> :&#x3D; <code>&gt;=1.2.0 &lt;2.0.0-0</code> (equivalent to <code>^1.2.0</code>)</li><li><code>^1.x</code> :&#x3D; <code>&gt;=1.0.0 &lt;2.0.0-0</code> (equivalent to <code>^1.0.0</code>)</li></ul><p>However, when both <code>major</code> and <code>minor</code> versions are <code>0</code>, Caret range allow flexibility within wildcard <code>x</code>:</p><p>Example:</p><ul><li><code>^0.0.x</code> :&#x3D; <code>&gt;=0.0.0 &lt;0.1.0-0</code> (<strong>NOT</strong> equivalent to <code>^0.0.0</code>, but similar to <code>^0.1.0</code>)</li></ul><h3 id="Usage-and-Common-Practices"><a href="#Usage-and-Common-Practices" class="headerlink" title="Usage and Common Practices"></a>Usage and Common Practices</h3><p>Caret ranges usually ideally used when an author may make breaking changes. For example, between <code>0.2.4</code> and <code>0.3.0</code> releases, which is a common practice. </p><p>However, it presumes that there will not be breaking changes between <code>0.2.4</code> and <code>0.2.5</code>. It allows for changes that are presumed to be additive (but non-breaking), according to commonly observed practices.</p><hr><p>Further Reading: <a href="https://github.com/npm/node-semver#ranges">version range</a> in npm-semver, <a href="https://github.com/actions/setup-node#supported-version-syntax">setup-node</a> in GitHub Actions</p>]]></content>
      
      
      <categories>
          
          <category> Coding </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Node.js </tag>
            
            <tag> json </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Why you shouldn&#39;t deploy your Hexo webpage using GitHub Desktop?</title>
      <link href="/github-desktop/"/>
      <url>/github-desktop/</url>
      
        <content type="html"><![CDATA[<h2 id="Methods-to-Deploy-Hexo-to-GitHub-io"><a href="#Methods-to-Deploy-Hexo-to-GitHub-io" class="headerlink" title="Methods to Deploy Hexo to GitHub.io"></a>Methods to Deploy Hexo to GitHub.io</h2><p>Assume you‚Äôve created a repository on GitHub called <code>&lt;username&gt;.github.io</code>. Here are two common method you can deploy you Hexo Blog:</p><h3 id="Hexo-Command"><a href="#Hexo-Command" class="headerlink" title="Hexo Command"></a>Hexo Command</h3><p>Hexo‚Äôs documentations and Tutorial has provided sufficient instructions on deploying your personal website on your GitHub repository.</p><p>According to the <a href="https://hexo.io/docs/github-pages">Hexo Tutorial</a>, we can deploy the repository by using <a href="https://docs.github.com/en/actions">GitHub Actions</a>.</p><ol><li><p>Create and Add the following contents to <code>.github/workflows/pages.yml</code>:</p><pre><code class="yml">name: Pageson:push:    branches:    - main # default branchjobs:build:    runs-on: ubuntu-latest    steps:    - uses: actions/checkout@v4        with:        token: $&#123;&#123; secrets.GITHUB_TOKEN &#125;&#125;        submodules: recursive    - name: Use Node.js 20        uses: actions/setup-node@v4        with:        # Examples: 20, 18.19, &gt;=16.20.2, lts/Iron, lts/Hydrogen, *, latest, current, node        # Ref: https://github.com/actions/setup-node#supported-version-syntax        node-version: &quot;&gt;=20&quot;     - name: Cache NPM dependencies        uses: actions/cache@v4        with:        path: node_modules        key: $&#123;&#123; runner.OS &#125;&#125;-npm-cache        restore-keys: |            $&#123;&#123; runner.OS &#125;&#125;-npm-cache    - name: Install Dependencies        run: npm install    - name: Build        run: npm run build    - name: Upload Pages artifact        uses: actions/upload-pages-artifact@v3        with:        path: ./publicdeploy:    needs: build    permissions:    pages: write    id-token: write    environment:    name: github-pages    url: $&#123;&#123; steps.deployment.outputs.page_url &#125;&#125;    runs-on: ubuntu-latest    steps:    - name: Deploy to GitHub Pages        id: deployment        uses: actions/deploy-pages@v4</code></pre></li><li><p>Install <code>hexo-deployer-git</code>.</p></li><li><p>Add&#x2F;Change the following configurations to <code>_config.yml</code>:</p><pre><code class="yml">deploy:type: gitrepo: https://github.com/&lt;username&gt;/&lt;project&gt;# for example, this blog is https://github.com/greenmeeple/greenmeeple.github.iobranch: gh-pages</code></pre></li><li><p>After finishing your bog posts, Run <code>hexo clean &amp;&amp; hexo deploy</code>.</p></li></ol><h3 id="GitHub-Desktop"><a href="#GitHub-Desktop" class="headerlink" title="GitHub Desktop"></a>GitHub Desktop</h3><p>Many Users installed <a href="https://desktop.github.com/download/">GitHub Desktop</a> for better visualization on changes, so do I. It provides more intuitive push and commit procedure and instruction compared to terminal. Most of the time I use it to make sure no unexpected line changes or modification.</p><p><img src="/images/site_notes/github_desktop.png"></p><p>But soon I noticed that, every time after running <code>hexo clean &amp;&amp; hexo deploy</code>, GitHub Desktop will warn me that there‚Äôs something need to be pulled. When I pull it for merging it return <code>Unable to merge unrelated histories in repository</code>. Even in the image above, it shows that I should pull something. However, how would I need to pull if I‚Äôve just push it?</p><h2 id="Security-Problem"><a href="#Security-Problem" class="headerlink" title="Security Problem"></a>Security Problem</h2><p>So I inspect my repository, these two method actually deploy <strong>completely different</strong> content to the repository, even though they output the identical content on the webpage.</p><p>When you deploy you webpage with Hexo command, it actually creates a folder <code>.deploy_git</code>, which is static HTML content without showing any configurations like your <code>themes</code> folder or <code>_config.yml</code> folder. In contrast, GitHub Desktop solely commit all folder that is not in <code>.gitignore</code> file and the website just rendered dynamically in the repository when someone visit.</p><p>This create a huge security problem as much as it seems. All contents in your config is now visible to everyone. Since Hexo is a simple framework that depends heavily on <a href="https://daringfireball.net/projects/markdown/">Markdown</a> and <code>.yml</code> files, there‚Äôs on where to hide all your settings and <code>&lt;script&gt;</code> if they just directly commit to your repository before building it statically. This may include not only your SEO and functionality of your webiste, but even some secret variable.</p><h3 id="GitTalk-comment-section-and-GitHub-OAUTH"><a href="#GitTalk-comment-section-and-GitHub-OAUTH" class="headerlink" title="GitTalk comment section and GitHub OAUTH"></a>GitTalk comment section and GitHub OAUTH</h3><p>For example, the comment section below every posts in this blog are powered by <a href="https://github.com/gitalk/gitalk">GitTalk</a>. It requires users to login through GitHub to comment. In order to handle the authorization of login, blog owners need to create an <a href="https://docs.github.com/en/apps/oauth-apps/building-oauth-apps/creating-an-oauth-app">OAUTH App</a>. Then they need to input their <code>clientID</code> and <code>clientSecret</code> initiate the plugin. For Hexo file structure, this will usually be stored in <code>_config.yml</code>.</p><p>Therefore, if Blog Owner simply commit the whole folder using GitHub Desktop, their OAUTH App credentials are leaked to everyone. And this is how I start noticing the two deploy methods above are so different.</p><h2 id="Saving-your-sensitive-information-from-Data-Leak"><a href="#Saving-your-sensitive-information-from-Data-Leak" class="headerlink" title="Saving your sensitive information from Data Leak?"></a>Saving your sensitive information from Data Leak?</h2><p>As you may know, once you commit your issue on GitHub, it will leave a trace. This is because the version control nature of GitHub. But that also means everyone can always inspect your repositories‚Äô history, even your newest version already removed your leaked data. Other than deleting your repository and start all over again, you may also cover and rewrite your commit history, and even rewrite the content by following <a href="./">this</a>.</p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/Environment_variable">Environment variable</a>, <a href="https://stackoverflow.com/questions/44342276/how-to-push-code-to-github-hiding-the-api-keys">How to push code to Github hiding the API keys?</a></p>]]></content>
      
      
      <categories>
          
          <category> Site_Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> GitHub </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mathjax prime superscript problem in Hexo theme</title>
      <link href="/hexo-mathjax/"/>
      <url>/hexo-mathjax/</url>
      
        <content type="html"><![CDATA[<h2 id="Prime-superscript-problem-e-g-x‚Äô-i-in-Mathjax"><a href="#Prime-superscript-problem-e-g-x‚Äô-i-in-Mathjax" class="headerlink" title="Prime superscript problem (e.g. x‚Äô_i) in Mathjax"></a>Prime superscript problem (e.g. x‚Äô_i) in Mathjax</h2><p>When I was using <a href="https://www.mathjax.org/">Mathjax</a> to create math formula in my blog post, I typed<br><code>((q_1, q_2), a, (q&#39;_1, q&#39;_2)) \in S \times \Sigma_&#123;int&#125; \times S</code> and it rendered as</p><p><em><strong>$((q_1, q_2), a, (q‚Äô_1, q‚Äô<em>2)) \in S \times \Sigma</em>{int} \times S$</strong></em></p><p>However, when <code>((q_1, q_2), a, (q&#39;_1, q&#39;_2))</code> &amp; <code>\in S \times \Sigma_&#123;int&#125; \times S</code> are seperated, they rendered properly.</p><p>$$((q_1, q_2), a, (q‚Äô_1, q‚Äô_2))$$</p><p>$$\in S \times \Sigma_{int} \times S$$</p><blockquote><p>Maybe I should use <code>\left</code> and <code>\right</code> for (), just like <code>\lbrace</code> and <code>\rbrace</code> for {}?</p></blockquote><p>So I typed <code>\left( \left( q_1, q_2 \right), a, \left( q&#39;_1, q&#39;_2 \right) \right) \in S \times \Sigma_&#123;int&#125; \times S</code>, didn‚Äôt work out:</p><p><em><strong>$\left( \left( q_1, q_2 \right), a, \left( q‚Äô_1, q‚Äô<em>2 \right) \right) \in S \times \Sigma</em>{int} \times S$</strong></em></p><h2 id="Source-of-error"><a href="#Source-of-error" class="headerlink" title="Source of error"></a>Source of error</h2><blockquote><p>Problem definitely comes from the first half of the formula, since second half are all variables.</p></blockquote><p>Turns out there may be an issue with how the <strong>prime symbol</strong> are being handled.</p><p>For simple formula, <code>q&#39;_1</code> and <code>q_1&#39;</code> are considered the identical.<br>However, for more complicated formula, the only <code>q_1&#39;</code> can be rendered correctly:</p><p>$$((q_1, q_2), a, (q_1‚Äô, q_2‚Äô)) \in S \times \Sigma_{int} \times S$$</p><h2 id="Solutions"><a href="#Solutions" class="headerlink" title="Solutions"></a>Solutions</h2><p>Afterwards, I found people reported <a href="https://physics.meta.stackexchange.com/questions/2614/a-prime-superscript-in-latex-mathjax-not-displayed-correctly">similar issue</a> before.</p><p>Two basic solutions:</p><ol><li><p>Stick to the format <code>x_&#123;Subscript&#125;^&#123;Superscript&#125;</code>, but for prime symbol <code>&#39;</code>, use it as <code>x_&#123;Subscript&#125;&#39;</code></p></li><li><p>Simply use <code>&#123;\prime&#125;</code> for every situation, e.g. <code>x_&#123;i&#125;^&#123;\prime&#125;</code>.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Site_Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Latex </tag>
            
            <tag> Mathjax </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Parameterized Verification 1.2 -- Synchronization Primitives of Processes</title>
      <link href="/pv1-2/"/>
      <url>/pv1-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Swen Jacobs</p></blockquote><p>Last post: <a href="../pv1-1/">Labeled Transition Systems</a></p><h2 id="Processes"><a href="#Processes" class="headerlink" title="Processes"></a>Processes</h2><p>A Process is an LTS $P &#x3D; (Q, Q_0, \Sigma, \delta, \lambda)$ with $\Sigma &#x3D; \Sigma_{int} \cup \lbrace out_a , in_a \mid a \in \Sigma_{sync} \rbrace $, where </p><ul><li>$\Sigma_{int}$ is a set of <code>internal</code> actions,</li><li>$\Sigma_{sync}$ a set of <code>synchronizing</code> actions,</li><li>$out_a$ is an <code>send</code> action (or <code>initiate</code> action),</li><li>$in_a$ is an <code>receive</code> action.</li></ul><h3 id="Composition-by-Synchronization"><a href="#Composition-by-Synchronization" class="headerlink" title="Composition by Synchronization"></a>Composition by Synchronization</h3><p>The composition $P^n$ of $n$ (uniform) processes wrt. $card$ is the LTS $(S, S_0, \Sigma_{int} \cup \Sigma_{sync}, \Delta, \Lambda)$ with:</p><ul><li><p>$S &#x3D; Q \times Q$</p></li><li><p>$S_0 &#x3D; Q_0 \times Q_0$</p></li><li><p>$\Delta \subseteq S \times (\Delta_{int} \cup \Delta_{sync} \times S)$ is the set of all transitions that satisfy one of the following:</p><p><strong>Internal Transition</strong>:</p><ul><li>For some $i \in\lbrace 1, ‚Ä¶ , n \rbrace$ , $(s, a, s‚Äô) \in S \times\Sigma_{int}\times S$ is an element such that:<br> $(s(i), a, s‚Äô(i)) \in\delta$ , and $s(j) &#x3D; s‚Äô(j)$ for $i \ne j \in\lbrace 1, ‚Ä¶, n \rbrace$</li></ul><blockquote><p>Process $s(i)$ take the action, other processes $s(j)$ remain their current states.</p></blockquote><p><strong>Synchronous Transition</strong></p><ul><li><p>For some $i \in \lbrace 1, ‚Ä¶ , n \rbrace$ and some $I \subseteq \lbrace 1, ‚Ä¶, n \rbrace \setminus \lbrace i \rbrace$ with $|I| \in card$ ,<br>$(s, a, s‚Äô) \in S \times \Sigma_{int} \times S$ is an element such that:</p><ul><li>$s(i) \buildrel out_a \over\longrightarrow s‚Äô(i)$ is (a local transition) in $P$<blockquote><p>One process $s(i)$ take the <code>send</code> action.</p></blockquote></li><li>for every $j \in I, s(j) \buildrel in_a \over\longrightarrow s‚Äô(j)$ is (a local transition) in $P$<blockquote><p>$I$ is the set of processes that can take the <code>receive</code> action. (size of $I$ must not be larger then $card$)</p></blockquote></li><li>for every $j \in\lbrace 1, ‚Ä¶, n \rbrace \setminus (I \cup\lbrace i \rbrace), s‚Äô(j) &#x3D; s(j)$<blockquote><p>Other processes $s(j)$ that cannot take <code>receive</code> actions remain their current states.</p></blockquote></li><li>$I$ is <strong>maximal</strong>.<blockquote><p>There does not exist a larger set $I‚Äô \supset I$ with $|I‚Äô| \in card$ that for all $j \in I‚Äô$ ,<br>there is a local transition from $s(j)$ that can take the <code>receive</code> action.</p></blockquote></li></ul></li></ul></li><li><p>$\Lambda(s) &#x3D; \lbrace p_{i} \mid p \in \text{AP and p} \in\lambda(s(i)), i \in \lbrace 1, ‚Ä¶, n\rbrace \rbrace$</p></li></ul><blockquote><p>In this course, send action &#x3D; $out_a$ &#x3D; $a!!$ ; receive action &#x3D; $in_a$ &#x3D; $a??$.</p></blockquote><p>Example of Composition by <code>Broadcast</code> synchronization. $(card &#x3D; \lbrace 1 \rbrace)$</p><p><img src="/images/notes/uds/pv/1_2_composition.png"></p><h2 id="Synchronization-Primitives"><a href="#Synchronization-Primitives" class="headerlink" title="Synchronization Primitives"></a>Synchronization Primitives</h2><p>In this course, there are 4 types of synchronization:<br><code>Pairwise Rendezvous</code>, <code>Broadcast</code>, <code>Asynchronous Rendezvous</code>, and <code>Lossy Broadcast</code>.</p><h3 id="Pairwise-Rendezvous"><a href="#Pairwise-Rendezvous" class="headerlink" title="Pairwise Rendezvous"></a>Pairwise Rendezvous</h3><blockquote><p><strong>Exactly ONE</strong> process take $out_a$ action, <strong>ONE</strong> process take $in_a$ action. $(card &#x3D; \lbrace 1 \rbrace)$</p></blockquote><p><img src="/images/notes/uds/pv/1_2_pairwise.png"></p><h3 id="Broadcast"><a href="#Broadcast" class="headerlink" title="Broadcast"></a>Broadcast</h3><blockquote><p><strong>ONE</strong> process take $out_a$ action, <strong>ALL</strong> process take $in_a$ action if they are able to $(card &#x3D; \mathbb{N}_0)$.</p></blockquote><p><img src="/images/notes/uds/pv/1_2_broadcast.png"></p><h3 id="Asynchronous-Rendezvous"><a href="#Asynchronous-Rendezvous" class="headerlink" title="Asynchronous Rendezvous"></a>Asynchronous Rendezvous</h3><blockquote><p><strong>ONE</strong> process take $out_a$ action, <strong>ZERO &#x2F; ONE</strong> process take $in_a$ action $(card &#x3D; {0, 1})$.</p></blockquote><p><img src="/images/notes/uds/pv/1_2_async.png"></p><h3 id="Lossy-Broadcast"><a href="#Lossy-Broadcast" class="headerlink" title="Lossy Broadcast"></a>Lossy Broadcast</h3><blockquote><p><strong>ONE</strong> process take $out_a$ action, <strong>ONE</strong> process take $in_a$ action $(card &#x3D; \mathbb{N}_0, I\text{ not necessarily maximal})$.</p></blockquote><p><img src="/images/notes/uds/pv/1_2_lossy.png"></p><hr><p>Next post: <a href=""></a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/Synchronization_(computer_science)">Synchronization</a>, <a href="https://www7.in.tum.de/~esparza/Talks/ParamVerif.PDF">Parameterized Verification</a> by Javier Esparza.</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PV </tag>
            
            <tag> LTS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Parameterized Verification 1.1 -- Labeled Transition Systems</title>
      <link href="/pv1-1/"/>
      <url>/pv1-1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>This is a learning note of a course in <a href="https://cispa.de/de">CISPA</a>, UdS. Taught by Swen Jacobs</p></blockquote><h2 id="Labeled-Transition-Systems-LTS"><a href="#Labeled-Transition-Systems-LTS" class="headerlink" title="Labeled Transition Systems (LTS)"></a>Labeled Transition Systems (LTS)</h2><p>LTS is a concept in theoretical computer science used in the study of computation. It is used to describe the potential behavior of discrete systems, e.g. <a href="https://en.wikipedia.org/wiki/Model_checking">Model Checking</a>.</p><p>It consists of states and transitions between states, which may be labeled with labels chosen from a set; the same label may appear on more than one transition. Mathematically, it can be described as <a href="https://en.wikipedia.org/wiki/Directed_graph">directed graph</a>.</p><h3 id="Labels"><a href="#Labels" class="headerlink" title="Labels"></a>Labels</h3><p>Labels can be used to describe the behaviour or distinguish between states.<br>If the set of label is a <a href="https://en.wikipedia.org/wiki/Singleton_(mathematics)">singleton</a> (only contains one label), then it can be omitted in the system.</p><h3 id="LTS-v-s-Finite-state-Automata"><a href="#LTS-v-s-Finite-state-Automata" class="headerlink" title="LTS v.s. Finite-state Automata"></a>LTS v.s. Finite-state Automata</h3><p>In Transition systems:</p><ul><li>The set of states is not necessarily finite, or even countable.</li><li>The set of transitions is not necessarily finite, or even countable.</li><li>No ‚Äústart‚Äù state or ‚Äúfinal‚Äù states are given.</li></ul><h2 id="Formal-definition"><a href="#Formal-definition" class="headerlink" title="Formal definition"></a>Formal definition</h2><p>Let $AP$ be a set of atomic propositions (statement or assertion that must be true or false),<br>i.e., observable properties of the system.</p><p>A labeled transition system (LTS) over $AP$ is a tuple $Q, Q_0, \Sigma, \delta, \lambda$, where</p><ul><li>$Q$ is a set of states</li><li>$Q_0 \subseteq Q$ is the set of initial states</li><li>$\Sigma$ is the set of transition labels (or actions)</li><li>$\delta \subseteq Q \times \Sigma \times Q$ is the transition relation (also write as $ q\buildrel a \over\rightarrow q‚Äô \in \delta$)</li><li>$\lambda : Q \rightarrow 2^{AP}$ is the state labeling.</li></ul><blockquote><p>In this course, we assume <strong>finite LTS</strong>, which means $AP$ and $Q$ are finite, unless explicitly stated.</p></blockquote><p><img src="/images/notes/uds/pv/1_1_LTS.png"></p><h2 id="Run-of-an-LTS"><a href="#Run-of-an-LTS" class="headerlink" title="Run of an LTS"></a>Run of an LTS</h2><p>Consider an LTS $M &#x3D; (Q, Q_0, \Sigma, \delta, \lambda)$.</p><h3 id="Path"><a href="#Path" class="headerlink" title="Path"></a>Path</h3><p>A path of $M$ an is a finite sequence $q_0a_0q_1a_1‚Ä¶q_n \in (Q\Sigma)\ast Q$, such that $ q_i \buildrel a_i \over\rightarrow q_{i+1}$ for all $i &lt; n$<br>or an infinite sequence $q_0a_0q_1a_1‚Ä¶q_n \in (Q\Sigma)^\omega$, such that $ q_i \buildrel a_i \over\rightarrow q_{i+1}$ for all $i \in \mathbb{N}$.</p><h3 id="Run"><a href="#Run" class="headerlink" title="Run"></a>Run</h3><p>A run of $M$ is a <strong>path</strong> of $M$ with $q_0 \in Q_0$, and that is maximal, i.e., it cannot be extended.</p><p>A run is <strong>deadlocked</strong> if it is finite.</p><h3 id="State-labeled-paths"><a href="#State-labeled-paths" class="headerlink" title="State-labeled paths"></a>State-labeled paths</h3><p>$q_0q_1‚Ä¶$, the projection of a path onto states $Q$,</p><h3 id="Action-labeled-paths"><a href="#Action-labeled-paths" class="headerlink" title="Action-labeled paths"></a>Action-labeled paths</h3><p>$a_0a_1‚Ä¶$, the projection of a path onto actions $\Sigma$,</p><h3 id="Traces"><a href="#Traces" class="headerlink" title="Traces"></a>Traces</h3><p>$\lambda (q_0)\lambda q_1‚Ä¶$, the sequence of labels of a <strong>state-labeled path</strong>.</p><hr><p>Next post: <a href="../pv1-2/">Synchronization Primitives of Processes</a></p><p>Further Reading: <a href="https://en.wikipedia.org/wiki/Transition_system">Transition System</a>, <a href="https://en.wikipedia.org/wiki/Model_checking">Model Checking</a>.</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
          <category> UdS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PV </tag>
            
            <tag> LTS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3-hexo Shortcut</title>
      <link href="/3_hexo_Shortcut/"/>
      <url>/3_hexo_Shortcut/</url>
      
        <content type="html"><![CDATA[<p>Below is the list of shortcuts by for readers from the 3-hexo theme.</p><h2 id="Details"><a href="#Details" class="headerlink" title="Details"></a>Details</h2><h3 id="Global-Shortcut"><a href="#Global-Shortcut" class="headerlink" title="Global Shortcut"></a>Global Shortcut</h3><table><thead><tr><th align="left">Key</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">s</td><td align="left">show &#x2F; hide sidebar</td></tr><tr><td align="left">w</td><td align="left">show &#x2F; hide post‚Äôs table of content</td></tr><tr><td align="left">i</td><td align="left">focus on search boxes</td></tr><tr><td align="left">j</td><td align="left">scroll down</td></tr><tr><td align="left">k</td><td align="left">scroll up</td></tr><tr><td align="left">g</td><td align="left">page up</td></tr><tr><td align="left">shift+g</td><td align="left">page down</td></tr></tbody></table><h3 id="Search-Box"><a href="#Search-Box" class="headerlink" title="Search Box"></a>Search Box</h3><table><thead><tr><th align="left">Key</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">esc</td><td align="left">1. If there is input in the search box, it will be cleared </br> 2. if not, remove its focus</td></tr><tr><td align="left">down</td><td align="left">scroll downward</td></tr><tr><td align="left">up</td><td align="left">scroll upward</td></tr><tr><td align="left">enter</td><td align="left">redirect to selected post (default: first search result)</td></tr></tbody></table><p>More info: <a href="https://yelog.org/2017/03/24/3-hexo-shortcuts/">3-hexo shortcut by yelog</a></p>]]></content>
      
      
      <categories>
          
          <category> Site_Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> 3-hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
